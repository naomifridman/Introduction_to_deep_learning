{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Deep_Learning_keras_boston_regression_and_training_tools.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naomifridman/Introduction_to_deep_learning/blob/master/Deep_Learning_keras_boston_regression_and_training_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g8ADnsTIeDD",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to Deep Learning \n",
        "# Training DNN with Keras\n",
        "### boston house price regression example\n",
        "* https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
        "* https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpDCvsayIeDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.gridspec as gridspec\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "%matplotlib inline  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kisebjD5IeDK",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvo8kZdhIeDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "def print_stats(ytest, ypred):\n",
        "    \n",
        "    print(\"Accuracy: {:.5f}, Cohen's Kappa Score: {:.5f}\".format(\n",
        "        accuracy_score(ytest, ypred), \n",
        "        cohen_kappa_score(ytest, ypred, weights=\"quadratic\")))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(ytest, ypred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(ytest, ypred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCkCFNvFIeDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drow_history_list(history_list, history_names=None,  metric=None):\n",
        "    \n",
        "    if metric is None:\n",
        "        metric = 'loss'\n",
        "        \n",
        "    leg = []\n",
        "    if history_names is not None:\n",
        "        for n in history_names:\n",
        "            leg.append('train ' + n)\n",
        "            leg.append('test ' + n)\n",
        "    else:\n",
        "        for n in range(len(history_list)):\n",
        "            leg.append('train ' + str(n))\n",
        "            leg.append('test ' + str(n))\n",
        "            \n",
        "    for hist in history_list:\n",
        "        \n",
        "        plt.plot(hist.history[metric])\n",
        "        plt.plot(hist.history['val_'+ metric], '--', linewidth=2)\n",
        "        \n",
        "        \n",
        "    plt.title('model '+metric)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(leg, loc='best')\n",
        "    plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dspqhx6oIeDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drow_history(history, metric, i_start=0):\n",
        "    if metric is None:\n",
        "        metric = 'loss'\n",
        "    plt.plot(history.history[metric][i_start:])\n",
        "    plt.plot(history.history['val_'+ metric][i_start:])\n",
        "    plt.title('model '+metric)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qieYYnK8IeDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fd698134-5a07-4473-e527-4d3b14a9fb77"
      },
      "source": [
        "import keras\n",
        "# Keras has many build in data sets\n",
        "from keras.datasets import mnist\n",
        "# Sequential is the basic feed forward neural network (FFN)\n",
        "from keras.models import Sequential\n",
        "# Dense is fully connected layer\n",
        "# Dropout is a \"noising\" layer, to prevent over feet.\n",
        "from keras.layers import Dense, Dropout\n",
        "# Read about optimizers in keras documentation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import optimizers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSyoi-5RIeDY",
        "colab_type": "text"
      },
      "source": [
        "## Read data and Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErDJmBtRIeDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcIqqwf9IeDb",
        "colab_type": "text"
      },
      "source": [
        "Data fields\n",
        "* Here's a brief version of what you'll find in the data description file.\n",
        "\n",
        "* SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
        "* MSSubClass: The building class\n",
        "* MSZoning: The general zoning classification\n",
        "* LotFrontage: Linear feet of street connected to property\n",
        "* LotArea: Lot size in square feet\n",
        "* Street: Type of road access\n",
        "* Alley: Type of alley access\n",
        "* LotShape: General shape of property\n",
        "* LandContour: Flatness of the property\n",
        "* Utilities: Type of utilities available\n",
        "* LotConfig: Lot configuration\n",
        "* LandSlope: Slope of property\n",
        "* Neighborhood: Physical locations within Ames city limits\n",
        "* Condition1: Proximity to main road or railroad\n",
        "* Condition2: Proximity to main road or railroad (if a second is present)\n",
        "* BldgType: Type of dwelling\n",
        "* HouseStyle: Style of dwelling\n",
        "* OverallQual: Overall material and finish quality\n",
        "* OverallCond: Overall condition rating\n",
        "* YearBuilt: Original construction date\n",
        "* YearRemodAdd: Remodel date\n",
        "* RoofStyle: Type of roof\n",
        "* RoofMatl: Roof material\n",
        "* Exterior1st: Exterior covering on house\n",
        "* Exterior2nd: Exterior covering on house (if more than one material)\n",
        "* MasVnrType: Masonry veneer type\n",
        "* MasVnrArea: Masonry veneer area in square feet\n",
        "* ExterQual: Exterior material quality\n",
        "* ExterCond: Present condition of the material on the exterior\n",
        "* Foundation: Type of foundation\n",
        "* BsmtQual: Height of the basement\n",
        "* BsmtCond: General condition of the basement\n",
        "* BsmtExposure: Walkout or garden level basement walls\n",
        "* BsmtFinType1: Quality of basement finished area\n",
        "* BsmtFinSF1: Type 1 finished square feet\n",
        "* BsmtFinType2: Quality of second finished area (if present)\n",
        "* BsmtFinSF2: Type 2 finished square feet\n",
        "* BsmtUnfSF: Unfinished square feet of basement area\n",
        "* TotalBsmtSF: Total square feet of basement area\n",
        "* Heating: Type of heating\n",
        "* HeatingQC: Heating quality and condition\n",
        "* CentralAir: Central air conditioning\n",
        "* Electrical: Electrical system\n",
        "* 1stFlrSF: First Floor square feet\n",
        "* 2ndFlrSF: Second floor square feet\n",
        "* LowQualFinSF: Low quality finished square feet (all floors)\n",
        "* GrLivArea: Above grade (ground) living area square feet\n",
        "* BsmtFullBath: Basement full bathrooms\n",
        "* BsmtHalfBath: Basement half bathrooms\n",
        "* FullBath: Full bathrooms above grade\n",
        "* HalfBath: Half baths above grade\n",
        "* Bedroom: Number of bedrooms above basement level\n",
        "* Kitchen: Number of kitchens\n",
        "* KitchenQual: Kitchen quality\n",
        "* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
        "* Functional: Home functionality rating\n",
        "* Fireplaces: Number of fireplaces\n",
        "* FireplaceQu: Fireplace quality\n",
        "* GarageType: Garage location\n",
        "* GarageYrBlt: Year garage was built\n",
        "* GarageFinish: Interior finish of the garage\n",
        "* GarageCars: Size of garage in car capacity\n",
        "* GarageArea: Size of garage in square feet\n",
        "* GarageQual: Garage quality\n",
        "* GarageCond: Garage condition\n",
        "* PavedDrive: Paved driveway\n",
        "* WoodDeckSF: Wood deck area in square feet\n",
        "* OpenPorchSF: Open porch area in square feet\n",
        "* EnclosedPorch: Enclosed porch area in square feet\n",
        "* 3SsnPorch: Three season porch area in square feet\n",
        "* ScreenPorch: Screen porch area in square feet\n",
        "* PoolArea: Pool area in square feet\n",
        "* PoolQC: Pool quality\n",
        "* Fence: Fence quality\n",
        "* MiscFeature: Miscellaneous feature not covered in other categories\n",
        "* MiscVal: $Value of miscellaneous feature\n",
        "* MoSold: Month Sold\n",
        "* YrSold: Year Sold\n",
        "* SaleType: Type of sale\n",
        "* SaleCondition: Condition of sale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuILN0qJSEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7f2242a2-009f-44e8-e490-9d05b3249d0c"
      },
      "source": [
        "import os\n",
        "# DATA_IN_KAGGLE:\n",
        "os.environ['KAGGLE_USERNAME']='ripcurl' #xxxxxx\n",
        "os.environ['KAGGLE_KEY']='f18cea91f5001432043566dbd5a174c7' #xxxxxx\n",
        "\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques # api copied from kaggle"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/31.2k [00:00<?, ?B/s]\n",
            "100% 31.2k/31.2k [00:00<00:00, 12.3MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/441k [00:00<?, ?B/s]\n",
            "100% 441k/441k [00:00<00:00, 62.7MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/450k [00:00<?, ?B/s]\n",
            "100% 450k/450k [00:00<00:00, 62.4MB/s]\n",
            "Downloading data_description.txt to /content\n",
            "  0% 0.00/13.1k [00:00<?, ?B/s]\n",
            "100% 13.1k/13.1k [00:00<00:00, 13.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YDb1fbQKACI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3cfb3568-bbbb-4968-c77f-12eecbb66325"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_description.txt  sample_data  sample_submission.csv  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVDV2xatIeDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "8350683a-6b36-43d5-ef38-182b244e9ad2"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxHGz_5IeDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "42b91e9a-437a-4f5e-ea2c-d7e9730dd992"
      },
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "test.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1961</td>\n",
              "      <td>1961</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Rec</td>\n",
              "      <td>468.0</td>\n",
              "      <td>LwQ</td>\n",
              "      <td>144.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>882.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1961.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1.0</td>\n",
              "      <td>730.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1958</td>\n",
              "      <td>1958</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>108.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>923.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>1329.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1329</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1958.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>393</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1997</td>\n",
              "      <td>1998</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>791.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>928.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>928</td>\n",
              "      <td>701</td>\n",
              "      <td>0</td>\n",
              "      <td>1629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>482.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>212</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>78.0</td>\n",
              "      <td>9978</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1998</td>\n",
              "      <td>1998</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>20.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>602.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>926.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>926</td>\n",
              "      <td>678</td>\n",
              "      <td>0</td>\n",
              "      <td>1604</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>360</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>120</td>\n",
              "      <td>RL</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5005</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>StoneBr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>TwnhsE</td>\n",
              "      <td>1Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>1992</td>\n",
              "      <td>1992</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>263.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1280</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1280</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id  MSSubClass MSZoning  ...  YrSold  SaleType SaleCondition\n",
              "0  1461          20       RH  ...    2010        WD        Normal\n",
              "1  1462          20       RL  ...    2010        WD        Normal\n",
              "2  1463          60       RL  ...    2010        WD        Normal\n",
              "3  1464          60       RL  ...    2010        WD        Normal\n",
              "4  1465         120       RL  ...    2010        WD        Normal\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tHem8viIeDi",
        "colab_type": "text"
      },
      "source": [
        "### Combine train and test data to process them together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9UbA8XHIeDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = train.SalePrice\n",
        "train.drop(['SalePrice'],axis = 1 , inplace = True)\n",
        "\n",
        "combined = train.append(test)\n",
        "combined.reset_index(inplace=True)\n",
        "combined.drop(['index', 'Id'], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lHSBENcIeDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "437507ec-0e7b-4b56-d5d4-12bf1fdae99a"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1459 entries, 0 to 1458\n",
            "Data columns (total 80 columns):\n",
            "Id               1459 non-null int64\n",
            "MSSubClass       1459 non-null int64\n",
            "MSZoning         1455 non-null object\n",
            "LotFrontage      1232 non-null float64\n",
            "LotArea          1459 non-null int64\n",
            "Street           1459 non-null object\n",
            "Alley            107 non-null object\n",
            "LotShape         1459 non-null object\n",
            "LandContour      1459 non-null object\n",
            "Utilities        1457 non-null object\n",
            "LotConfig        1459 non-null object\n",
            "LandSlope        1459 non-null object\n",
            "Neighborhood     1459 non-null object\n",
            "Condition1       1459 non-null object\n",
            "Condition2       1459 non-null object\n",
            "BldgType         1459 non-null object\n",
            "HouseStyle       1459 non-null object\n",
            "OverallQual      1459 non-null int64\n",
            "OverallCond      1459 non-null int64\n",
            "YearBuilt        1459 non-null int64\n",
            "YearRemodAdd     1459 non-null int64\n",
            "RoofStyle        1459 non-null object\n",
            "RoofMatl         1459 non-null object\n",
            "Exterior1st      1458 non-null object\n",
            "Exterior2nd      1458 non-null object\n",
            "MasVnrType       1443 non-null object\n",
            "MasVnrArea       1444 non-null float64\n",
            "ExterQual        1459 non-null object\n",
            "ExterCond        1459 non-null object\n",
            "Foundation       1459 non-null object\n",
            "BsmtQual         1415 non-null object\n",
            "BsmtCond         1414 non-null object\n",
            "BsmtExposure     1415 non-null object\n",
            "BsmtFinType1     1417 non-null object\n",
            "BsmtFinSF1       1458 non-null float64\n",
            "BsmtFinType2     1417 non-null object\n",
            "BsmtFinSF2       1458 non-null float64\n",
            "BsmtUnfSF        1458 non-null float64\n",
            "TotalBsmtSF      1458 non-null float64\n",
            "Heating          1459 non-null object\n",
            "HeatingQC        1459 non-null object\n",
            "CentralAir       1459 non-null object\n",
            "Electrical       1459 non-null object\n",
            "1stFlrSF         1459 non-null int64\n",
            "2ndFlrSF         1459 non-null int64\n",
            "LowQualFinSF     1459 non-null int64\n",
            "GrLivArea        1459 non-null int64\n",
            "BsmtFullBath     1457 non-null float64\n",
            "BsmtHalfBath     1457 non-null float64\n",
            "FullBath         1459 non-null int64\n",
            "HalfBath         1459 non-null int64\n",
            "BedroomAbvGr     1459 non-null int64\n",
            "KitchenAbvGr     1459 non-null int64\n",
            "KitchenQual      1458 non-null object\n",
            "TotRmsAbvGrd     1459 non-null int64\n",
            "Functional       1457 non-null object\n",
            "Fireplaces       1459 non-null int64\n",
            "FireplaceQu      729 non-null object\n",
            "GarageType       1383 non-null object\n",
            "GarageYrBlt      1381 non-null float64\n",
            "GarageFinish     1381 non-null object\n",
            "GarageCars       1458 non-null float64\n",
            "GarageArea       1458 non-null float64\n",
            "GarageQual       1381 non-null object\n",
            "GarageCond       1381 non-null object\n",
            "PavedDrive       1459 non-null object\n",
            "WoodDeckSF       1459 non-null int64\n",
            "OpenPorchSF      1459 non-null int64\n",
            "EnclosedPorch    1459 non-null int64\n",
            "3SsnPorch        1459 non-null int64\n",
            "ScreenPorch      1459 non-null int64\n",
            "PoolArea         1459 non-null int64\n",
            "PoolQC           3 non-null object\n",
            "Fence            290 non-null object\n",
            "MiscFeature      51 non-null object\n",
            "MiscVal          1459 non-null int64\n",
            "MoSold           1459 non-null int64\n",
            "YrSold           1459 non-null int64\n",
            "SaleType         1458 non-null object\n",
            "SaleCondition    1459 non-null object\n",
            "dtypes: float64(11), int64(26), object(43)\n",
            "memory usage: 912.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZaPwKJ7IeDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cols_with_no_nans(df,col_type):\n",
        "    '''\n",
        "    Arguments :\n",
        "    df : The dataframe to process\n",
        "    col_type : \n",
        "          num : to only get numerical columns with no nans\n",
        "          no_num : to only get nun-numerical columns with no nans\n",
        "          all : to get any columns with no nans    \n",
        "    '''\n",
        "    if (col_type == 'num'):\n",
        "        predictors = df.select_dtypes(exclude=['object'])\n",
        "    elif (col_type == 'no_num'):\n",
        "        predictors = df.select_dtypes(include=['object'])\n",
        "    elif (col_type == 'all'):\n",
        "        predictors = df\n",
        "    else :\n",
        "        print('Error : choose a type (num, no_num, all)')\n",
        "        return 0\n",
        "    cols_with_no_nans = []\n",
        "    for col in predictors.columns:\n",
        "        if not df[col].isnull().any():\n",
        "            cols_with_no_nans.append(col)\n",
        "    return cols_with_no_nans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpQKbCbCIeDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0908a9a9-fd25-4048-f64f-163b084fa372"
      },
      "source": [
        "num_cols_train = get_cols_with_no_nans(train , 'num')\n",
        "cat_cols_train = get_cols_with_no_nans(train , 'no_num')\n",
        "print ('Number of numerical columns with no nan values :',len(num_cols_train))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols_train))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 34\n",
            "Number of nun-numerical columns with no nan values : 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG7jOIrPIeDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b2ae829b-646e-4582-e48d-f80be5358df9"
      },
      "source": [
        "num_cols_combined = get_cols_with_no_nans(combined , 'num')\n",
        "cat_cols_combined = get_cols_with_no_nans(combined , 'no_num')\n",
        "print ('Number of numerical columns with no nan values :',len(num_cols_combined))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols_combined))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 25\n",
            "Number of nun-numerical columns with no nan values : 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZNHNKZVIeDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a2131105-8d5b-46a2-dc0f-dbf8c16e38ac"
      },
      "source": [
        "num_cols_test = get_cols_with_no_nans(test , 'num')\n",
        "cat_cols_test = get_cols_with_no_nans(test , 'no_num')\n",
        "print ('Number of numerical columns with no nan values :',len(num_cols_test))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 26\n",
            "Number of nun-numerical columns with no nan values : 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naHuSwqyIeD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dif =list(set(num_cols_train)-set(num_cols_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RjLR_lZIeD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "9f861259-39e4-457b-901b-c119decf28c6"
      },
      "source": [
        "train[dif].info()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 8 columns):\n",
            "GarageCars      1460 non-null int64\n",
            "BsmtUnfSF       1460 non-null int64\n",
            "GarageArea      1460 non-null int64\n",
            "BsmtFullBath    1460 non-null int64\n",
            "TotalBsmtSF     1460 non-null int64\n",
            "BsmtHalfBath    1460 non-null int64\n",
            "BsmtFinSF1      1460 non-null int64\n",
            "BsmtFinSF2      1460 non-null int64\n",
            "dtypes: int64(8)\n",
            "memory usage: 91.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhTbaU8gIeD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "716899ca-b3d6-4f80-daff-183a43c0a44c"
      },
      "source": [
        "test[dif].info()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1459 entries, 0 to 1458\n",
            "Data columns (total 8 columns):\n",
            "GarageCars      1458 non-null float64\n",
            "BsmtUnfSF       1458 non-null float64\n",
            "GarageArea      1458 non-null float64\n",
            "BsmtFullBath    1457 non-null float64\n",
            "TotalBsmtSF     1458 non-null float64\n",
            "BsmtHalfBath    1457 non-null float64\n",
            "BsmtFinSF1      1458 non-null float64\n",
            "BsmtFinSF2      1458 non-null float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 91.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meyg7WfkIeEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "5c5b6b6e-33d4-4750-913e-9f0b88b4e749"
      },
      "source": [
        "train[dif].hist(figsize = (12,10))\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAJOCAYAAABInurKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72TmOrBpIeEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "315c2ab5-d546-40bb-8596-a6bd10850f97"
      },
      "source": [
        "dif"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GarageCars',\n",
              " 'BsmtUnfSF',\n",
              " 'GarageArea',\n",
              " 'BsmtFullBath',\n",
              " 'TotalBsmtSF',\n",
              " 'BsmtHalfBath',\n",
              " 'BsmtFinSF1',\n",
              " 'BsmtFinSF2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U_AQHxIIeEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fil0 = ['BsmtFinSF1',\n",
        " 'BsmtFullBath',\n",
        " 'BsmtUnfSF',\n",
        " 'BsmtFinSF2',\n",
        " 'BsmtHalfBath']\n",
        "test[fil0] = test[fil0].fillna(0)\n",
        "test['GarageCars'] = test['GarageCars'].fillna(2.)\n",
        "test['TotalBsmtSF'] = test['TotalBsmtSF'].fillna(train['TotalBsmtSF'].median())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmCCmCyQIeEO",
        "colab_type": "text"
      },
      "source": [
        "#### Check null in categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaOfgcxzIeEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dif =list(set(cat_cols_train)-set(cat_cols_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYWwsHy0IeES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "82d23884-008d-46c9-f394-fcdd926483fa"
      },
      "source": [
        "train.shape,test.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460, 80), (1459, 80))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzVwmK7jIeEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "a9fe3b09-46e0-4ad7-8892-bfbbfc3095bd"
      },
      "source": [
        "train[dif].info()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 7 columns):\n",
            "Utilities      1460 non-null object\n",
            "KitchenQual    1460 non-null object\n",
            "Functional     1460 non-null object\n",
            "Exterior2nd    1460 non-null object\n",
            "Exterior1st    1460 non-null object\n",
            "MSZoning       1460 non-null object\n",
            "SaleType       1460 non-null object\n",
            "dtypes: object(7)\n",
            "memory usage: 79.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zES_vmNIeEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "16325a5d-5b95-49e2-b69f-3163a1d4ba19"
      },
      "source": [
        "test[dif].info()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1459 entries, 0 to 1458\n",
            "Data columns (total 7 columns):\n",
            "Utilities      1457 non-null object\n",
            "KitchenQual    1458 non-null object\n",
            "Functional     1457 non-null object\n",
            "Exterior2nd    1458 non-null object\n",
            "Exterior1st    1458 non-null object\n",
            "MSZoning       1455 non-null object\n",
            "SaleType       1458 non-null object\n",
            "dtypes: object(7)\n",
            "memory usage: 79.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooy5LlYUIeEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "ffed872e-130c-48a5-f9ac-6e71f796e47c"
      },
      "source": [
        "for col in dif:\n",
        "    print(col)\n",
        "    test[col] = test[col].fillna(value=str(train[col].mode()[0]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Utilities\n",
            "KitchenQual\n",
            "Functional\n",
            "Exterior2nd\n",
            "Exterior1st\n",
            "MSZoning\n",
            "SaleType\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCISqIVxIeEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "6a273e2f-e903-4a7a-8f6a-6094bd9b032a"
      },
      "source": [
        "test[dif].info()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1459 entries, 0 to 1458\n",
            "Data columns (total 7 columns):\n",
            "Utilities      1459 non-null object\n",
            "KitchenQual    1459 non-null object\n",
            "Functional     1459 non-null object\n",
            "Exterior2nd    1459 non-null object\n",
            "Exterior1st    1459 non-null object\n",
            "MSZoning       1459 non-null object\n",
            "SaleType       1459 non-null object\n",
            "dtypes: object(7)\n",
            "memory usage: 79.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7XT23xtIeEo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "41e14a5a-0c83-419a-faa3-533c65bdb1b5"
      },
      "source": [
        "test.KitchenQual.value_counts()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TA    758\n",
              "Gd    565\n",
              "Ex    105\n",
              "Fa     31\n",
              "Name: KitchenQual, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGke2LRWIeEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined = train.append(test)\n",
        "combined.reset_index(inplace=True)\n",
        "combined.drop(['index', 'Id'], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6LCRxWIeEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "008401d4-a1dd-423f-e79f-accf495e1137"
      },
      "source": [
        "num_cols = get_cols_with_no_nans(combined , 'num')\n",
        "cat_cols = get_cols_with_no_nans(combined , 'no_num')\n",
        "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 32\n",
            "Number of nun-numerical columns with no nan values : 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjJRDbbYIeEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "7e24a066-a9dc-4cd2-fa46-a9752b0e2086"
      },
      "source": [
        "combined = combined[num_cols + cat_cols]\n",
        "combined.hist(figsize = (12,10))\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAJOCAYAAABInurKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXmYXUWZ/z9fCMoWgRgJgUQCgso2\nYogEZhgMI7KqIHHQDEMSlkEcMo4/cQRXwIXBhVFQhhEEWWR1g4gIItg4oGEQRDaBRGxIWAIhBJIQ\nIAnv74+qmz59c7vv7e7bd+n+fp7nPvecOufUqVNvLe956606igiMMcYYY4wx1Vmn2QkwxhhjjDGm\nXbDybIwxxhhjTI1YeTbGGGOMMaZGrDwbY4wxxhhTI1aejTHGGGOMqRErz8YYY4wxxtSIledBQNJM\nSbc1Ox2mdmqVmaQpkhY0Ik2mPZHUKWnfZqejmUgKSds1Ox3VkDQhp3VEs9NiuiNpmaRtm50OUx+G\nmjyHpfIsaZakP0h6RdJFNV7TrUMsNLrLCr8/9SENh0i6R9KLkhZJukXSNvnYqZJWlsX96T4/6BBH\n0uslXSDpMUlLc34eWKe4Q9LyQv4v6cO1e0n6naQXJC2WdLukd+VjMyWtLpPtd+uR5nZD0g8lPZXr\nwCOSji0c+6ykv+b8WSDpqjrcr0PSyznORZJ+KmnsQOMdKuQ2bkXOn+cl/ULS+Ganqx7kl96QdFKd\n4x0r6XxJT+Z8e1TSRZLeXs/7DDaNkH3u135YFlask6XfngARsXFEPFpj3P3qTyUdntvqlyR11PN5\nm8kwluc3Jc3N+sBDkqbX85mLDEvlGXgS+ApwYR3i2jQXio0j4h3VTpY0QskicwlwIrAJsA1wDrC6\ncOpVhXg3joiv1yGtQ40RwHzg3aR8/DxwtaQJdYr/HYX837TayVm2bwCuA74DjAK2Ak4DXimc+vsy\n2c6qU3rbjf8EJkTEG4APAF+RtJukGcCRwL4RsTEwCbi5TvecleN8K7Ap8K2+RqChbaV8f86fscBC\nUjmuK5LWrXecNTADWAzUrTOV9Ebgd8CGwN8DI4GJwK3Ae3u4ppXLzqDLvgdmlbWHv+/LxQPsTxcD\n3wbOGPhjtBzDUZ7Lgffn62YAZ0n624E+UCWGpfIcET+NiGuA54rhkkZLuk7Skmwx/F9J60i6FHgz\n8HP1wwqcLR4nSJoLzAV2Bf4aETdHYmlE/CQiHq/XMw4HImJ5RJwaEZ0R8VpEXAf8FdgtW5oWSDpR\n0jPZwnlU6VpJb5Q0O7/Z/h/wlv6kIb/hnyTpXlLFfWtO2xURsToiVkTEryLi3jo88pAiIh6IiNJL\nReTfW4B3ATdGxF/yeU9HxHml65Ss949m68JfJR1RCL8tWx+ez8cqjkRExGLgJ8DO+dpNJF0i6Vml\nkYzPS1qnEO/tkr4l6Tng1Bz+L5L+nNPxoKSJhVvsKulepdGHqyStX7+cG3wi4mXgx8COsGaU55uS\nHpe0UNL/SNqgdL6k/8h17ElJRxfjUrLEnivpeknLgX2q5Pc6ef+xXHcvkbRJPlYa8TtK0vws5+Ml\nvSvn9xKVjeRI2gj4EHACsL2kSRUe+eic9qckfSpft6WS9W5UIa53KlnC1gP+H/AicGRE/CW35Usi\n4gcR8Z2y9B4j6XHglgEJpgFUkP1BuXwvlfREIX9KbeynC23sofn8R3If+tl87gHAZ4EPq8ZRWhVc\nf3IZOkfJgrpU0h2SSm12v/vTiPh1RFxNMqgNSYaZPE+JiIeyPnAH8L/Ann3PteoMS+W5F04EFgBv\nAsaQCkdExJHA4+Q3uX5agQ8FJpMK8N3A23NnvI+kjeuT/OGNpDEk5fWBHLQF6Q10K+AY4BxJm+Vj\n5wAvk97Kj86//jINOJhkyXwEWC3pYkkHFu5nKiDpvyW9BDwEPAVcD8wBpmeFbJIKlsqsCJ0NHBgR\nI4G/Be4pRDkZeBgYDXwduECSKtx3NDAV+GMO+g6prGxLGsmYDhxVuGQy8CipXfiqpH8kKdHTgZLl\nvPgyfjhwAMlq8jfAzL7kS7ORtCHwYZIsIFnm3krq2LYj1akv5nMPAD5FsrZuD1Ty9/4n4Ksk6+xt\n9J7fM/Nvn3x8Y6DctWlyvteHSZbDz+X77gQcLundhXMPA5YBPwJuJFmkytknx7cfcJKkfSPiSeD3\npHJSfI4fR8TKfL+fRcRrFeIr593ADsD+NZzbVCrI/gLgo7m+7Uz3F4AtgPXpKg/nA/8M7Eayxn9B\n0jYRcQNwOl0Ww6qjtBX4CGkUbzNgHqk8gfvTXhmu8lR6uX8XXfpAfYmIYfsjuW5cVNj/EnAtsF2F\ncztJw8il/QkkS9mSwu9T+dhM4LbCuQH8Q1l8ewBXA8+SlLiLgI3zsVOBV8vi3rLZ+dXKP2A94NfA\n9/L+FGAFMKJwzjM539cFVgJvLxw7vYLMXizk/9mFeBeUlYujy9KyQ5bnAmAVMBsYUygbq8pku0ez\n86/JslsX2IvkdrNeDjsiy3M5SSk9KYdvlPNsKrBBWTwzgXmF/Q2zHLfI+x3AS/n6J4DLSC/K6+b6\ntmPh2o8CHYV4Hy+7143Av/fwPJ3APxf2vw78T7PzuQY5dJKUzCW5fjwJ7AIoy+EthXP3JFmHILm/\nnVE49tac79vl/YuAS8rk3Vt+3wz8a+HY23J6RtDV7m5VOP4c8OHC/k+ATxT2fw18O29PI7W5pXJW\niq/YFnwduCBvHwvckrdFchPbO+/PA44vXPeBnHdLgV+Vxb9ts+XbH9nnY49n+byh7JoppDZ23bw/\nMj/r5MI5dwGH5u1TgR+WxdFBV51cAtxdOFZehr5fOHYQ8FBhf0D9aZZzR7PlYHnWR575vIuBGwAN\nRh7b8tydb5AaxF8pDQufXMM1oyNi0/z7Zi/nzS/uRMSciDg8It5EeqPbm2Q9KXF1Id5NI1lBTAXy\ncO+lpApV9B9+LiJWFfZfIlmx3kSXv3SJxypEPbGQ/x/vJQnlsv1zRMyMiHGkN/stSdaxEnPKZDuH\nYUwk95bbgHHAx3LYZRGxL8mafzzwZUn7R8RykhXleOCpPOxXnJz1dCHel/Jm0XLx8ZznW0XEERHx\nLMlKvR7dy8BjJOtLiW4yBsYDf+nlsZ4ubJfKXTtwaCT//vVJdelW0rNuCNyV3SKWkDqlN+VrtqR6\nXSoer5bfW1Y4NoJk9S+xsLC9osL+xgBKk6T2Ib0oQTKOrE8aKeopfY/lNEBSxPdUmli6N/AaaSgY\nktK+ZsJpRMzOeff/gNf1En+rspbsJW1BelE9CHhM0q3KE8Ayz0VEyRd1Rf6vKIte+HihLZzYy3k9\n1in3pxUZtvKU9A1S33t4ZE263lh5LhDJt+bEiNiWZEX4pKT3lA4PNPpe7nsn8FOy/6WpnTwkfwGp\nY50aaTi1Gs+SrL/F2cdvHkAyepPtQ6S3Zsu2OiMo8z2PiJUR8SPgXnIeRsSNEfFekuLyEGlocSAs\nIllnti6EvZlknV6TlLJr5pendSiRX2h+Spqkswep09yp0FltEmkyEiR3m2p1qZh/1fL7yQrHVtG9\nE6+VI0n93M8lPU1yvVmftV03ytP/JEBEPA/8ivTC9k/AlYXO+Gbg0PzyXo1B6cAHgzLZ7xURd0bE\nIcDmwDUki2C/oq5XGnu9ifvTbgw3eUo6DTgQ2C8iXhysdA1L5VlpVYT1ScOH60paP4e9T9J2WSF7\ngVTYSv5sC0n+d/W4/15Kk402z/tvJynrw9oC2U/OJblJvD8iVlQ7GVJjQqqMp0raUNKOVPaD7DOS\n3q40SXFc3h9PGiq2bAtI2lzSRyRtLGldSfuT8ulmpQl6B0saqTR57ECSL+sdksYoLWO0EWkFk2V0\n1dF+kcvD1SRf5pGStgY+Cfywl8u+D3xKaXUQ5XZj617ObyvyMx1C8kd8gPSC8q1Cm7VVlhmkvJsp\nacfsX3lKb3HXkN9XAP9P0jbZ37HkW7mqcoy9MoPkV7lr4TcVOEhptYwSX8htwU4k3+vi0oiXk3yy\nP5S3S/wXKX8ulfSWnGcj8z3aljLZz5V0hKRNsmHiRfpf3xYCE2p82aiZgfSnue1Zn/Tivk7WBdar\nZ/qazTCT52dIL7n7RsRz1c4fCMNSeSb5Vq4ATiY5w6/IYduT/OOWkSaK/HdE/CZf85/A5/Ow5acG\neP8lpMJwn6RlpCHQn5F87UyN5E73o6TO6ml1rfl4RA2XzyINEz1Nsgz/oE7JWkqazHSH0soCc4D7\nSZNRTRdBctFYADwPfJPkpzqb1KB/luSbt4RULz6WXTvWISlaT5KWmXp3jmeg/BvJr/dR0oS2y+ll\nKctsDf9qPm8pyYIzqqfz24if5zbpRdLzzYiIB4CTSC5tcyS9SGon3wYQEb8kuSXdks+pZUWJ3vL7\nQpIb1m9Jq+e8nM/vE5L2IFmwz4m0YkvpNzunc1rh9Ftz2M3ANyPiV4Vjs0l9w9MRsWZVgYhYRLLK\nv5yfYSlp8upI6lMmG81asgf+TLLed2a5H0+aj9AffpT/n5N090ATW2Ag/emRpP7/XJJ7wAoGPpLV\nKgxHeZ5OGjmaV9AHPlvHtK1Bg+QOYowxxhhjzJBjuFqejTHGGGOM6TNWno0xxhhjjKkRK8/GGGOM\nMcbUiJVnY4wxxhhjamREsxPQG6NHj44JEyY0Oxm9snz5cjbaaKNmJ6MmekrrXXfdtSgvRj6olMuz\nnfKu1egt75olz2rpMr3T7PoJQ7eOttJzWJ6tS3/yx/KsL81+pprlWctnCJv122233aLV+c1vftPs\nJNRMT2kF/hBNkGc75V2r0VveNUue1dJleqfZ9TOGcB1tpeewPFuX/uSP5Vlfmv1MtcrTbhvGGGOM\nMcbUiJVnY4wxxhhjaqSlfZ77yoSTf1H1nM4zDm5ASkwt3PfEC8ysIjPLq72oJlPL0xSp1ma7vNQX\n18+hheXZPGx5NsYYY4wxpkasPBtjjDHGGFMjVp6NMcYYY4ypESvPxhhjjDHG1IiVZ2OMMcYYY2rE\nyrMxxhhjjDE1YuXZGGOMMcaYGrHybIwxxhhjTI1YeTbGGGOMMaZGrDwbY4wxxhhTI1aejTHGGGOM\nqRErz8YYY4wxxtSIlWdjjDHGmCrMnz+fffbZhx133JGddtqJs846CwBJoyTdJGlu/t8sh0vS2ZLm\nSbpX0sRSXJJm5PPnSprRpEcy/WREsxNgjDHGGNPqjBgxgjPPPJOJEyeydOlSdtttN4D1gZOBmyPi\nDEkn5/2TgAOB7fNvMnAuMFnSKOAUYBIQwF2SZkfE841/KtMfbHk2xhhjjKnC2LFjmTgxGY9HjhzJ\nDjvsAPA64BDg4nzaxcChefsQ4JJIzAE2lTQW2B+4KSIWZ4X5JuCAxj2JGSi2PBtjjDHG9IHOzk7+\n+Mc/AiwDto2Ip/Khp4ExeXsrYH7hsgU5rKfwtZB0HHAcwJgxY+jo6FhzbMwGcOIuq3pMY/HcdmHZ\nsmVtkW4rz8YYY4wxNbJs2TKmTp3Kt7/9baZOnfpa8VhEhKSo170i4jzgPIBJkybFlClT1hz7zmXX\ncuZ9PatxnUdM6fFYq9LR0UHxGVsVu20Y08Z4AosxxjSOlStXMnXqVI444ggOO+ywUvDC7I5B/n8m\nhz8BjC9cPi6H9RRu2gQrz8a0MaUJLA8++CBz5szhnHPOge4TWLYHbs770H0Cy3GkCSwUJrBMBnYH\nTikp3MYYYyAiOOaYY9hhhx345Cc/WTw0GygZHGYA1xbCp2ejxR7AC9m940ZgP0mb5XZ2vxxm2oSq\nyrOkCyU9I+n+QpitWsa0AJ7AYowxjeH222/n0ksv5ZZbbmHXXXdl1113BdgEOAN4r6S5wL55H+B6\n4FFgHnA+8K8AEbEY+DJwZ/59KYeZNqEWn+eLgO8ClxTCvCyLMS1GIyaw9DZ5BYbmBJZG0S4TZYwZ\nruy1115EdHdnlvRCRDwHvKf8/Egnn1Aproi4ELhwMNJpBp+qynNE/FbShLLgQ4ApeftioIOkPK+x\nagFzJJWsWlPIVi0ASSWr1hUDfgJjTMMmsPQ2eQWG5gSWRlGaKHP00Udz3XXXsfnmm3P//WnALxsg\nrgImAJ3A4RHxvCQBZwEHAS8BMyPi7nzNDODzOfqvRMTFGGOMGTD9XW1jTDOWZalGbxavEvW27LST\ntaid0mpqp7cJLBHxVB8msEwpC+8Y1ISbisycOZNZs2Yxffr0YrBH+4wxpkUY8FJ1jVyWpRozT/5F\n1XPqbflql2VVIKX1kksuWcuqBaybRwMmYKtWW1HDBJYzWHsCyyxJV5KUrReygn0jcHphkuB+wGca\n8hCmG3vvvTednZ3lwR7tM8aYFqG/yrOtWm1KD1atscBVtmq1H6UJLLvssktp8gp0TWC5WtIxwGPA\n4fnY9aSXoXmkF6KjIE1gkVSawAKewNJqNGW0b7BHq6qNFtbr3h51M8bUk/4qz7ZqtSk9WLU2pfvK\nDB3YqtUWeALL8KORo32DPbJWbbSwXiOF7TRCaIxpfaoqz5KuIClLoyUtIFkcbdUaWoxoxU+Lgldn\n6Alb0oYdHu0zxpgWoZbVNqb1cMhWrSFIK31aFLw6Q0/Ykjbs8Ghfm+LVU4wZevgLgwZglT8takxr\nMG3aNPbcc08efvhhxo0bBzAaf4ShbZk5cyY33HBDebC/AGpMGzPg1TbMkGAJtmoZ0xJccUX3qQOS\nFtmHvX3x6inGDD2sPA8zpk2bRkdHB4sWLWLcuHGcdtppAE+RrFr2YTfGmMGnKaun+AugveO5JKZW\nrDwPM8qtWgDHHnvs6oiwVcsYYxpMK80zGe5zTDyXxNSKfZ6NMcaYxrLQ80yMaV+sPBtjjDGNpbR6\nCqw9z2S6EnuQ55kANwL7SdoszzXZL4cZY5rAsHPbmFBtUf4zDm5QSowxxgx1yueZ0LV6ir+VYEyb\nMuyUZ2OMMaZRePUUY4YeVp6NMcYMCtVG+owxph2x8myMMcYYuzUaUyOeMGiMMcYYY0yNWHk2xhhj\njKmBo48+ms0335ydd955TZikUZJukjQ3/2+WwyXpbEnzJN0raWLhmhn5/LmSZlS4lWlhrDwbY4wx\nxtTAzJkzueGGG8qDTwZujojtgZvzPsCBwPb5dxxwLiRlGzgFmAzsDpxSUrhNe2Dl2RhjjDGmBvbe\ne29GjRpVHnwIcHHevhg4tBB+SSTmAJvmj+LsD9wUEYsj4nngJuCAwU+9qReeMGiMMcYY03/G5I/Z\nADwNjMnbWwHzC+ctyGE9ha+FpONIVmvGjBlDR0dH1003gBN3WdVjoorntgvLli1ri3RbeTbGGGOM\nqQMREZKijvGdB5wHMGnSpJgyZcqaY9+57FrOvK9nNa7ziCk9HmtVOjo6KD5jq2K3DWOMMcaY/rMw\nu2OQ/5/J4U8A4wvnjcthPYWbNsHKszHGGGNM/5kNlFbMmAFcWwifnlfd2AN4Ibt33AjsJ2mzPFFw\nvxxm2oS2ctvw16qMMcYY0yymTZtGR0cHixYtYty4cQCjgTOAqyUdAzwGHJ5Pvx44CJgHvAQcBRAR\niyV9Gbgzn/eliFjcwMcwA6StlGdjjDHGmGZxxRVXdNuXtCgingPeU35uRARwQqV4IuJC4MLBSKMZ\nfOy2YYwxxhhjTI1YeTbGGGOMMaZG7LZhjDGmLak2D6bzjIMblBJjzHDCyrMZ0rhzNcYYY0w9sduG\nMcYYY4wxNWLl2RhjjDHGmBqx8myMMcYYY0yNWHk2xhhjjDGmRjxh0AxrPKHQGGOMMX3ByrNpa/zJ\ndmOMMcY0ErttGGOMMcYYUyNWno0xxhhjjKkRu22UYR9YY4wxZm3cPxqTsOXZGGOMMcaYGrHybIwx\nxhhjTI3YbcOYXvAwpTE949VujDHDEVuejTHGGGOMqZGGW54lHQCcBawLfD8izmh0Gkz9GGx5trpl\na6hZpl0/hxaW59DC8hxaNLv/bLf+qZVoqPIsaV3gHOC9wALgTkmzI+LBRqZjIJQXxhN3WcXMQthw\nKoxDQZ6mC8tzaGF5drXX5e10iXZqry3PoUUryHOgxql2qj/1ptGW592BeRHxKICkK4FDAFf+9sTy\nrEKbNU4tL09bUvrEgOV53xMvVFQ6hwq11M8WKlOun0OLlpdnNQZjZLinF92eaFaZarTyvBUwv7C/\nAJhcPEHSccBxeXeZpIcblLZ+8XEYDSwq7etrTUxMdbqltcDW/YxvoPLsKT0m00t56i3vmiXPauka\n9PrR4vWvGg2vn9DadbRe8ixvp5uRhgKWZ+vSn/wZtvIcDPpaV5tVP1tutY2IOA84r9npqBVJf4iI\nSc1ORy00I629ybOd8q7VaFbeVauflmn/aUWZDhV5DpXnqIXhIM/BohXzZ7jJs12eqdGrbTwBjC/s\nj8thpj2xPIcWlufQwvIcWlieQwvLs41ptPJ8J7C9pG0kvQ74CDC7wWkw9cPyHFpYnkMLy3NoYXkO\nLSzPNqahbhsRsUrSLOBG0tIsF0bEA41MwyDQNi4m1DmtdZBnO+Vdq1H3vKtT/bRM+0+r1c+6p6mJ\ntP1zWJ4NoWH5Y3n2SFs8kyKi2WkwxhhjjDGmLfAXBhuApJmSbivsh6TtBuleE3L8LTcZdKggaYqk\nBYX9t0m6R9JSSR8fhPtZpk1GiR9Iel7S/zU7Pe1GeZ1p0D0vkvSVBt+zW1s/1JD0ZknL8hrFgxF/\nh6RjByNuUz8knSrph3l7UPunZrQdtdCWyrOkTkkrciV+XtIvJI2vfmWf7rGmcBTCOiS9nO9b+u05\nwPtcJOnVHNdSSXdJencfru+UtO9A0tAsmizHY8vCBlJBPw38JiJGRsTZw1mm1WiizNfK0z4qOnuR\nPmYwLiJ2z9d/VtJf87MskHRVIe66txWNpExOpd93m52u/pLr92uFOvmwpKOana5WplIZAFZFxMYR\nsbrZ6TP1oYe6vuUA4iu2fS9I+q2kXfpw/aAZF+tJWyrPmfdHxMbAWGAh8J16RCppvKTfACcA75P0\n7zn8VGBP4BlgHnB4bkR+L+kzkublBnn/QlwHKK3J+DXSTNqe+Hp+ljcA5wI/7cOb/TjgPCXL5x8K\n4TdImivpJkmb5fRI0tk5rfdKmlhI64x8/lxJM2q8d79R+izpVsBi4CvUWY4NZmug3FetTzItlTtJ\nDwJbAh/M4aOAS/NpN7SiLPM9D8jlf56kk6ucPih1d5DZGuiMiOWQ8hg4Etg3P8sk4Oaya2blNmLj\nQlvRKem+Yn2VNCrX05rrawPYgLTW6tPAV3L6ZzXw/nVDUidwIbAKeIhUJ08Czpe0Yx/jasvRnz7W\nzyLvLyvDT/ZyD0lqOZ2iXnWuGe1qTwxAnj1Rs5xrZFZuF0cBI4G7Jd1fOthb/udTbm7l/AcgItru\nB3SSOq3S/kHAI4XtB4GlpGVfPpXDp5AWIf80SQF+Cji0dC1JifssqUM/AXgVWAm8RmpwTwX+Ahxb\nlpYd8/0C2C6fsy7Qke+zLXAMsAzYMV8TwHZ5+yJS51SKb8N8fMu8/xbgFuA5Umd2GbBpPnZpPndF\njv/TwIQcdjXwOLAc+G0hb34JCNgDuCOHjwIezf+b5e3NBlF+6+Z8WgAcAPwp52Pd5JjPPaAgx2XA\nn3J4RwU5TgEWFPaPAv6c7/8o8NFK52bZrAZezvd4az9l+jZgYpbpa/m3PKf1awWZvpivubgVZFkm\nz22B15Xk2ei6W0Xm3e6bw2YCt+XtCTmPZ5DqzSLgc/nYMVm+q3OcpwHfBb7dS56sVcYK6RhdFvZ1\n4OS8fTLwtd7q62D/sjxXAv9cLs9SngHfBJ4H/gocWLh2FPAD4Ml8/Joe6tcOOY+WkF48P1BWJtYq\nB/nY+4B78nW/A/6mcOydwN35uquAK0kv5p2kL7ctKHvOZ4EP5e0P5HQsyenaoUxmJwH3Aq+QJtqP\nB36a43gO+G4t+dOMH32on73V1bJ6MqJQzr8K3E7qh7YDNgEuINXTJ7IM1i3kz+2k+vMCqW99T6V6\nQy99Xz5eUQb52NGk9vv5nK5dc7iAb5Ha1peB+/J+r3WOJrSr9ZZnH+U8pUJ9WXMeSR/6YS9l4tjC\ndUeS2pP78/7uuVysyGXkd8A38rH7clzLgZeAuTktT2QZP0t6oX+mWflf+rXcW2JfkbQh8GFgTg66\ngKTojAR2JlW+ElsA65Msnl8Ezid1ELsBfw98AVg/Is4BTic1wD8H/q2XJBySz4FUuOaRCscbgGci\nfXpzNanyH1LlWdYFppMa3IWlYOA/SdbIHUgNxqkAEXFkjvuISG+LXy9E9ypJIfsAsJekHfL9L4nE\nHGBTSWOB/YGbImJxRDwP3ERSQgaL3Un5tCr/rgQ+RB3lKGmbiLiBLMecP+/oQxqfIXXUbyAp0t+q\nZPmLiH8A/pcuK+MjxeN9kOnHIuLuLNPHgd+TFMSxwI/zda+SGo735Of9dQvIEgqfmY2IV0ny7LWs\nQ/3rbh1kDsk9422kPP6ipB0i4gLgeOD3Oc5TcpqnS/oPSZP6MFJUiUNIL0Pk/0ML4ZXq62CzO6le\nPt2DPCcDD5O+BPZ14IKCxehS0sviTsDmJMWkG5LWI7WZv8rn/BtwmaS35VMqlgNJ7yRZkD8KvBH4\nHjBb0uuVlvq6Jt9/FPAjYGqlh5O0jqQPApsC90l6K3AF8AngTcD1wM9znCWmAQfnawK4DniMpDhs\nlfOolvxpBv2qn33gSNIX8EaS8uQiUvnZjvRCsx9QdJObTFL+RgOnkEblRlWIt8e+L9e3ijKQdAjJ\nEHYYSZ4v07WCw37A3qSXu22Aw3N6q9W5ZrSrPTHY8qwbuQ69nfRSW2I1qXxsTxrNfxPJaAFJkQZ4\nR0RsSDIijSK1/52ksnA06QWmYv1uFO2sPF8jaQnp7fW9wDdy+EpgR0lviIjnI6IotJXAVyNiJanA\njQbOioilkZaIeRAodrYbkSr/HXl/K5KLxCtKvjx357CnCtcsyGGvJ731lnglh1fiU/lZlgHfBr4Q\n2acsIuZFxE0R8UpEPAv8F1D0nw3ga0p+tccVwk+OiBWkjue1/FyVPge6VS/hg0XxftcAnyc1ooMl\nx0qcLWlJ6UdqiNcQEb+IiL/kRvRWUkf/9314xoHIdASp47kDGEN624Zkldw8Iv5EskBvXLimWbKk\nH/dsRN3tL6dFxIqcx3/qKc5p9BmLAAAgAElEQVSI+CFJ6dsfuBV4RtJJZacVy1jpWQL4VVl9HRMR\npTbkaZLMoTmyLN13FV1y+jxwqqR/yccfi4jzc3m+mPSCNyYrGQcCx2f5rcx1p5w9SGX3jIh4NSJu\nIdW/afl4T+XgOOB7EXFHRKyOiItJ7eoe+bceaTRgZUT8mLSOLqQ8/wawlaSXSIaMU4AjI+Jh0gvc\nL3KdXEmyGm8A/G0hzWdHxPzcpu5O6sT/IyKWR8TLEVH0na+YP7Vl/aAwkHJ0TaEMX9PDORdFxAMR\nsYqk6BwEfCLnzTOkF6iPFM5/hi45XUV60Ti4PNIq7WRvMjge+M+I+HNO0xJgkqT7SMrzSJIytjAi\n/kwaUahW55pVFysxGGmpRc594ezcdiwFZgFnlQ5ExF3AJhGxICI6gXNIL6Ww9nMsICnXrwHX5jJz\nPane/00d0tlv2ll5PjQiNiVZo2YBt0ragvQ2chDwmKRb1X2SznPRNdFhRf5fWDi+gi6F5HWkN9RP\nRMSLJL/VOSSrxzeBn0REvXwQv5mfZUOS7+Q3JB0IIGmMpCslPSHpReCHJMWhxNPAx0id1gmkRqUU\nTkQEqfMoKlqtxKGkxu5/GBw59sTHI2LT0o9kZV6DpAMlzZG0ODcCB9E936vRL5lK2pjUWJyby12R\np0myhNSYbNCH9LQSg113K7GKpFwVWY+kqBV5urD9Um9xRsRlEbEvqeE/HviyCnMe6F7GSm3FXnn7\nQOAESXuXxVmqr61ASU7HA+dHxPk5fE0eRcRLeXNjkmWwZJnrjS2B+RHxWiHsMbo6zp7KwdbAiWUv\nveNzfFsCT+T8K8YJaTThOJKRY25+rl0jomQt3rJwLjld8+nekReVlfEkBXlVD8/XU/60I4cWyvCh\nPZxTzJutSfXqqYKMvkcaYShRSU5rTVCr0vf1JoOtgbMK9x9FUrZOBvYluWVsQHrhPY+kTLdKnWsW\ntci5L3w8tx0bkPrWc0kGRfJIz0aSns5yPZ00ytAby0l9XomVpfiaRTsrzwBkC8RPSUMBe0XEnRFx\nCKmyXkPyE+0TeVjxcOCvOW4iotRRB2nIuKSkPkFXhd6Qrk9sbkQaWijxeqp8ejNbOe8n+YSV3sRP\nz/fcJSLeQBqqLha0VfnaZ4Cf0WUp2yI/y1i6FISePgfa6M+EVrrfgnrLMdPnRlHS64GfkF6SxuRG\n4HqqV/C1b94HmeZy9xOStbpkRVlIUqYhyfSZvP0KqVMo0SxZ0t97DkbdLUVdIexx0vBukW0oKE39\nJVtDfkSyYO1c5dwn8n+pvu4OLCy5Y+T/koyb9fneJ+j+Aa1a7zsfGCVp0yrnPQmMV/fJZW8u3aOX\ncjCfNPqwaeG3YURcQVKMtypzj3hzjq+U9tfoyvPy9Gxd2slxjC975mKZmg+8We0zeXCwy1F53rxC\n8usvyegNEbFT4ZxKcqo0Qa23vq83Gcwnuf2U7r9JRGwQEb8gyX8+yW1kCmmOymlUr3Ot9CntRqRl\nOUmfAda4ybyp59MrExGvRcT/klwuSi+Q55Is0ntluZ5Bdx2lyDjSyOtquj/zCNIIUtNoe+VZiUNI\niupcSUdI2iQPv71I97eVWrmA1Km+XGrg1d3X8INAaebobOD9JKH/O8mPZ0eS1WKMpG1IDv6jqeHT\nm5LeTrKUlFZvGElSpl6QtBXwH4VzNyIVrG3z9n6kCVSQ/Gwh+RKVCtlskp+mJO0BvBBpuPhGYD9J\nmynNet0vhw0Wd5LyaUT+fYTku1hvOUJSPieob7PAX0d62XkWWJUtxvv18/59kekFpEkuc0mTQSDJ\n7EN5ezpwbd5eBOzZArKEfn5mdpDqLlSW+VXAJyS9Pd93Esl37sqKMVRP+0xJB0saqeRDeyDJz/eO\nXq7ZSNLI0jZJNveT8qrk8zeDLhn3VF8HmztJ9XKLvsgzp+2XwH/n8rdeuWU9cwfJqv/pfM4UUht6\npaTX9VIOzgeOlzQ558lGJRmQ5gisAj6e4zyMpCSvV8pzkuJVyvMiVwMHS3pPfoE9kaQA/o7K/B9J\nWT8jp2F9SX9XLX+aSMM+A53LwK+AMyW9IdeNt6j7Up2b0yWnfyT5M19fIboe+z56l8H/AJ+RtFM+\ntpWkf8x17jCSonYdqR9/GdiF6nWuGe1qTzRCno8A6+f6tR7Jdatfll6lkaPtSXUKklwfBD6U+8Z/\nI036hvQcr5J0mj1Irn2LSXIq5v/6QHF1scYTTZyt2N8f6S2mtMLEUlJjeARJ6bmB5Gv8IqmQ7RUV\nZo+SOocAJhTCbgO+lMMfyPGvIk1uuzTvzycJeGzhus+R3pxfzeecSfKDPItUCJ8hLXNVOr98tY3S\ndctJFrLTgXXy8Z2Au/Lxe0gNe2mlh21JE9FeJb2Z/ZKuma+3kJSwX+fnOpbUeZxDeuu+D5hUSNPR\n+TnnAUc1QIYH0bWaySuDIMd/zttvzPvPA3fnsA6qr7ZxAkkJW5JlfyV5BY0K53aLr58yfSY/x72k\nmdyl679IsloHaSm0UYV73tIKsizI85Gcns81qe72JvN1SMO2c3P8DwLHFK6fQGHGeLlcKazMkfcP\ny3Ippfc+YGZPZaJQX0u+1A/QtZrHG7NsS/W1JOMe62sD5LmQrlVfXsny+ll5PuRzi+3ZKJKf78Kc\nNz/tQYY7kdrIF7IsPpjDeywH+fgBOWwJSXn6ETAyH5sE/JGu1TauIq3q8CdSXVhJD2WTpEg9mNNz\nK7BTWZktX43gzSSreGkliLMrlZPy/GnWjxrrZ4W6WstqG+XlfBOSdXFBzs8/Ah8p5E9xtY1HgP16\nqHM99n29ySAfO5JUZ5aS2tLFpDp3AamNXZbDXwR+Qw11jia0q/WUZ1/kXJDVU6S+6VP0bbWN0upT\npXb+RVL9W0BaPeoRkm61gtTfzSnkf0c+tprUZk/J1xXzf1GlNDfy589zG2OMMWbQkTSTpBzv1ey0\nGDMQ2t5twxhjjDHGmEZh5dkYY4wZBCRdKOkZdf+62qlKK0jck38HFY71+rVa1e+LcsaYAWC3DWOM\nMWYQyBMml5E+vLFzDjsVWBYR3yw7d0fSx1pKaxj/mrQaBCQf0feSfD/vBKZFxIONeAZjzNq0y1I7\nxhhjTFsREb+VNKHG0w8BroyIV4C/Sip9rRbyF+UAJJW+KGfl2Zgm0dLK8+jRo2PChAlr9pcvX85G\nG23UvAQNEs1+rrvuumtRRPR5Dce+Mlzk2WjK87FZ8qyUFjPwPGmUPMF1tN4sX76cnXfemXnz5jFp\n0qTSMO9LwLOSppOW2zox0odltqLrU/XQ/ctx5V+Um9zTPZW+XHkcwAYbbLDb+PFdy+O+9tprrLNO\n+3trttJzPPLII66fA6SVnqPW9rallecJEybwhz90LeXX0dHBlClTmpegQaLZzyVpwB+KqIXhIs9G\nU56PzZJnpbSYgedJo+QJrqP1pqOjgwkTJvC+971vTb5KmgvsRlre68ukpU2Prtc9I+I84DyASZMm\nxVCUZys9h+vnwGml56hVni2tPBtjjDFDjFWRPzUv6XzSBzug9y/HtcrX7YwxeLUNY4wxppGsV9gu\n/1rtRyS9XunLtNuTvqTXsC8EGmNqo60sz/c98QIzT/5Fj8c7zzi4gakxA6WaPMEybTdcR4cWlufA\n+PKXv8yDDz7IokWLGDduHKeddhrAOEn3kdw2OoGPAkTEA5KuJk0EXAWcULBQzyJ9Dnpd4MKIeKA/\n6bE8TSOZMIT797ZSno0xxph24Qtf+MJavpzHHnvsXyNiUqXzI+KrwFcrhF8PXD8YaTTG9B27bRhj\njDHGGFMjVp6NMcYYY4ypESvPxhhjjDHG1IiVZ2OMMcYYY2rEyrMxxhhjjDE14tU2jDENYygvXWTM\nUMf115iELc/GGGOMMcbUiJVnY4wxxhhjasRuG8YYY4wxwwy74fQfW56NMcYYY4ypESvPxhhjjDHG\n1IiVZ2OMaRHmz5/PPvvsw4477shOO+3EWWedBYCkUZJukjQ3/2+WwyXpbEnzJN0raWIpLkkz8vlz\nJc1o0iMZY8yQwz7PxhjTIowYMYIzzzyTiRMnsnTpUnbbbTeA9YGTgZsj4gxJJ+f9k4ADge3zbzJw\nLjBZ0ijgFGASEMBdkmZHxPONfypjjBla2PJsjDEtwtixY5k4MRmPR44cyQ477ADwOuAQ4OJ82sXA\noXn7EOCSSMwBNpU0FtgfuCkiFmeF+SbggMY9iTHGDF1seR5mzJ8/n+nTp7Nw4UIkcdxxxwFpWBi4\nCpgAdAKHR8TzkgScBRwEvATMjIi78zUzgM/nqL8SERdjjKkLnZ2d/PGPfwRYBmwbEU/lQ08DY/L2\nVsD8wmULclhP4Wsh6TjgOIAxY8bQ0dGx5tiYDeDEXVb1mMbiuWZtli1b5jwyZghi5XmY4WFhY1qf\nZcuWMXXqVL797W8zderU14rHIiIkRb3uFRHnAecBTJo0KaZMmbLm2Hcuu5Yz7+u5m+g8YkqPx0x6\nubjkkku47rrr2Hzzzbn//vsBGyuMaXfstjHM8LCwMa3NypUrmTp1KkcccQSHHXZYKXhhrnfk/2dy\n+BPA+MLl43JYT+GmwcycOZMbbrihPLhkrNgeuDnvQ3djxXEkYwUFY8VkYHfglNKkUWNM47HleRjT\niGHhgQwJg4eFa8FDw0OHiOCYY45hhx124JOf/GTx0GxgBnBG/r+2ED5L0pUkxeqFiHhK0o3A6QUF\naz/gMw15CNONvffem87OzvLgQ4ApeftioIM00rfGWAHMkVQyVkwhGysAJJWMFVcMcvKNMRWw8jxM\nadSw8ECGhMHDwrXQ0dFBMV9N+3L77bdz6aWXsssuu7DrrruWgjchKc1XSzoGeAw4PB+7njTEP480\nzH8UQEQslvRl4M583pdKipdpCca0ow97qxg7bDAwzcbK8zCkt2HhbLWqdVh4Sll4x6Am3PQJSZ3A\nUmA1sCoiJvXH19I0jr322otkdOxC0gsR8RzwnvLzs4XyhEpxRcSFwIWDkU5TP9rJh31mtc85N8jY\n0UyDwdFHH20fdmPluZyh/q13DwsPO/aJiEWF/T5NDG10Yo0ZJthY0abMnDmTWbNmMX369GKwJ9wP\nM6w8DzM8LDzs6ZOvZWFouSEM9ZdXYzI2VrQp9mE3YOV52OFh4WFFAL/KQ8Lfy8O5ffW17KY89+ZP\nCbVNAh0I7ejnaP/M4c20adPo6Ohg0aJFjBs3DmA0NlYMNZriwz7QtmWwfdhrjb8d28iqyrOkC4H3\nAc9ExM45zP49xrQ+e0XEE5I2B26S9FDxYH98LXvzp4TaJoEOhHacQOoJncObK67obkyUtMjGiqFL\nI33YB9q2DLYPe63xt2MbWcs6zxex9vq9XqPSmBYnIp7I/88APyPVvb6uF2yMMaZ3vA77MKOq8hwR\nvwXKh4f8QQ1jWhhJG0kaWdom+UjeT5evJaztazldiT3IvpYNTrYxxrQjfW1XbwT2k7RZNiTul8NM\nm9Df8dW2XKOyFpqxjmU7+vuYlmcM8LPkScUI4PKIuEHSnfTB19IYY0wX9mE3UIcJg+20RmUtNGMd\ny3b09zGtTUQ8CryjQniffS2NMcYk7MNuoDaf50rYv8cYY4wxxgw7+qs827/HGGOMMcYMO2pZqu4K\n0oLeoyUtIK2aYf8eY0zD8UdUjDHGNJuqynNETOvhkP17jDHGGGPMsKK/bhvGGGOMMcYMO6w8G2OM\nMcYYUyNWno0xxhhjjKkRK8/GGGOMMcbUiJVnY4wxxhhjasTKszHGtBBHH300m2++OTvvvPOaMEmj\nJN0kaW7+3yyHS9LZkuZJulfSxMI1M/L5cyXNqHArY4wx/cDKszHGtBAzZ87khhtuKA8+Gbg5IrYH\nbs77AAcC2+ffccC5kJRt0pr8k4HdgVNKCrcxxpiBYeV5mFHJqgWsa6uWMa3B3nvvzahRo8qDDwEu\nztsXA4cWwi+JxBxgU0ljgf2BmyJicUQ8D9wEHDD4qTfGmKFP1Y+kmKHFzJkzmTVrFtOnTy8GjwWu\niogzJJ1MsmqdRHer1mSSVWtywao1CQjgLkmzcydtjKk/YyLiqbz9NDAmb28FzC+ctyCH9RS+FpKO\nI1mtGTNmDB0dHV033QBO3GVVj4kqnmvWZtmyZb3mkaROYCmwGlgVEZNy+3oVMAHoBA6PiOclCTiL\n9BXfl4CZEXH3YKbfGFMZK8/DjL333pvOzs7y4E3pbtXqICnPa6xawBxJJavWFLJVC0BSyap1xWCn\n35jhTkSEpKhjfOcB5wFMmjQppkyZsubYdy67ljPv67mb6DxiSo/HTHq5KOZnD+wTEYsK+yUXnZqM\nGXVPtDGmKlaeDcCIVrRqgS1btVDNumWGBAsljY2Ip/IL7DM5/AlgfOG8cTnsCdJLbjG8owHpNAPn\nELpkV9WYUWi7jTENwsqz6UYrWbXAlq1aqNG6Zdqb2cAM4Iz8f20hfJakK0lWyBeygn0jcHphkuB+\nwGcanGZTnQB+ldvc7+X2sq8uOt2U58F0w2kVY4cNBqbZWHk2AKts1TKmNZg2bRodHR0sWrSIcePG\nAYwmKc1XSzoGeAw4PJ9+PckHdh7JD/YogIhYLOnLwJ35vC+V3KxMS7FXRDwhaXPgJkkPFQ/2x5gx\nmG44M0/+Ra/HG2XssMHANBsrzwZgCbZqGdMSXHFF96kDkhZFxHPAe8rPzUP4J1SKJyIuBC4cjDSa\n+hART+T/ZyT9jLSsYF9ddIwxDcZL1Q0zpk2bxp577snDDz/MuHHjuOCCCyAN+71X0lxgX5ISDcmq\n9SjJqnU+8K+QrFpAyap1J7ZqGWNMn5C0kaSRpW2SEeJ+ulx0YG1jxvS8hOgeZGNGg5NtjMGW52FH\nuVUL4Nhjj10dEbZqGWNM4xgD/CytQMcI4PKIuEHSnfTBRccY03isPBtjhgwTqvlknnFwg1JiTO9E\nxKPAOyqE99lFxxjTWOy2YYwxxhhjTI1YeTbGGGOMMaZGrDwbY4wxxhhTI1aejTHGGGOMqRErz8YY\nY4wxxtSIlWdjjDHGGGNqxEvVGWOGDV7KzhhjzECx8myMMcaYpuOXW9MuWHk2xpiMO29jjDHVsM+z\nMcYYY4wxNWLl2RhjjDHGmBqx8myMMcYYY0yN2OfZGGNMv7CPuDFmOGLl2RhjasTKojHGGCvPxvSC\nlSVjjDHGFGm48izpAOAsYF3g+xFxRqPTYOqH5Tm0sDyHFs2Wp18+60uz5Wnqi+VZnVZtQxqqPEta\nFzgHeC+wALhT0uyIeLCR6WgmlQrCibusYmYOb6fOxPIcWlieQwvLc2hheQ4tLM/2ptGW592BeRHx\nKICkK4FDABeW9sTyHFpYngOk2ssxNPQF2fIcWlieVahmpYSWMlANWJ73PfFCt7alnBZ61iFHo5Xn\nrYD5hf0FwOTiCZKOA47Lu8skPVw4PBpY1FPk+lqdUtkLg3GPjxeeqxHPUIGt+3ndoMoTmpYfNdMi\n6SvPx2bJs1Jahj0fL8uTfpSZQZMnDLyODoQWqT+DSaX8a1l5DlQegy3PQvz9LpeDkEbLc+Dxt508\nW27CYEScB5xX6ZikP0TEpAYnadAZqs8Fw1OejaaR+dibPBudlnah1fPEdXTwaEb+DQd5DpXnqAXL\nszVp9EdSngDGF/bH5TDTnlieQwvLc2hheQ4tLM+hheXZxjRaeb4T2F7SNpJeB3wEmN3gNJj6YXkO\nLSzPoYXlObSwPIcWlmcb01C3jYhYJWkWcCNpaZYLI+KBPkTR43Bxm9OWz2V5tgx1ycc6yLNuaRli\nNCVPLM+WoG75Z3l2o+2fw/LsRts9hyKi2WkwxhhjjDGmLWi024YxxhhjjDFti5VnM6yRtEzSts1O\nhxkYkmZKuq2w/3eS5mb5HjoI95siaUG9420XJL055+26/bj2VEk/HIx01XDviyR9pRn3NsZ0UWtd\nlPRZSd9vRJr6Qtsoz5IOkPSwpHmSTu7hnI9IukPScknP5O1/laRGp7caknaXdIuklZJWS3pJ0mXN\nTlejqEWevVzbJzn3VkkjYuPSIvU13numpJD04b6kud5IGi/pN5IelPSApH9vcnr6Lc9CHJ2S9i0L\n66YU94EvAd/N8r1GUoekl7PC94Kk30rapQ9pC0nb5e3xwLeAMcW8lzRK0k1Zab9J0mY5XJLOznlz\nr6SJhXhn5PPnSprRj+ccFAryXFnsuHLdex7YJuft6hzeIenYpiW4jJye5yW9vs7x/ibnyWuFtudT\nrST3anVR0uslXZWP3yFpQj/usVZdreGaNXWoLHybnJ/nloVXbeOUXmJfkHRP/n2xr8/S6vQmzyyH\nAwcqzx7u+3pJ/ynpcUkrcln9VE/9bA3xdZMnsEPh2JRcBlbkcrI6y/WLEXF6RNTUtkjaVNKFkp6W\ntFTSI8U8y3Evz/3AMklL+vMsAEREy/9IzvR/AbYFXgf8Cdix7JwTgYXAh4CRgIB3ApcBr+/j/UYM\n8vPsCSwDvgL8Q07r3wNLy5+rhrgErNNsGdVbnr1c2yc553tdBHylTmn/DfAc8Isml6GxwMS8PRJ4\npK9lpxXkWRZPJ7BvWdhM4LYaru12HjCvGBfQARxbSO+XgHv6kLYAtivk/b+QPmqwJu+BrwMn53NO\nBr6Wtw8CfpnL6h7AHTl8FPBo/t8sb2/WDBn2Is/OvL0jMCOX/b+tcM2a/K0h/lOBHw5i+icAq4HF\nwD+WHet3W5DbnsXAf5C+Aldqex4EPtcKcq+lLgL/CvxP3v4IcFU/7rNWXa3hmjV1qCz8lFyuFlNo\nw6mhjQOmANcNVllq9q+aPLMczhqoPHu492zg/4CdSYtL7AHMBf6rn/GVy/OFQrqnkNrTAckT+AFw\nda5X6wBvBz5UrQz2617NLhw1ZsiewI2F/c8AnynsbwIsB6b2EsfBwB+BF0lf9Tm1cGxCztRjgMeB\n3+bwHwFPZyH/FtipcM0bgZ/n+O4kKcLFzvvtwE25QXgYOLxw7DbgnAppvJb0nfvNgOuAZ4Hn8/a4\nwnkdwFeB24EVwHYk5eFRkgL+V+CIZsutv/Ls5bpa5HwRcC5wfT53X3rpMEuVifRlp6eBdQvHPgjc\nW9jfGngNmAqsArYoHCtV/pNyPJfm8PcB9wBLgN8Bf1O45mRSw7iU1AF/cAB5ei3w3naSZ4V4OulF\nee4tv8rO+0uW0wrSS+rrKVPuSMrgq4X93YHfZzk9BXwXeF0+9ttcTpbn+D5ckPeJwCukzv8pYGy+\nZizwcN7+HjCtcK+H8/FpwPcK4d3Oa9avKM8sk+8DPyN9AWxSDp+Q82QEqS1aDbyc8+e7+Zyd6GoD\nFwKfzeGnkjq4S7IsHyjFm49vCfyE1P79Ffh44Viv1+ZzvkhqG/+Lso6Y1Bb8T07XUuBWYOt87Fzg\nmxXq1ScptD352e8vl2feviqXoeuBlcBXGyl3aqiLpNUd9szbI7JcNdC6msP/hfTiupikfG3ZUx3K\n4SLV14/lMvKhsvgCOIGktC0n9Y/FvvVx4K7C+T328+34qybPLIc7K8izJzmcBnwnb6+X8/QbeX8D\nUh0eBbwnb48vS89kUl3ftlI5oOzFmN51qMeBy/L2FHpQnotx0tXuzMjXLyK/uObj9wOH9pKfdVOe\n28Vto9JnLLcq7O9J6iCv7SWO5cB0YFNSBfuY1vaFfDdpKGH/vP9LYHtgc+BuknWzxDk5zi1IgpxR\nOiBpI1Llvjxf+xHgvyXtKGnDnN4fF2+ch1reCdxBemP6AUlZezNJCfhuWVqPJH2ycySpkzkbODAi\nRgJ/S1LYWpVq8uyJWuQM8E+kDn0k6UWlKhFxB0me/1AWz+WF/enAHyLiJ8CfgSPKotmC1PBsDRwn\n6Z3AhcBHSS9b3wNmF4aS/0IacdiE1Kj9UNLYWtJbpKzsNIP+yrOv1JRfEfEWUsP6/kiuBa8Ujyut\nqXoEMKcQvBr4f6TPxO5J6jz+Nce3dz7nHTm+q/L+FqT6uZBUF7cgdTiQOowxebun/GlUvvWV8nS9\ng9Qmvici/lB+ckR8DvhfYFbOn1mSRgK/Bm4gKcPbATcXLvsAcCWpPZ5Nbt8krUMySvwpp+M9wCck\n7V/t2gLTSW31ZcD+ksaUHT8C+DJJ1vfQ1a5fAXy4NCyd3S/2y/fqre0ZExFP5e0VpPL5VZKSWnzm\nRsi9lrjXnBMRq0iKzRsHemNJ/wD8J3A46SXhMVLe9VaH9iJ9HORK0kvRDNbmUNJI42LgPrr3rV8C\n3inpIUm/BN5E9X6+nahFnqPpLs9XgTOoIAfSy+KUvP0uUjtVks2epBf+xaSXlDsionjvUj+5gFQv\na6GiDpX7rFFU/ijMnpL+JOmXknbqId69gLfldHxRUskFZA7wVUlHSdq+xjT2i3ZRnqsxGliUCw4A\nkn4naUn2odk7Ijoi4r6IeC0i7iU1lO8ui+fUiFgeESsAIuLCiFiaO99TgXdI2kRpksxU4JSIeCki\nHgQuLsTzPqAzIn4QEasi4o8kS8o/0jWcUGpskbRxPv6JiHgxIp6LiJ/kuJeSGuLytF4UEQ/kZ15F\nsrTtLGmDiHgq+r5eZDtQVc45+NqIuD3L+uXKUVXkCpJViNz5H5TDSkynS5m+PO8XeY1UJl7JZeg4\nkoXpjohYHREXk6yUewBExI8i4smczqtI1pXd+5DetcpOX65tUa7J8lyS/dH+u3SgDvl1do5zKTCL\npICX4r4rIubk+tpJetEpr3PlrCQ14p/IL1RBatCJZOaIPqStldmZ1Mne14dr3gc8HRFnRsTLuR0t\nvtzdFhHXR/KZvpSkoEPq0N8UEV+KiFcjzUc4n2SAqHYtkvYivbxeHRF3kV64/qksbb+IiN/mdv1z\npM56POkFIEgvaJAUtt9HxJP00vYAmxTaHkgjGreXtmvPsrbnCNJaxXfnvP0MKW8n9HLNDOCXEfE8\nqU09QNLmZed8i2SE+HdSnVzTt5IU7h+Q2unvkKyQ1fr5oc7GwOU9yOH3pA+zvJGkNF8AbJX7kXeT\nlGtI5f2p8ogzT5FeUsbfsCEAACAASURBVKrSgw5VGln6P7rXjy2Ba0iuKluTXmyv6SHq0yJiRUT8\nifSiXWoD/o2koM8CHsx+4AeWXXt3oY85u5bnqES7KM/VPmP5HDBa0pqPvkTE30bEpvnYOpImZ2f1\nZyW9ABxPKiBF1rxlSVpX0hmS/iLpRdLwBPmaN5GGR+ZXupYk+MllSsARJMvU8yQla2y+z3qkgnRZ\nRPw0h20o6XuSHsv3/i2wqbrPbF9zv4hYThpKPh54StIvJL29Uka2CP39LGlVOefg+ZUuroHLgcOy\nZfgw4O6IeAzS6g3ANnS9wV8O7CJp18L1z5Yp61sDJ5aVg/GkRgJJ05UmuZSO7czaZbJHKpWdJlHP\nz8weGhGbln5k6y8MPL9Iw/+bkoYn3wf8WNLf5LjfKum6PNHkReD0KnGvSxpyLub9apIlmmwRfyaH\n95Q/rfp53vJ0XUvqkL9fssrWwHiS4toTTxe2XwLWz/V6a2DLsjrzWbqs+L1dC0kZ+1VELMr7l7O2\nNbPYdi4jWTS3zC88V5JfoElKd8kq3Vvbs4qusrIByS0BmiP3WuJec05+nk1IzzdQtiRZOYE1efsc\nPVjVJW1AMihdls//PWnEqPxl5zN01bNufWs+/8MkF7rrgY0k3Valn28napHnIrrLc33godLBohyy\nUecPJEV5b5Ky/Dvg7+iuPC8i6ygVGJuP90ovOtSVJJk/XnbJk8W2PyI+Q3It2bBC9OVtwMb5WVdE\nmmC4G2k05WrgR5JGFc6fWLjHx6s9R0+0i/Jc7TOWvydZ9A7pJY7L8zXjI2ITkt9beUdQtBT9U45v\nX1LjMiGHi+QmsYpUkEsUC/h84NaygrBxRHwsIl7K6Z2aO6ILgD9HxH8Vrj+RZMGaHBFvoGtYpZje\nblatiLgxIt5LKtgPkaw1rUp/P0tai5yhnxa/PILwGHAga7tszCDl/z2SnqbLRaLYMZffdz7J57FY\nDjaMiCskbU2S0SzgjbkTvp+1y2RFeik7zWDQPzM70Pwqkq1S/0vyCdwvB59Lqjfb5zr32Z7iznn/\naWBlWd6/VIhvBl1D/LOB6UrsAbwQaZj/RmA/SZupy0Xgxr4+zyCwRp55/12kIeC/pzASUEalst+f\nJSDnA38tqzMjI+KgahdmZexw4N35JehpkivOOyS9o3Dq+MI1G5OGj5/MQVcAH8rlbTLp5RR6b3te\nBg7I29uRfJuhOXKvpS7Opqvd+hBwS35xGChPkpRbYI374hvp+cXgg8AbSC6NJXltVUpb4UVtXqGe\ndetbSf7PIyPiY5J2Jxm2fkLv/Xw7UYs8f093eS6gdzncSnJPfGeO/1aSW9buJEMdJJeryUojMhTi\nmkwyEJSU7OV0V263KGz3pEP9pac+S9IWJblnea5Dalf7TB6JPR3YiGT4qittoTzn4ZnSZyz/TBqS\ne6BwfAlpCPa/JX1I0khJ62Sr4Eb5tJHA4oh4OQul/O22nJF0TQTakCSE0v1WAz8FTs1W4rfTfQj/\nOuCtko6UtF7+vUtdfjmfJk1w+i7Jd/kflHy2npd0UL73CmBJfmM6pbeEShoj6ZBcSV4hWT5eq/J8\nTaOaPHu5rhY598S6ktYv/F7Xw3mXk4YH9yZNdkDS+qRO+Thg18Lv34B/KlqjyjgfOF5p1EOSNpJ0\nsJJLyEYkhePZfI+jSJbUWvk7uspOaZmmqgrGYNBfefaRgeZXNyTtSZo0WErnSNIko2W5Pn+s7JKF\ndCmDf0dSeF5flvcvABMlzSV1GGfk868nTeadRyoTJV/qxSTf2zvz70s5rKmUyXMrkrLSQfIvPEDS\ntypcVswfSG3gWEmfUFryamTueKvxf8BSSSdJ2iBbr3aW9K4arj2UZP3fka46ugPJHaPYPh8kaa/c\nBnwZmBPZtzOSi90i0iTJG3ObU2x7LiNNSHubpAWSTs333C3LfSzJkgdNkHtPdVHSlyR9IJ92AfBG\nSfNIkyH7tbQksF6xTSW9eBwlaVel0bvTSX6znfn88jIyg+SOsQtd8vo70svOLnkbksvBPZLuIQ3z\nT5T0A6WRt8OBeZIeIs37WUrf+vmWpkZ5/hp4k6S/kAxvX6R3OdxKqg8PRsSr5MnUpJfWZ/N9f03y\n1/+JpJ1yPdzj/7N37uFWVeX+/7xKpiEJiBKISZYZqElIasUxLG9pvygpyywhNeuYdUor8XTxkhl6\njqWWp5OdOHgL62Smqamk7lN68hJh3g3EbYCgIRfZqAX6/v54x2TPvdh7rbX3Xvf9/TzPetacY8w5\n5pjjHZd3jPmOMYArgcvdPesg3g98LOk4kwjlPaNQh5qd3N+RZPkB4I1m9tl0TLr/ITP7MyHPvLlW\nSczsG0nX2irlyX8hJvA+XuLW3uMNMKO0Uj/CNOJeoqfyN2J08ERiiZcPE6OK64iK/QdsPoNzUC6s\nbYmRo3XpvmPpulzVDsCNdK62cR5wW+7+3ZP/34jMczswIee/L2FMv5b4bHgPcGzyG01k6A5ieZ7P\n5OPH5isHjCIKxFoio7RRp2XLGkDOcyhYWSO5ecEvW5mhy+xbolf9Crml6IgCvBx4VUG42yTZvp80\nW7ibuB6W8ke2isP/ECMlELbsq4jG+rtJhmUt99WKP0qvttFjerH5UnVdwkplIlsNooNQaL6U8z+A\nGHnuIJStswvC+2yS3xqiwd5M3t3Fv9l/3aTjG4jRv7kFddI7iLpqNXBxctuTaIBXE59Zs2X8zqTr\njPyxBWGNTuGvSPfencWh2L3E5MQLunmHo1JYg+i62kYHMdL2hoLrv5HC/Eg3YfVY9yT/OVRoWcxG\n/qV8UVinnpPKyROpnBauEpUvQ9OJr7d7dRP2TaRVT+hmdQSKtK0Uaedb8ddHOWxLzNc4I50bYWL2\nw4Kwtyb0miXpeifsyvPLCe6aykBHksnFdOpVpXSoTWWFHtrP5HcmxXW1Njrbga8TXySfT+/eRm5p\nze7yU19/lgIU/cTMziPsrgrt64QQQgghmhYzu4zo2B7hMWI9oGkKs41GxMzeYmZvTZ/j9yXWiL62\n3vESQgghhKgwJxAmIhNLXTgQ0MhzH0k2eHOJntgzwKXALFeCCiGEEEK0LFKehRBCCCGEKBOZbQgh\nhBBCCFEmPS2x1RCMGDHCx44du+l8/fr1DB5cakUyUYrCdJw/f/5Kdy9rx6D+UCjPRqFR81Vf41VP\neTZqWjYT9SqfMHDq3Hq+V73k2aqyrBblppfKZ/NQTnqVLc96L7VS7LfPPvt4njvuuMNF/ylMR+CP\nXgd5NgqNmq/6Gq96yrNR07KZqFf59AFU59bzveolz1aVZbUoN71UPpuHctKrXHnKbEMIIYQQQogy\naWizjUZk7Mwbi/q3zzqiRjEZGCi9m4sHl61lRhGZSV4ij8p3bVF6txaqb+uHRp6FEEIIIYQoEynP\nQgghhBBClImUZyGEEEIIIcpEyrMQQgghhBBlogmDoqnRBBghhBBC1BKNPAshhBBCCFEmUp4HGMcd\ndxwf+tCH2HPPPfPOW5rZPDNbmP6HAVhwsZktMrMHzGxidoOZTU/XLzSz6bV+DyGEEEKIeiDleYAx\nY8YMzjvvvELnUcBt7r4bcBswM7m/D9gt/U4EfghgZsOBM4D9gH2BMzKFWwghhBCilZHyPMA44IAD\neO1rX1voPBS4LB1fBnwwHU8FLk+7Vt4NDDWzUcChwDx3X+Xuq4F5wGHVj70QQgghRH3RhEEBMMjd\nl6fjFcDIdLwTsCR33dLk1pP7ZpjZicSoNSNHjqStra1XETt1r429ur6Qcp7X0dHR63jVgkaNlxBC\nCDGQkfIsuuDubmZewfAuBS4FmDRpkk+ZMqVX9xfberQc2o8p/by2tjZ6G69a0KjxEkIIIQYyMtsQ\nABuTOQbp/9nkvgzYOXfdmOTWk7sQQgghREsj5VkArAGyFTOmA9el4+uBY9OqG/sDa5N5xy3AIWY2\nLE0UPCS5CSGEEEK0NDLbGGAcffTR3HrrrTz//POMGTOGs846C2A5cLCZHQ88BRyVLr8JOBxYBLwA\nfArA3VeZ2beA+9J1Z7v7qlq+hxBCCCFEPZDyPMCYO3fuZra0J5xwwsvu/t7Ca93dgc91F467zwZm\nVyueQgghhBCNiMw2hBBCCCGEKBMpz0II0SAsWbKEL33pS4wfP5499tiDiy66CIiNibQLqBBCNAZS\nnoUQokEYNGgQ//zP/8wjjzzC3XffzSWXXAKwNbHrp3YBbTKWLFnCgQceqM5QiyB5igwpz0II0SCM\nGjWKN7/5zQAMGTKEcePGAWxF7PapXUCbjEGDBnHBBReoM9QiSJ4iQxMGhRCiAWlvb2fBggUAHcCu\n9dgFtNq7XJbaQbRaz6717p3Zs3bYYQcWLlyYdYamJO/LgDbgNHKdIeBuM8s6Q1NInSEAM8s6Q3Nr\n9hKCUaNGMWrUKKCzcyt5DkykPAshRIPR0dHBtGnTuPDCC5k2bdoreb9a7gJa7V0uS+0gWs4OoX2h\nHrt3tre3s2TJEqhTZ6ijo4NT93q5aBxr2aFodEp1sFasWMHdd98NdezcjtymeAdU8uxKJTvNUp6F\nEKKB2LhxI9OmTeOYY47hyCOPzJyfMbNR7r68F7uATilwb6tqxEWPNEJnqK2tjQvuXF/03mp1VpqR\nYh2sjo4O3v3ud/PDH/6wrp3b7191HRc82LMaJ3l2pZKd5pI2z2Y228yeNbOHcm4yjhdCiArj7px/\n/vmMGzeOU045Je91PdoFtCnZsGFDj50hgF50hrpzFzVG8hRQ3oTBOWw+0UTG8UIIUWHuuusu5s2b\nx+23386ECROYMGECwHbALGIX0IXAQekcYhfQxcQuoD8GToLYBRTIdgG9D+0CWhfcneOPP16doRZB\n8hQZJc023P13Zja2wFnG8UIIUWEmT57MHXfc0eXTopmtdffnAO0C2mTcddddXHHFFey1115ZRwg6\nO0M/N7PjgaeAo5LfTcDhRGfoBeBTEJ0hM8s6Q6DOUF2QPEVGX22eR7bizO9yqNfs8ErSCOkohBCt\nzuTJk4n+TSfqDDUvkqfI6PeEwVaa+V0O9ZodXkkaIR2FEEIIIZqRvm6SIuN4IRqA4447jh133JE9\n99wz77ylJvQKIYQQ1aGvI8+ZcfwsNjeOP9nMriYmB65NSyvdApybmyR4CHB636MthACYMWMGJ598\nMscee2zeeRTwM3efZWYziQm9p9F1Qu9+xITe/XITeicBDsw3s+vTznQtxdhSX45mHVGjmAghhGhW\nylmqbi7wB2B3M1uaDOI181uIBuCAAw5g+PDhhc5D0VbOQgghRFUoZ7WNo3vwknG8EI3JoHpM6IXG\n3/GqGSb8akKvEEI0NtphUIgWppYTeqHxd7xqhgm/mtArhBCNTV8nDAohGpeNmtArhBBCVAcpz0K0\nHmvQbldCCCFEVZDZhhBNzNFHH01bWxsrV65kzJgxnHXWWQDLiQm92u1KCCGEqDADTnnWUlU9Y2bt\nwDrgZWCju09Ky5j9DBgLtANHuftqMzPgIkIZewGY4e5/qke8BzJz526+w/0JJ5zwsrtrQq8QQghR\nBWS2IQo50N0nuPukdD4TuM3ddwNuS+fQdc3gE4k1g4UQQgghWhopz6IUU+ndmsFCCCGEEC3LgDPb\nEEVx4Na0tNmP0rJkI3u5ZvDynFvJdYFLUWpd3lKU87xGXVe3UeMlhBBCDGSkPIs8k919mZntCMwz\ns8fynn1ZM7jUusClKLUubynKWbe3UdfVbdR4CSGEEAMZmW2ITbj7svT/LHAtsC/wTC/XDBZC9IPz\nzjuPHXfckT333HOTm5kNN7N5ZrYw/Q9L7mZmF5vZIjN7wMwm5u6Znq5faGbTu3mUEEKIPiDlWQBg\nZoPNbEh2TKz1+xCxNnBv1gwWQvSDww47jJtvvrnQuVcTd9MqOWcA+xGd4DMyhVsIIUT/kNmGyBgJ\nXBsr0DEI+Km732xm9wE/L3fNYCFE/9h7770ZPnx4ofNUYEo6vgxoA04jN3EXuNvMsom7U4B52Xrd\nZjYPOAzYfG1DIYQQvULKswDA3RcDe3fj/hzQqzWDhRAVp7cTd3ty34xik3qrPWm11ITgaj1bk3GF\nEP1ByrMQQjQRfZm4WyK8Hif1VnvSaqkJweVM+O0LmowrhOgPsnkWQojGp7cTdzWhVwghqoSUZyGE\naHx6O3H3FuAQMxuWJgoektyEEEL0E5ltCCFEA/Gtb32LRx55hJUrVzJmzBiAEcAsejFx191Xmdm3\ngPvSdWdnkweFEEL0DynPoqUZW8qmctYRNYqJEOXxjW98o4s9rpmt7MvEXXefDcyuUjSFEGLAIrMN\nIYQQQgghykTKsxBCCCGEEGUi5VkIIYQQQogykc1zjZENrhBCCCFE86KRZyGEEEIIIcpEyrMQQggh\nhBBlIuVZCCGEEEKIMpHyLIQQQgghRJlowqCoG6UmTwohhBBCNBoaeRZCCCGEEKJMpDwLIYQQQghR\nJlKehRBCCCGEKJOmsnl+cNlaZhSxk9UGI6K3jJ15I6futbHHfKU8JYQQQog8GnkWQgghhBCiTKQ8\nCyGEEEIIUSZSnoUQQgghhCiTmivPZnaYmT1uZovMbGatny8qi+TZWkiercVAl+fYmTd2+3tw2dqm\nXGd+oMuz1ZA8m5eaKs9mtiVwCfA+YDxwtJmNr2UcROWQPFsLybO1kDxbC8mztZA8m5tar7axL7DI\n3RcDmNnVwFTgkRrHo2kpNVpS49UhWl6eDZbe1abl5dkIlMpTcw4bXKlHSZ6tRdXlOcDqu3qj8tnE\n1Fp53glYkjtfCuyXv8DMTgROTKcdZvZ4znsEsLKnwO28/kewv2E0yf2F6bhLHx/XX3k2BF8oka+K\nUYk8V4S+xque8qx6Ga0mjRC/A8+rXfmE/tW51aZa8sjKfJ3kXS959luWjVA+aki56dWw5XOAyasc\nypFpWfJsuHWe3f1S4NLu/Mzsj+4+qcZRajlqmY7F5NkoNGq+asR4lZJnI8a52ah1Gg7EOrdV3wt6\nlmcrv3M1aJT0Gojls1pUMr1qPWFwGbBz7nxMchPNieTZWkierYXk2VpInq2F5NnE1Fp5vg/Yzcze\nYGZbAR8Drq9xHETlkDxbC8mztZA8WwvJs7WQPJuYmpptuPtGMzsZuAXYEpjt7g/3IoiG/vzfRFQk\nHSsgz0ahUfNVTeNVIXk2alo2E41UPltVnk33Xmo/a05V00vlsy5ULL3M3SsVlhBCCCGEEC2NdhgU\nQgghhBCiTKQ8VwAzczN7U73uF+VhZv9pZt+o4/PnmNk59Xq+6B2l5KVy21pInvXHzM40syvT8dgk\nk5qvCmZmU8xsaa2f24rUU6bVlGPTKM/FtrE0s3Yz+4eZjShwX5AENdbMxpjZNWa20szWmtlDZjYj\nd+3xZvaYma0zs2fM7CYzG1KhuI8ys5+Y2fIU/mNmdpaZVWw3hDLj0W5mD5rZ/Wb2x1o+u9rk84CZ\n7Wxmd5jZI2b2YpYHgBXAZ9P7329mh+fuPz3lrcfN7NCce5bvlqTwt+3m2QuS7Vo5nFwoAzMbbmbz\nzGxh+h+W3M3MLk7xesDMJuaeOT1dv9DMpvcp0SpIsfLZz3BLlu0S929lZheY2VIz60jhXVip+FWK\ngjz7sJn9S53js5k8zWxGyrsvmNkKM/uhmQ2tQVzaUznuSHXznO7KYRnh9DmNS+Wjgjhmv9G9jWO1\nKFU+6yXb3mJmh5rZ71I7+jcz+18z+0DBNd3KuZL1rJntk9JrUbrXij2jCulQsr5tIpm+38zuNbP1\nZvacmV1pZjv14v7ZZvasmT2UcxtuZvOAK4ER/ZF1j7h7w/8IY/ongF2BrYA/A+Nz/u3A48Dnc257\nJTcHxgJ3ABcCg4mJkm8D3peufTfwDPC2dD4cmA4MKTN+DrypB7/hKX4/BcYmt52Bi4C3lrq/wunY\nDoyotzyr+G6PA58HRgETUx74S0rfg4AzgS93c+/4lKdeDbwh5bUtu8l3LwH/WnDvnsDfge3LiOMc\nYE2hDIDzgZnpeCZwXjo+HPgNYMD+wD25PLU4/Q9Lx8PqmPZFy2el5Jpz61K2S9x/BvC/wOiUjmOB\nY8t89hzgnCL+FSu3WZ5Nx0NSvq1IGlZInuenOvIw4FUpHW8iVgzYqsrxaQcOSsc7AQ8Bs/oQzphi\naVxMnqXyUT6OjfYrVT6BU2shW2BQGdecCVyZjscmmQxK5x8GngdOALYjBv/eDfy4IIxuyxK9qGeB\nKcSycd3Ws8C96VpL92a6RLfPqKU8m1SmHwe2AV4HzE5pPbTMOBxAtPcP5dzOT+k/BVhbTNbJvddt\nat0LdpmJ8w7gltz56cDpufN24OvAfTm3fwe+Rqfy3AFM6CH8LwO/KvL8NuCE3PkM4M7cuQNfSAm+\nEvg3YIvkdw7wYHbeQ/ibKm3gCGBBylBLgDNz121N9KSeI5Sw+4CRuTgtBtYBTwLHdPOcdlpbeS6W\nBz4B3A/8NvmNAG5I6fhCSrNMZv+bZL4a+Afwg+R+C/BEwXPPB67Nnf8PMcK9FvgdsEfObw7dK8+P\nA6PS8Sjg8XT8I+DowuuAo4Ef5dy7XFeHtC9aPqss17FEQ3o58DfgqXR9JssbgC8WCX9ckvUa4GHg\nAwXyOid3/hVgOfA0cBxV7PQC1wEHN4g8zyQ6iEcVXLdtSvPj0jW/AH5G1EF/AvbOXTsauCZd/yTw\nhYLwf55kuC7JYVJBHjgod/5vwA25cK8HVgGLgE8XhPsLos7MlK4tgX8llI8NhGK1c7regc8CC1N+\nuITOSfWl8lGXODbSr1j5BF5LtI09yfZfgReB4Tm/txHt3KvS+XHAo0R9eQuwS+5aBz6X0vTJ5HYR\n0bY9D8wH/qlAZpspWoSy81fgK0Xecwui7D8FPJvy03ZEWfoEne30X4k29G/pvh8BxxLlfTWR189O\n12xWzxJ18GM59031MT3U5bWSZxPK9Cngq93I8SHgjML7C8NI558iyv7LhA70GTrbyilEfV3xNrVZ\nzDa628aycFj/buC1ZjbOzLYk1ky8ssD/EjP7mJm9vuDee4BDLUwp3mVmr+5DHD8ETCJ6QFOJzAcx\n4vlLd3+lzHDWEwV5KKFI/7OZfTD5TScqg52B7YmK/kUL84+Lid7vEOCdhKJYiAO3mtl8iy0/W43u\n8kBb8svSY5KZPQDcRlSwOxCV5pWAp/v2JCqfk4GrgKvTvTcBbzCznQHMbAuix3xZLg6/AXYDdiQU\niKu6iWehDEa6+/J0vAIYmY57yvfllIdaUu34lCrb3yfKxa7ESNSxRIWa3XuKmZ1kZntln1cBzOxV\nwK+BWwl5fR64ysx2L4yAmR1GdLIPJuR7UAXfr/BZY4nG7J5qPaMEhfJ8DTF69cv8Re7eQZSJg5PT\nVKLzOJz40vYrM3tVKie/JkbIdgLeC3zRcuZRwAeIcjaUUIZ/0F3EUtk7nBhgIN2zlFCiPwyca2bv\nyd0ylVCghxJl8RSiofw00RGaQXSeM94PvB14K3AUkMWxx3zUBBQrn+8kBmV6ku1ewB+AaTnvjwO/\ncPcNZjaVUMaOJOrS3wNzC57/QWLb6fHp/D5gAp355H/MbOsS77A70e79osg1M9LvQKIu2Bb4b6Is\nZfX/Xims9xCf88cRaXEI8Mb0uy+945b0XP8u7cYdeq7LK0mp+raZZPp6os7Ix/MVoqN9SIn7M56l\nU9n/FPA9YHRODq9QhTa1WZTncrmCaDgPJhIyv1vPR4hM8A3gSQub07cDuPvviYwyEbgReM7Mvpsa\n6nI5z91XuftfCfOQo5P79kQlXRbu3ubuD7r7K+7+AJFp3528N6Tw3uTuL7v7fHd/Pvm9AuxpZtu4\n+3Lvfr3Iye4+EXgf8DkzO6AX79cs5PPAX4hOBYQy/BgxmjSB6CG/l9jH/hWiZ+rAvoSycDkxAvGy\nu9+ZwlhF5KlPpvP3EqYeN2YPd/fZ7r7O3f9O9Jj3NrPtcvG7rJgMUhy8n2nQivRUtjNl+vSU7u3A\nBXTK6DvAecAxwB+BZTl7tv2JBnaWu//D3W8nRhizspvnKOC/3f0hd19PyLbiWNjyXkOMcj5f6voa\nMQR40d03duO3nPiKAzDf3X/h7huA7xIN+P6EMrqDu5+d0nkx8GNCbhl3uvtN7v4yIeu9C57zKzNb\nA9xJfBk6NynS7wJOc/eX3P1+4L+IfJLxB3f/VapPXyRGn88hRq+/6O7/5+7P5a6f5e5rUj1+B1FX\nQPF81CWO6fer7pOy4RgBrCwh25+SykTqNHwsuUEM4HzH3R9NYZwLTDCzXXLhfCe1jS8CuPuV7v6c\nu2909wuIOnSzDmsB2+fi1BPHAN9198VJUfwWMah1ClH/A5zl7i+6+5+Jkcosnx0IfNvdVxH1/s9K\nxKckdazLm0WmWb3RnUyXE4p7Sdz9RuJrAu7+v8RgSKHuVnE5NIvyXO42llcQPagZhPKzCXdf7e4z\n3X0PohdyP1HZWfL/jbv/P6LnNDWFcUIv4pjvtTxFjIRAfPoZVW4gZrafxWSHv5nZWiIjZ5nsCuIT\nytVm9rSZnW9mr0qN+UfTtcvN7EYze0th2O6+LP0/C1xLKIqtRpYHPkWkW77H/BJRp71CpNVgoqB9\nnPisB5HP/kHIs7t89wc6FbNPAlcnZQEz29LMZpnZE2b2PPEpFzrlB/FZulAGz5jZqBTGKKInTQ/P\nX1bEvV7UIj49le0RxKjoUzm3p0ijBqmTeYm7v4sYffw2MDuNOI0GlhR8Fdp0bwGj2byMV5Q0En4N\ncJW7/7LU9VWkUJ6vBra27mfIjyI+90IufVKaZiPCuwCjc4rlGmJkKz8qtyJ3/EI3z/uguw91913c\n/aTUaI8GVrn7utx1hfLLy4z0Xl+g5zQujMe26X2K5aPCOA519w/SOBQrnyuJEdhisr0GeEeqmw4g\nBht+n67ZBbgoJ9dVxOf4HmVgZl82s0ctJu6vIb4adZkQ3A1ZB6dYWzqaVC5TWTo/uf+h8ML0Lv8g\n5LuMUNSyeI4hvnPUXwAAIABJREFUzAZepuf6d0w37tBzXV5JStW3zSLTrN7oTqb5eqUoZvY+oi19\nS3r24cALmRwIPbfibWqzKM9lbWPp7k8R9nSHU/DJouC6lYTd5GhCWc77veLutwG3E5/vIUwpXpO7\n7HXdBJtP+NcTdjYAvwU+lD5dlsNPiXfb2d23A/6TyLi4+wZ3P8vdxxOfZt5PGmVx91vc/WCSPRYx\nsrMJMxtsafWQZOZxCFFBtBS5PPAhwuY4v7LCNrnjQwj7510JRfu96dP8RqJCnU/3+e58YIyZHUh8\nrcibbHyc6HgdRFQeY5N79ol3EDHBo1AG1xMmOaT/69Lx9cCxFuwPrE2fom4BDjGzYRaziA9JbvWi\n6tvMFinbK4kvMvlRkdfTTcWXRpwuIez4xhNldOeCstntvcRISGEZrxipE/8T4FF3/24lw+4DhfJ8\nOzEad2T+ojRK/j7CBApy6ZPSdAyRxksI28ihud8Qdz+c/vE0MNy6ropUKL9NI04pjTcAz/UnjbvJ\nR41OsfL5B0rI1t1XE4MMHyXquKvTqCqEbD9TINtt3P3/csHlZfBPwFeJLznD3H0oMT+klBnM4+lZ\n04pc8zSwS64sLSPq82dy12RfJabTqZxdn67bOatniTbgJbqpZ1Md/LyZ7Z+edSxd6+zu6vJKUqq+\nbSaZLiWsAvLx3IKQc1ty6lH/sjCxvYbYOfCx9OybCHvsTA6DqUab6g0woaGcH9Fo/oWY6PG1Ar92\nOmdjv5E02YRQVrJJRecRyvAg4jPkJcDCdN1UIgMOIwS+L2FYf0zy/3YS5GuANyXBFE4YvC3dvzOh\nvJ6Y/LLVNq4gGd0TPbjv0s1qG0QPaXo63jedZ8b2BxL2SlumcP9MKH4j0zsMJjpEZwH/W5BGu6br\n/0xMyPlab2XQyL+CPHBUStMHiC8MToxYPpHS8wHCnvQdSd47EyPCy4gCvZjoXA1O6frXfL4j7Oja\ngYcL4nBSet5r073/USDbXxAVeRcZEJ8kb0v56rekiRwpbpekZz9I10lUxxGTJBYBn2qA9O+xfFZQ\nrj2V7SuJkYchhBL9GGmCL/BFYtLINume6UTDks1UX0zMyn5Vum4d8JZ07xzShEGi0VlBKEuvSc/c\nJNsKvOfkgjx7P3B4o8iTaBy7m73/J2Jk+kxCMT0ypfMpSXavIuqrPwGnJTlk8wrenp51JsUnBG3K\nA93E8/eEffTWhJ3yM7n8UhhulsYvAo+kND6JtFJOoTwL5N9jPioVx0b4FcqzwK+obNM1H03nz9F1\nIuiHiAGAPdL5dsBHcv6FaXo4oeS+jih/3yRGeDeTWTf54MOEUvYpoo7dIsn00uR/AlGHfiTdl42a\n3k/U/04MimX17J3pHkvv9iJRLx9OlMOl9FDPEvObHkrp+QM6J5Z2W5fXUp5NJtOP0rnaxtZ0rrax\ngs6JlwcTHZ3X0zkB1OnU5V5J77CB0Nv+Tpju3ZZk+BJVaFPrXqgrlJHa6abiomsD+/2UoTtSAt8A\njEvXHZASeiXReP6F3AxQ4vPDrcnvrpQZelpt47kkuC1z/qNzGWId0bifAbymMDMSFcRT6bobiIKZ\nZbyjCeVuPVEwLk7vOIqwA1xLVBht1GmZqwbPA3PobAy/lO5ZnwrYN3L3vB74VZLlSuDigjCnpDBP\nK3DfNhXsdUmGxxbIdtPz9auoXIcRyuzfiFGTb9K52saJxFeErGzcC7w/F84eubLzCPChnF8XeRFK\n9gpqsNpGI/6A44lG9cVU//yIzqW7zqTrahsLSMuFJf/RhAnVCmLE9m56VnLHUr7yPIaoJ1cRDeJn\nc35dwk1uWxIrMjyZ4nkfMCb5FVOeS+WjHuPYDL9isk3+26T0eribez9JKCLZClGzc36Fabol0RY+\nT3zN+SpdO8ibZFaYD5LbYUSHKWvH24Ajkt8WRNlfkvyuzOXP7sJqo7OTnc1zWUPUA18BltZbLgNE\nplOJcvgCnQMIuxfE55Ikm0XEZN98/fC59H5riEHKq+kst1OqJcestySEEEL0CTM7k2hQP1HqWiGE\n6A4zO4QwXT3IYwJww9IsNs9CCCGEEKJFcfdbCbOc/esdl1LUfM94IYQQQgghCnH3X9c7DuUgsw0h\nhBBCCCHKRGYbQgghhBBClElDm22MGDHCx44dW5Gw1q9fz+DBgysSVq3Dr3bc58+fv9Ldy9rNpz8U\nyrPa71VtGjX+9ZJnvWhEOVQyTrWSJ7ReGe2Jer5XPeXZH2qRZrWSS6uUz0ajGeuLwjiXLc96L6dS\n7LfPPvt4pbjjjjsqFlatw6923IE/eh3kWe33qjaNGv96ybNeNKIcKhmnWsnTW7CM9kQ936ue8uwP\ntUizWsmlVcpno9GM9UVhnMuVp8w2hBBCCCGEKJOGNtsoZOzMG4v6t886okYxEZXgwWVrmSGZigqi\nOqKylCqjSk9RSZTfmovC+vbUvTZ2kV8ry0sjz0IIIYQQQpSJlGchhBBCCCHKRMqzEEIIIYQQZSLl\nWQghhBBCiDKR8iyEEA3CkiVLOPDAAxk/fjx77LEHF110EQBmNtzM5pnZwvQ/LLmbmV1sZovM7AEz\nm5iFZWbT0/ULzWx6nV5JCCFajqZabUMIIVqZQYMGccEFFzBx4kTWrVvHPvvsA7A1MBO4zd1nmdnM\ndH4a8D5gt/TbD/ghsJ+ZDQfOACYBDsw3s+vdfXXt30oIIVoLjTwLIUSDMGrUKCZOjMHjIUOGMG7c\nOICtgKnAZemyy4APpuOpwOVpff+7gaFmNgo4FJjn7quSwjwPOKx2byKEEK2LRp6FEAOGZloHur29\nnQULFgB0ALu6+/LktQIYmY53Apbkblua3Hpy3wwzOxE4EWDkyJG0tbVt8hu5Tazd2hP5a5uJjo6O\npo27EM1CM9W3vUXKsxBCNBgdHR1MmzaNCy+8kGnTpr2S93N3NzOv1LPc/VLgUoBJkyb5lClTNvl9\n/6rruODBnpuJ9mOm9OjXyLS1tZF/TyGE6A0lzTbMbLaZPWtmD+XcNHlFCCGqwIYNG5g2bRrHHHMM\nRx55ZOb8TDLHIP0/m9yXATvnbh+T3HpyF0II0U/KsXmew+a2ctnkld2A29I5dJ28ciIxeYXc5JX9\ngH2BMzKFWwhRPcxsSzNbYGY3pPM3mNk9qYP7MzPbKrm/Op0vSv5j6xnvgYq7c/zxxzNu3DhOOeWU\nvNf1QDboMB24Lud+bBq42B9Ym8w7bgEOMbNhqa49JLkJIYToJyWVZ3f/HbCqwFmTV4RoDv4FeDR3\nfh7wPXd/E7AaOD65Hw+sTu7fS9eJGnPXXXdxxRVXcPvttzNhwgQmTJgAsB0wCzjYzBYCB6VzgJuA\nxcAi4MfASQDuvgr4FnBf+p2d3IQQQvSTvto8j6zH5JViE1eg+OSVak8QqWb4mtwi+oKZjQGOAL4N\nnGJmBrwH+Hi65DLgTOIL0dR0DPAL4AdmZu5eMdtaUZrJkydTmORmttbdnwPeW3h9ks/nugvL3WcD\ns6sRTyGEGMj0e8JgLSevzCg1c7PI5JVqTxCpZvia3CL6yIXAV4Eh6Xx7YI27Z73QfCd2UwfX3Tea\n2dp0/cp8gMU6t/Ui37ks1cEuRaXeRx1eIYRoXfqqPD9jZqPcfXkvJq9MKXBv6+OzhRAlMLP3A8+6\n+3wzm1KpcIt1bmtBd0sfnbrXy1xw5/p01r/xgEqtHqEOrxBCtC593SRFk1eEaGzeBXzAzNqBqwlz\njYuIeQiZhplfgWFTxzf5bwc8V8sICyGEEM1AOUvVzQX+AOxuZkvN7Hg0eUWIhsbdT3f3Me4+FvgY\ncLu7HwPcAXw4XVbY8c06xB9O18veWQghhCig5DdOdz+6By9NXhGi+TgNuNrMzgEWAD9J7j8BrjCz\nRcTqOh+rU/yEEEKIhkY7DA4wlixZwrHHHsszzzyDmXHiiScCm9bi/hkwFmgHjnL31WmFhouAw4EX\ngBnu/qd0z3Tg6ynoc9z9MkTD4e5tpDkG7r6YWGu98JqXgI/UNGJCCCEGLKW274bG3cJbyvMAY9Cg\nQVxwwQVMnDiRdevWsc8++wBsTefGN7PMbGY6P42uG9/sRyxrtl9u45tJgAPzzez6tI63EEIIIURL\n0tcJg6JJGTVqFBMnxq7pQ4YMYdy4cQBboY1vhBBCCCFKopHnAUx7ezsLFiwA6AB2rcbGN8XWBR65\nTf82vqk3WstXCCGEGHhIeR6gdHR0MG3aNC688EKmTZv2St6vkhvfFFsX+PtXXccFDxbPgpVad7ca\naC1fIYQQYuAhs40ByIYNG5g2bRrHHHMMRx55ZOb8TDLHoBcb33TnLoQQInHcccex4447sueee25y\nM7PhZjbPzBam/2HJ3czsYjNbZGYPmNnE3D3T0/UL02RtIUSdkPI8wHB3jj/+eMaNG8cpp5yS99LG\nN0IIUWFmzJjBzTffXOicTdDeDbgtnUPXCdonEhO0yU3Q3o9YLeeMTOEWjYOZtZvZg2Z2v5n9Mbn1\nuqMkGh8pzwOMu+66iyuuuILbb7+dCRMmMGHCBIjd5LTxjRBCVJgDDjiA4cOHFzprgnbrcqC7T3D3\nSem8Vx0l0RzI5nmAMXnyZAo3jjOzte7+HNr4RgghasHIakzQhuKTtPtDLSZIl5pE3kzvkmMqMCUd\nX0asuX8auY4ScLeZDTWzUbl8IRoYKc9CCCFEnajkBO0UXo+TtPtDLSZIl5pEXqkJ5FV8FwduTfL8\nUZJFbztKXZTnanWGKkFhR6ecFbR6S7Xft68dKSnPQgghRG15Jhtl7MUE7SkF7m01iKfoHZPdfZmZ\n7QjMM7PH8p596ShVqzNUCWYU7BB46l4bS66g1VuqveJWXztSA055LrUdZKNuBSmEEKJlyCZoz2Lz\nCdonm9nVxOTAtUnBvgU4NzdJ8BDg9BrHWZTA3Zel/2fN7FpicmdvO0qiCRhwyrMQonEp1bkVotk4\n+uijaWtrY+XKlYwZMwZgBKE0/9zMjgeeAo5Kl98EHE5M0H4B+BTEBG0zyyZogyZoNxxmNhjYwt3X\npeNDgLPpZUep9jEXfUHKsxBCCFEl5s6d2+XczFZqgnZLMhK41swgdKufuvvNZnYfvegoieZAyrMQ\nQgghRD9w98XA3t2497qjJBofKc9CiIqhOQVCCCFaHW2SIoQQQgghRJlo5FkIIWpIqdH59zx7DTfc\ncAM77rgjDz30ELBpe+afAWOBduAod19tYWB5EWE7+QIww93/lO6ZDnw9BXuOu1+GEEKIfiPlWQgh\nEo1gdjJjxgxOPvlkjj322LxztsXvLDObmc5Po+sWv/sRW/zul5TtM4BJxMYN883s+rS1sxBCiH7Q\nL+XZzNqBdcDLwEZ3n9SXERIhxMBAS9GV5oADDqC9vb3QuVdb/KZr52XLmZnZPOAwoOvSD0IIIXpN\nJUaeD3T3lbnzXo2QVOD5QogCzGxn4HJi+SQHLnX3i9S5bVp6u8VvT+6bUWz731Lb7TbSVsG9oa9b\n8gohBFTHbKNXIyRaFFyIqrARONXd/2RmQ4jP9vOAGahz29T0ZYvfEuH1uP3v96+6ruh2u9XeOrda\n9HVLXiGEgP4rzw7cmiryH6VKuLcjJF2U52KjIMVGQKD4KEg20tCfMIpRzZEMjZKI3pLK4PJ0vM7M\nHiXKmzq3zUlvt/hdRqecM/e2GsRTCCEqRiPMQ+mO/irPk919mZntCMwzs8fynn0ZISk2CjKjVCIW\nGQXJRhr6E0YxqjmSoVES0R/MbCzwNuAeqti5hdId3GpQyrSgkpTbiS3W4S2nA79ixQrWr1+fD6NX\nW/ya2S3AuWY2LF13CHB6WZEXQghRlH4pz+6+LP0/a2bXAvvS+xESIUSVMLNtgWuAL7r782nrWKDy\nnVso3cGtBqfutbGoaUElKbdzXazDWyqN3nHDj2hra2PlypV84hOfABhBKM1lb/Hr7qvM7FvAfem6\ns7PJg0IIIfpHn1scMxsMbJE+CQ8mRjbOppcjJP2JvBCiZ8zsVYTifJW7/zI5q3Pb4Myd23VBDDNb\n2Zctft19NjC7GnEUQoiBTH92GBwJ3GlmfwbuBW5095sJpflgM1sIHJTOIUZIFhMjJD8GTurHs4UQ\nRUirZ/wEeNTdv5vzyjq3sHnn9lgL9kedWyGEEKJb+jzy7O6Lgb27ce/1CIkQouK8C/gk8KCZ3Z/c\n/pVefv4XvSOb3HLqXhvrYsIihBCi+miHQSFaEHe/E7AevNW5FUI0HY268oIYeEh5FkKIMtEOiUII\nIfpj8yyEEEIIIcSAQiPPQgghhBCiC/rS1jMaeRZCCCGEEKJMWmrkuVgvSbPfhRBCCCFEf2kp5VkI\nIYQQA5NyzAy0IoeoBDLbEEIIIYQQokykPAshhBBCCFEmMtsQQgjRJ7RphRBiIKKRZyGEEEIIIcpE\nyrMQQgghhBBlIrONAvr7GVKfMYUQQgghWhcpz0IIIYQQoumo14ClzDaEEEIIIYQoE408NxkyCxFC\nCCGEqB9SnntJT8qrtv8WQgghGpuxM28s2l5rAEqUg8w2hBBCCCGEKBONPLcYpcw6QD1rIURtkJnZ\nwELyFgOFmivPZnYYcBGwJfBf7j6r1nEQlUPybC0kz9ZC8mwtJM/Wot7yLGewTXRPTZVnM9sSuAQ4\nGFgK3Gdm17v7I7WMh6gMkmdrIXm2Fs0gT41Ulk8jyFPKVuVoBHkOBErl2TmHDe5TuLUeed4XWOTu\niwHM7GpgKqDM0pxInq2F5NlaSJ6theRZA2rYoau6PNXZqR61Vp53ApbkzpcC++UvMLMTgRPTaYeZ\nPV6JB38BRgArKxFWf8K38/oUfEXj3k0cduljUP2VZ8n36mN61Yqq5ql+UC951oVql+2+0J841bJ8\nQv/LaDWpYvmv53vVU579od9pVoY8ayKXFiqfDUUj1sWlOPC8zeJcljwbbsKgu18KXFrpcM3sj+4+\nqdLh1iL8ase9mhSTZzO/FzR//PtCtcpnf2hEOTRinHqilctoT7Tqe0HztqG1ekYtn1MJGrHO7Ylm\nSteMvsa51kvVLQN2zp2PSW6iOZE8WwvJs7WQPFsLybO1kDybmForz/cBu5nZG8xsK+BjwPU1joOo\nHJJnayF5thaSZ2shebYWkmcTU1OzDXffaGYnA7cQS7PMdveHa/T4an/2qGb4DfnJpgLybMj36gXN\nHv8u1Ll89odGlEPd41Qhedb9PapE071XA5TPWqRZreRSd/k3gDyrQd3TtQ/0Kc7m7pWOiBBCCCGE\nEC2JtucWQgghhBCiTKQ89wMzm2JmS+sdD9F6mNkcMzun3vEYqJjZCjObXOc4XG1mX69nHOqBmW1t\nZm5mY+odF1E5atlemlmbmZ1Qi2eJ6mFmt5rZMen4BDNrq3OUNtGSyrOZtZvZg2Z2v5n9MbkNN7MX\nzewVM9toZs8mBWXbMsKbna5/KOc2HPh3YKSZzTOzYcndzGypmb2c4jCxj+GfaWbL0jvcb2aH5/xO\nN7NFZva4mR3au9RpDMzssBT/RWY2M+c+2cz+z8zWmtkqM7vLzN5e5bh0K98k14UF8j0zyfaV9P9n\nM3tH8puerl9oZtNzYe2T8sIiM7vYzKya71MrzKwj93slla/s/JgS9x5mZosK3GaZ2YZ0/xozu9PM\nii4h1F1Z70X8h6Y4X9ub+7oJp0v+MbNXm9n5ZvZCSpeXzOwWM3tPf55TSwrLZ6Vl3cu4XG1mf0/P\nWmdm95nZO8u4r6d2oLtybWb2KzP7h5k9kNXbZra9mV1uZs+Y2fMpTU5JfpmSvz6XFiv6+p61IrUf\nvylwW2hmvzGznc3sDjN7JKX5nG7un5Lq56xt+mYf4tCe0jqrR9dY1PufNbMtkjwuTvlvkzx6wTbA\nN3NxfN7MvpievYeFUvZ8kt8LZvaEmX0zvdsrBfn91719v0bGzK40s/8ucHu3mT1nZqP6GGa39XB6\n1j9yZfeP1otBCXc/xN2v6uZ5g5LsxvYynmW39eVEruV+QDswosDtfGA1cBAwk9gW8yFgVhnhHQBM\nBB4qCO9SYmHzmcB5yX0G4MAq4F+Be4qEu2WR8M8EvtzNPeOBPwOvBt4APJGF0yw/YnLEE8CuwFbp\nfcYDrwXWAEena7YBDgHe2ouwB/UhPj3Jd2Y6zsv3KmI5IQPeBTwNLAeGA4vT/7B0PCzdcy+wf7rn\nN8D7SsUTmAOcU29Z9SIN24GDenH9YcTuWnm3WcB/peNXEZ3TJ8p47ojexDV372eA54C/A9sX+K0A\nJvc2/yQZ35LyxffTe3wN+B/ggt7kWeBq4Ot1kGW35bOSsi5x/dZEHTqmMB2IAZ+TgeVl5snu2oHu\nyvXhxOoHi1JZvSe5zwWuALZLzx4PfKi7eDbLL9Vba+lsf0altFpBbNwxMbl5ygfjC+6fAtzQh+dO\nAZbmZPPXLB+l9P0A8CTw30kev0nlaZM8evGsNuCEXH5eAeySzhcDXyF0gRtTekwujGOr/oDtU3oc\nnM63Bv4CzOhHmN2VtS2BK4Ez0/kWwGeBZ0nz7Xr5jBOAtnQ8KOXPsb0Mo+y2vtSvJUeee2Aq0JGO\nLyMKzm+APc1stJldbzHSucjMPp3dZGavBo5M1+5uZhcmt6nAzbnwPpiOP0dkxDnAO4GhWW/OYqT7\nh2Z2k5mtBw5MYX0A+DXwFjP7TzPbJoW1jZndYGZ/M7PVZnYD8Enganf/u7s/SVT2+1Y4rarNpm1J\n3f0fROM4FXgzgLvPdfeX3f1Fd7/V3R8AMLNPm9mjqQf7SG50qN3MTjOzB4D1qVc62syuSWn3pJl9\nIXt4GtmYmUYbniMa45eT31gzcyKdTzazlUTFnsl3d2CxB3cRitfrgA8D84CTgPuJxuc6M3sz0SlY\nAbxCNBg/B25Pz8tG2teY2RIzm5FLp2FmdmN633vM7I0Vk0ANMLNtzOwSM1tu8TXm38zsVWa2PXAt\nsGtudGf7/L3uvgH4abpmSArvsFQ+v25mK81sGdHBOiyTpZmdmnv+u8xsQRphWmFm3ymI4nTgQkJB\nOLqbV3inmT2W6oVLU1nFzBab2UG56+4lGutXA0cQ5f4F4Nz0HrOJDmA+bivM7Mtm9jDwfHLb1+JL\nxjozu5JQXOtBT+WzR3or6ySbe1K+f9rMvmdmJVd/cvdXiHzxOouvf5jZWyy+UqxN5f3yLFrA3yxG\nM58ws+eBTwF3mtm9xODGP6fnHgXsTXQYfgu83czGA28HrnL3te7+irs/4u79+lLRANxHdOompPN/\nAu4AHgde5+5/Sm5PEB3Cgy1G+9ea2X3AHllAJdrObVKbt9rMHiHSsltS+l4PfJQolzOAy4ky8GFg\nYpJtvn3EzKZa58jyE2Z2WDfBfwQYAhxlZiOIQacfAxvj0X6Xu9/Zi/Rratz9OeDzwKVmNhg4gxik\nmJPaxn9NabnS4qtP9nVmCzP7Raq71liYxozLBf3DVAfcbKHf/FPBc7Oyu0P6YWbnWO7rhpm9KbW/\n2fmdBW1ixu/S/8OpTplW5rv/jhjYzDOV0OGgqy5XlFZVnh241czmW2xtCTCSpCARiszriN7tAqJx\nWAqMJgrqudb5ifVrRM/3cDoV1a+n8FblwhuZjscDNxAjlIcSvaydcnH7OPBtojDfSYy2vTmF/5d0\nbfYZ7NPAnsBNwFuBF4nKpXBLz3z4zUB325LuRLz/y2Z2mZm9z3KfT8zsI8Ro/LGEMvoBYtQw42hC\ncRlKKKm/JkbMdgLeC3zROk1cPk8UkHcTMl8NfKsgjsOB3dK9pxDKMOnZL6Q4vZooQ88k9x2ISv9A\nYtR0GPC99H4ZuxByP9TMdiE6Zd9P904gFO+MjwFnpXAWEfmmmTiLyLd7AfsQozpfTZX3h4hOyLbp\nl5dllrafJMpWR85rLLCBKL+ziFGUiwgF9D+Ab5tZVh5+QCiwryVk+atc+G8myvVPibK6ycwmx9HA\ne4gO09uI0SqI+iKvbB9ByPjvRKf8LmIUZnnyz9cPeT4KHAxsnxSC64AfEXnvN0Qerwc9lc9i9FbW\nG4hO6/ZEI/v/iJGloiRF91hC0VudnL9DyHYo8HoiDSHagcz/QqK8jwC+QShUY4HBwLTkfnoWT0KZ\nfA1wN3CehUnWm0rFrxlIHaJ7iFE40v/viXop7/YnQpZnAhcTsvouUe7eaWZ/JpTr9XTfdp4BvDH9\nDqVrGXOiTPxHro3G3e8l8ts4Ig9m7eP/EXLa1D6a2b6Egv0VQvYHECOgmzCzNxD54Tp3/zeizVhE\njIhOzt7DwmRlDwYI7v4/hHznElt/ZzL4ElGfHUBs2tJByD7jBqIufR0h+yuyIIm28jNEGzYE+EP+\nmWa2JVF2n6D/W3hn+XSPVKdc04+wRpZRV29ONT4L1PsH7JT+dyQUqAMIc4B2IjOsIRTp/yB2+HkZ\nGJK7/zvAnHT8BKHYjiUyy6EpnDV0/Qy1miiMrwBHJLfHCIVwUjqfA1yee44RFc8bc+G/g/h0NZL4\n7LEFoTTNJpSrl4BP5ML4CfDheqd5L+XzYdLn+XT+SeAH6XhcSqelxMjA9SktbgH+pYfw2oHjcuf7\nAX8tuOZ04L/T8aPAe3N+o4jG/KEkBwfW5vzvBTrS8V/StWuIjtEq4BPAl1NeOSld9w3gvPQOt+XC\nPYr0yTPF6doe3mlOQRodDjxWb9kVkWk7BZ/yCfOW9+TOp2bvQM9mG3+ns3w+S850It2zFtgine+Q\n0nRvOsv6k8BhObl9jQKTjOR3DnB3On5DCmdczn8Fuc+YxNenh9PxnkR53yqdX0PUGQ8RjfIcYE3y\nG53exzO3XPgfz50fAjxZEMc/UR+zjR7LZ6Vk3c0zZwJz03F3ZhsvpnR8KR1/JHfvz4mO0qiCMHdN\n4RxEZzvwMrl6JIU3i1AKTs3iSZTZSYRy/U1CIdhIKO0HFcRzbYrbGuD8epfFMmV8JqnuSWmzW5JT\n5vZgKksXAfcW3HsvoSRlbeeinF++7VxMKovp/EQ628udUj76cCab3HV3E23nZDrbx0we78jKCaEU\nf6+H92ubRiDMAAAgAElEQVQjFP12omM9Muc3JuWXxUR7/Tui47aQaNNfyclzDXBUveVVpTwwktCH\n8uVhIfDu3PnOqYxs0c39I1L+H5zkeSUxGLFJnsntJTrL7kvAx3JhnJPll3T+JuJrQHZ+J6kepgJm\nG+nesXQ121hT4L+6nHBacuTZ3Zel/2eJT4b7EqODWxIjjuOIAn8S0bitcvd1uSCeonOkZXQ6z/uN\nTuFlnw1HEQ39dKK3/Np07U+JkZD8lpv5EZ0diNGN+cADKV43Azu4+zPEZ+AfpnCnE4X81SnMjGbc\n0rPHbUnd/VF3n+HuYwglZTQxarQzoZz2RD5ddwFGp09La8xsDfGJdmTO/9qc36NEhZn/bLzCOidP\nbKRz9PN5Quka6u47An8jKvZlRH7I8soY4GEiz+2SC3crOuVV6p3yk49eAEpObm0UzMyI0YnCslNq\nBPMKdx9KdGieIBTjPH/z+PwHoUQBPJMr64PoTKfpxGjoX5KJwKG5uH2SGHHGw/zpD2w++pzPU1m5\nx90fSn7vM7PXEjbs2c5gz6W4P2Nmo9z9aaJctxPKVk/hj6brF4rsmfWgV9sG90XWZjY+jfY9k8wp\nvkk0xj3x7ZQvtiEUqB/kRji/RNSjCywml30iuT+d/h+jsx3YQHTQsno7K1fLCp4/Bljm7uvd/Wx3\nn0CMvP4auMaSKVFij1QfDHX3rxZ5h0bid8DkZPqyg7svJEZ332lmOxJ171VEGhbmw8VEWo0mBg8G\nJXMI2LztLCxDQGcbTShVmWwydiLq1T3obB+nEPXszaRP/pSuP48h6oh7UnuaPXupu5/s7rsSdfN6\n4HjClGU74OmcPIe6+8+LPKNpSWmykminMl4P/DrXNj6Y3Hc0sy0tJkIvTmU2mwQ8IifPhWwuz1m5\nsrsv8D0zO7hKr9UXnrFO09pMlytJyynPZjbYOm0kBxMjOg8RjVu+Ub0uHT8NDC+oDPMK79N0VX5e\nn9yuJ3rqWXg3EqOKOwJzLGZdf5lQdnfM3e+545VE4d6DaOQfdfft3H3bJMRTiU/GlxITjrJPFR+1\nmNH/BmLE4N7yUqdhKGtbUnd/jBjF25OohIvZ/ObTdQkxOpGvAIe4++E5//fl/Yl03pgL49d0KlOv\no9Oc4nHCftPMbH9ihHo5MTK+NWG3PozId4+mMFcRn/0hRqmzvFfqnZoWjy78CjYvO1m58s1u6nr/\ns8To1rm5hrmQ12QHubKeKdRZR+yjRPm7GPhlym8Hpricmez3VhBK+ifMLF8n5hXIrNxnzCVMN6YR\n+Tn77HcbYfP8Wzrzz3TCDGCz18wdLycUtjyvpz70atvgPsr6x8TI+hs9zGrOJr7EFcWD+4k67/Dk\ntszdjyM6LV8AZpvZ7nTW99nE44cIZS2rR6fTqQBcT4xQU1Cu889eS4xSv5b6yaZS/IFQFD9NmBnh\n7s8Tefw3xJe2r7N5+wdRZy1LfsOJAYLM7Cov9+VsXoa6tNFEnZnJBouVlXYiytcHifL8SWB+ahu3\n8zCrgdL155mE+cDQZDLQBTN7HdFhvYRof7cgviIMZJYSEwnzbefW7r6CMLk4nDBl244YJQZ4TU6e\ng8jJM08quw8QXxaOSM7rydXjRFtbDkXbj15yPV3r6uuKXLuJllOeidHFO5M91r3Aje5+M1HpbU0o\nYwelc9x9CdHj/o7F0kNvJXqhV6bw5hJG5PcQCtavid7YLMIebGQK7xHiE9buxIjzS0QlsoDIdJuR\nRtB+TFRk9xATEp82s+8SM0C/QMwM3ZewKTwj3fqL9Lybgc+5+8uFYTcy7r6RsHe8hVAwf+7uD1tM\n/DnV0vquZrYzoaDcDfwX8GWLZd8sTSworNQz7gXWWUwi3Cb1mPe0ziXv/pOwjd0lPeeXREO+O512\nWucTE2UWEjbHNyX3hcQo9CJCdield1pFfF7+DiHz84DTgJ+la2al+58gGieIkZ2DzOwoi0mO25tZ\nNomnFZgLnJHea0fChCIrV88Qoxk9jqanivb3RCeyO7JO6W2ksk6afAdgZsea2fapfKwlKlwnKsgb\niE7rhPTbm1AE3psL/wtmNiop7zMJWebf7f3Ep8RtiHyzO2EKtoQwHToy5Z+D6WrL3h2/A7a2mNw2\nyMyOJhr0mtNT+SxxW29lPYRQUDuSremnKRMz25OwV384nX/UzEYnJX5Numw4aVIuIeusHVgOvDXJ\n5SA6Bx5uIkZUdyVM4U5KYZ9pZhMtJj9uQ9TJK+lUupsSd38R+CMxn+P3Oa8niDZno5ndD3wVGG9m\nPzGzk8zso0S5mUmk63qi7Xp1N23nz4HTzWxYqtM/n9xHEp/jRxPmEzcC/2dmlxByuJL44roY+Adh\nV/s1ADPbyTrnrvwE+JSZvddiMttOZvaW3LsYUTZXA5ena06xmIT/JsLu/dH0vA1EJ3Gg85/EgEXW\n0dnRzLK5F0OIrzbPEQpvNgdnBCHPI4hynJW1zbCYhPtOOke77wfebbFE4lAiX5Uk1enPEeW1bMxs\nLqmutpjYfDzRNmdt/SbdsJxIDJgfPSyxRIz43ECMED4BfDbntzUxarU8/S4Gtk5+U+i04bqZbpai\nIkajVxA9sjkULD+Wwj+XqCieJwrzF5LfaMJ2q4Owtf0M0fj3ejm2ZvgRIw4/Jzod69P/j4DXJv/P\nEiO/HUTP9m09yTWl3dyU9qsJBTyzVdyCaDQeB9YlmZ+b/MYWpjFdlz06E7iyh/hvQXx+XkJ8dryS\nzuXqNgs3uf8T0fg8n+6bnty75BUafAmlHmTwGqIRXEGMUn2XTjthS+nzHKHwDCe3VF0ujHentBlO\nge0sMbLoxAoBmdsfSXMAUl5amWT8IDFqsm3KPwd38w6zM9mmOH+V+OS/mui8bV1w/V1E4z68wH1r\nwpbvCcIsYAmhIORtgjdbCo9QCB9I8b0S+CV1sHmukazfS9RpHal8nQv8Npd+hTbPf0/XdhCf/88i\nLXdFmHUtT34L6bSR3GwpuZQ/8jaX/07nfIvu4nk2MVCxLrnfBry9p/Cb6Ud09B2YmHM7Krl9Juc2\nmTCdWJv+8/MQirWdryEm9K1JafgVcnVYykcvprRdSyg1nyO39CpF2sfk/6FcmVkEHJrc2+iss7cm\nvgTNIexzL6Nz/tMKop3I5klNoYHr2SrkgXZyZZn4ivCVVI6yNP1W8htCDB6uS/dNJ2d3TG5Zulx4\nVxJ1ZL7snkPnvBUjFPY1RH1wImXYPKfzzyX5rQGOrHXaZZWPEEIIIYQQogStaLYhhBBCCCFEVZDy\nLIQQQgghRJlIeRZCCCGEEKJMpDwLIYQQQghRJoNKX1I/RowY4WPHjt10vn79egYPHly/CFWQRnqX\n+fPnr3T3HUpf2T9aWZ6Vpj9pUy95VpJ65o1658vC59dKnqAy2hN9TYd//OMfPPnkk2zcGEvIjxgx\ngqVLl64kljX8GbEKTzuxi91qMzNiV7/DiZVaZrj7nwDMbDrw9RT0Oe5+WannD0R51vod61k++8tA\nyA8Z5b5r2fKs91IpxX777LOP57njjju8VWikdwH+6JJnQ9GftKmXPCtJPfNGvfNl4fNrJU9XGe2R\nvqbD008/7fPnz3d39+eff9532203J5bZPB+Y6bHa1UzgvHR8OLEOvBFLF96T3IcTy7UNJ9adX0xa\nBrPYbyDKs9bvWM/y2V8GQn7IKPddy5WnzDaEEEKIKjBq1CgmTpwIwJAhQxg3bhzAVsBUYr1h0v8H\n0/FU4PLUjt9N7I43CjgUmOfuq9x9NTCPzh1uhRA1pqHNNoQQQohWoL29nQULFkBsFrGrd27/vYLY\ndQ9io6gluduWJree3DfDzE4kNptg5MiRtLW1bfLr6Ojoct6KDIR3FPWnqZTnB5etZcbMG3v0b591\nRI9+ovEoJU+QTEVXxiq/NBSSR3l0dHQwbdo0LrzwQqZNm/ZK3s/d3cwqtluZu18KXAowadIknzJl\nyia/7191HRfcub7He1tBXm1tbeTfWQxssjrq1L02dqtv9DXPy2xDCCGEqBIbNmxg2rRpHHPMMRx5\n5JGZ8zPJHIP0/2xyXwbsnLt9THLryV0IUQekPAshhBBVwN05/vjjGTduHKecckre63pgejqeDlyX\ncz/Wgv2Btcm84xbgEDMbZmbDgEOSmxCiDjSV2YYQQgjRLNx1111cccUV7LXXXkyYMCFz3g6YBfzc\nzI4HngKOSn43EStuLCKWqvsUgLuvMrNvAfel685291U1eg0hRAFSnoUQQogqMHnyZGL1q07MbK27\nPwe8t/D6tFTW57oLy91nA7OrEU8hRO+Q2YYQQgghhBBlIuVZCCGEEEKIMpHyLIQQQgghRJlIeRZC\nCCGEEKJMpDwLIYQQQghRJlKehRBCCCGEKBMpz0IIIYQQQpSJlGchhBBCCCHKRMqzEEIIIYQQZSLl\neYCxZMkSDjzwQMaPH88ee+zBRRddBICZDTezeWa2MP0PS+5mZheb2SIze8DMJmZhmdn0dP1CM5te\np1cSQgghhKgZ2p57gDFo0CAuuOACJk6cyLp169hnn30AtgZmAre5+ywzm5nOTwPeB+yWfvsBPwT2\nM7PhwBnAJMCB+WZ2vbuvrv1bCSGEEELUBo08DzBGjRrFxIkxeDxkyBDGjRsHsBUwFbgsXXYZ8MF0\nPBW43IO7gaFmNgo4FJjn7quSwjwPOKx2byKEEEIIUXs08jyAaW9vZ8GCBQAdwK7uvjx5rQBGpuOd\ngCW525Ymt57cu2BmJwInAowcOZK2trZNfiO3gVP32lg0jvnrBxIdHR0D9t2FEEKIRqak8mxmOwOX\nE8qUA5e6+0Xps/3PgLFAO3CUu682MwMuAg4HXgBmuPufUljTga+noM9x98sQdaGjo4Np06Zx4YUX\nMm3atFfyfu7uZuaVeI67XwpcCjBp0iSfMmXKJr/vX3UdFzxYPAu2HzOlqH+r0tbWRj6thBBCCNEY\nlGO2sRE41d3HA/sDnzOz8XTayO4G3Pb/27v3KLuqOsHj3x8v7QEUAiaNBAy0MAMjg0IGsGXo+IoB\nW1FRBFmGSJCxBcWWdnXUdniJDS5bu+12aSOiiBjEBxpBQJqx2tElNIFGw1MihoFMIB3C0wcS+M0f\nZ9/kVFGPW6n7ru9nrVp17z6vffY+p+p39tlnn/IdhveRPYmqjyy1PrIHAwcBpzceSlNnPfXUUxx1\n1FEcd9xxvOUtb2kkP1i6Y1B+ry3pq4HdaovPLmljpauDTjjhBGbOnMlLXvKSevKWPvwpSVJ7TBg8\nZ+aaRstxZj4O3EF1e94+sn0oM1m8eDH77LMPH/zgB+uTlgGNoOl44Hu19IUl8DoEeLR077gGmB8R\nO5bgbH5JUwctWrSIq6++emTyLnhhK0lSW0yqz3NEzAFeBtwAzOq1PrL91Ee0W31aV6xYwcUXX8ye\ne+7JFVdc0Uh+PnAucFlELAbuBY4u035A1QVnJVU3nHcBZOb6iDgbuLHMd1Zmru/Qbqg47LDDWLVq\n1cjkHRh+YTtENXLKxgtb4PqIaFzYzqNc2AJEROPCdmm78y9JUr9pOniOiO2AbwMfyMzHqq7NlV7p\nI9tP/WO71ad13rx5vO997xuWFhGPZuZDwKtHzl8CrZNHW1dmXghc2I58akq2aseFLYx/cdtKY11c\nduIB024/rNnt7UuSxtdU8BwRW1MFzpdk5ndK8oMRsUtmrplEH9l5I9KHNj/rkibSygvbsr4xL25b\naayLy0VLrhx3uVZcQHf7Yc1ub1+SNL4J+zyX0TO+BNyRmZ+uTbKPrNSbNvjwpyRJ7dHMaBuvAN4J\nvCoibik/R1D1kX1tRNwNvKZ8h6qP7D1UfWS/CLwXqj6yQKOP7I3YR1Zql0fwwlaSpLaYsNtGZv4E\niDEm20dW6qJjjz2WoaEh1q1bx+zZsznzzDMB1lBd2PrwZx8677zzOProo5k5cya33norsHFEFMfV\nl6Qe4Ou5pT62dOlS1qxZw1NPPcX999/P4sWLAZ7OzFdn5l6Z+ZpGIFyGjzw5M/8kM/fLzOWN9WTm\nhZn54vLz5W7tj2DBggWjDT/ouPqS1CMMniWph+y///7MmDFjZLLj6ks9LiJWRcSK0r11eUmbMdmX\nVqn3TWqcZ0lSV7RlXH0Yf/jBiYbN68TQgb3A4QM1Ca/MzHW17427RudGxJLy/a8ZftfoYKq7Rgd3\nOrPdNGeC0ZMAVp37+g7kZPIMniWpj3Ry+MGJhs3rxNCBvcDhAzUFR7JpmN4JX1pVu0hWDzN4lqTe\n57j6feqEE07giiuu8AHQ6SGBH5aL238uF6aTvWs0LHhu54upun1HZaI7VzD1u1eNbYz1hurNXb/B\nsyT1vsa4+ufy7OEHT4mIS6lu+T5aAuxrgE/UHhKcD3y4w3kWsGjRIk455RQWLlxYT57UrfzaA6Bz\nqQK0myJiWenPrt5xaGaujoiZwLURcWd94ubcNWrni6m6fUdlojtXMPW7V41tnLbfhlHfUL256/eB\nQUnqIWeffTYvf/nLueuuu5g9ezbAzjiuft867LDDfAB0msjM1eX3WuByqpFuHpzkS6vUB2x5lqQe\n8rGPfWxYa1BErMvMh3Bc/UHSlQdAx7p13TAID0V2qytCRGwLbJGZj5fP84GzmORdo45nXJvF4FmS\npC7p5AOg/3jJ90a9dd0wCA94drErwizg8qrbOlsBX8/MqyPiRuCyZl9apf5g8CxJUmf5AOiAycx7\ngP1HSZ/0XSNtMtFwdt0ays4+z5IkdVbjVj48+1b+wvICjUPYdCv/GmB+ROxYHgKdX9IkdYEtz5Ik\ntcmxxx7L0NAQ69atG/kAaNO38jNzfUQ0HgAFHwCVusrgWZKkNlm6dOmw7z4AKvU/g+dpZrQB+4Et\nI+JaHLBfUgv1an9FSZoK+zxPM4sWLeLqq68embwL1YD9ewHXUQ3YD8MH7D+JasD+xtuxTqcaXucg\n4PTayxgkSZIGli3P08xhhx3GqlWrRibvwPAB+4eo3na1ccB+4PqIaAzYP48yYD9AabVeACxFmoI5\ntbdBNfP2KUmSOs3gWQBb9eKA/TAYg/Zvjm4N9C9JksZn8KxhemnAfhiMQfs3RxcH+pc0TdlHXWqO\nfZ4FsKF0x2ASA/aPli5JkjTQDJ4F8AgO2C9JkjQhu21MMyMH7D/zzDMB1gCvdcB+SZKk8Rk8TzMj\nB+wHOPHEE5/OTAfslyRJfWOifvrtYvAsSZKklupWYNsJ9nmWJEmSmmTLsyRJkoZx6MKx2fIsSZIk\nNcmWZ0kDw5YSSVK72fIsSZIkNcngWZIkSWqS3TYkSZI0KYM8FN1EDJ4lSaNasfpRFk3jf5CSNBq7\nbUiSJElNMniWJEmSmmS3DUkdM537yEmSBoMtz5IkSVKTbHmWNG34EhVJqvhA8OYzeJakYs6SKzlt\nvw1j/kMxuNZ05sWnVLHbhiRJktQkW54lSV1hS6akftTx4DkiFgD/AGwJXJCZ53Y6D2qdbtfnVEdv\n8J/zcN2uT7WW9TlYrM/BYn32r44GzxGxJfA54LXA/cCNEbEsM2/vZD7UGtbnYGlFfToUXe/w/Bws\n/VCf3kloXifqc6L6OG2/Vm1p+ul0y/NBwMrMvAcgIi4FjgR65uRvt8bBPNZDSX32x6Xt9dnuYKzd\n67c+B0srgoOJ1vGVBdtOKk/j6Pv69M7SMANfnwNWXxOZcn3aWNE9nQ6edwXuq32/Hzi4PkNEnASc\nVL4+ERF31SbvDKwba+VxXoty2QHvH2NfurQPL9rM5dpan4NgCvU5lbLpVn22zFjnRydMZdutOH9f\ned6ztt+2+oTBPkdb+Pe0leVgfY6hRfXV6X3sZn1OSTf/znbaJGKupuqz5x4YzMzzgfNHmxYRyzNz\nboez1BaDtC/jmS712Wq9Wjbj1WcrdXP/u132nd6+5+jE+qkcpnt9Dto+tvNv7qCV1Xhava+dHqpu\nNbBb7fvskqb+ZH0OFutzsFifg8X6HCzWZx/rdPB8I7BXROwREdsAxwDLOpwHtY71OVisz8FifQ4W\n63OwWJ99rKPdNjJzQ0ScAlxDNTTLhZl52yRW0fbbxR3U9/tifbZVx8umBfXZSt08Nrp9XLZk+y2q\nz26XRa/oejlYn03ri33skb+3fVFWLdLSfY3MbOX6JEmSpIHl67l7XET8JCIWTWH5+yNi3hjTXhMR\nqzZ33YKIGIqIE8eYNiciMiJ67sFcSZK0eXo2eI6Ir0XEl0ek/VlEPBQRu7RhW3+IiCciYn1E/DAi\n9m7lNlqpBL0ZEad1Oy+9aLLHTkTsEBEXRsQDEfF4RPwyIpZ0LseSJKlf9GzwDJwKHB4RrwWIiDcA\n1wIbgONbtZHylh+AT2TmdlRjL64FvjjF9a6KiBURcUtELC9pMyLi2oi4u/zesaRHRHw2IlZGxC8i\n4oAJVn88sB5YOJU8dlNELIiIu8o+tzpQHXnsPJeqPk/LzDUj8rEV8BlgO2Af4PnAG4GVLc7TMG0+\nPvraaGXTxm1dGBFrI+LWWtqo9dChbZ8REavLvt8SEUe0Y9tN5K2d52dPaNU5GBHHl/nvjoiW/W9q\npX6uz8mco/1eT60wRnntHxE/K8f79yPiebVpHy7ldVdEvK6W3tPHTETsFhE/iojbI+K2iDi1pHfm\n2MjMnv0B3gb8GtgeeBgYArYBfk4V8PyKatDrS4EdyzJbAN8CHgAeKcvsU1vn16heiXk18BtgXkk7\nozbPG4FHR+TlRODOko+rgN1K+lZAAn9R8vM4cDrVgOfLgceApcDWwCeBJcB7Sr5/B3wXOK6sM4AP\nlPRHqd55/1NgUS0f25d8vx14CnjpiHwuAu4t619S8jGvTPtPwMVlH24D/hpY1YV63bKU1Z61+ty3\nTcfOtsDfAleV9DPK8fG1UjcnArcCbxpnXX9K9WT0o+X3n9amDQEn1vbrU6Xs7wFOLsfGVqOscxWw\n84i0TwJLyuclwHnl8xG14+MQ4IZun5ttPj6eVTZt3NZhwAHArRPVQ4e2fQbwV10u/7afn73w04pz\nEJhRzvUZwI7l847d3rdBqs/JnKP9XE9tLq8bgT8rn08Azi6f9y3Hw3OAPcpxsmU/HDPALsAB5fP2\nwC/L/nTk2Ojllmcy85vAzcAPqIKgd2bmH6gCwjdTHSSzgSeAz9YWvQLYC/hjqsDo4hGrfgdwJlWB\n/6w+ISK2A46l1vIYEUcBH6J6deYLgBuAr49Y52uBlwKvAD4K7AS8m+ptNS8Dji7LrwLOohqW5j7g\n/1FV9lfLuj9O1ar8EkZ/49BbqYLfbwL/Qq0VPiL2A/6p7N+uwAtLGTScRTWu5J5UB1K3rr43vpa0\n1GfjtaQtUzt2llK9nemk2uQjqQLoHYBLgOuBcyLiXRGxV309ETEDuJLq+NoJ+DRwZUTsNMpm3w38\nOVV9z6Wqq8k4EriofL4IeFMt/atZuR7YIVrcdWm6yswfU51vdWPVQye23Qvafn72sMmeg68Drs3M\n9Zn5MNXd0QWdzvQE+ro+J3mO9nM9tcQY5bU38OPy+VrgqPL5SODSzHwyM39NFfccRB8cM5m5JjNv\nLp8fB+6gins6cmz0dPBcvJcqELkpMxuvsjwQuDkzV2fm76kC4bdFxBaZ+UxmfiUzHy/TzgAOjIht\na+u8PDN/VuZ9sqQtiYhHqFqOD2J4YPkeqm4dd2XmBqoA96CI2LU2z3llm7+gqsTfAl+iCnBXUwVU\ns4DDgQuA64CZVFdGLwR+TxV43ULVwj0L+DvgP0aUx/FUB/szVAH8O2LTA2lvA76bmT8t+/URqqus\nhqOBj2fmw5l5L1Wg3Q2jvZZ01zHmnYr3Aq8CzqodOwA/y8zvlvr/HfA+qiD6FOD2clvn8DLv64G7\nM/PizNyQmUup6ucNo2zvaODvM/O+zFxP1eI9lgR+GBE3RfX6VYBZualbyQNUxwB0rrx6xWhl00lj\n1UOnnFJuK17Yri4jE5gux1srzsF+KKt+yONkDWI9tdNtbAp+38aml7MMRHlFxByqGOsGOnRs9Hzw\nnJkPUgW0D9eSdwL+PCIeKQHvipI+MyK2jIhPRsQ9EfEYm1qQd64tXy+ohnMzcweqWxdPUbVcN7wI\n+Fxte+uAZ6havRserH3+HVU3kAOoguWX1Nb3QuDerO4XZGY+Vrb3gjJtY95KgHx/43s5QA6jCvQA\nLqfqq9u4Shq5/BMMvwLdZcS+3ztKOQyMcuyso/rDUXffiPl+l5mfyMwDqY6ty4BvllbnF/LscrqX\n0U+uYeU/ynJ1h9aOj5Mj4rAReUqqf+7T0bhl00ldqIfPA39CdRdrDdUFtNrDc3AAWE9NOQF4b0Tc\nRHXH/Q9dzk/LlN4C3wY+UOKpjdp5bPR88Fw8TRVcNjwGXJCZO9R+npuZD1A9RHcEVYvj84EXl2Xq\nLbBjFmZmrgL+EvjHiHhOSb4PWDxie3+UmTeMk+eHy/rWAndTtTI/WNJfVG4XrI2I7an6TW9N9c9y\nN8prOiNiC4YH6AvLflwVEQ9QXRhsw6ZW8sby1Q5XB9WM2vIPMPx1oLuPk/926vZrScer/8eAT1B1\nE9qDqlvNi0bMtjuj53dY+TNO+Wbm6vJ7LdVF0EHAg43uGI3jo8ze7fLqqDHKppPGqoe2y8wHM/Pp\ncuH8RTq/7zBNjrcWnYP9UFb9kMfJGsR6apvMvDMz55cGoqVU/Zmhz8srIramCpwvyczvlOSOHBv9\nEjw/CcyOTa+xfBI4ICJ2B4iImRHxxjLv9mX6Q1QPyJ0z2Y1l5lVULZaN8Xu/AHw0IvYp29shIsbr\nz7oF8Nwy77bAHKoW4GVU/bMXUz2sdwXVrf1bqbpsXEHV0T/K9v+S4RcNC4H/RdUq1fh5O/CGcnv3\nm8CREfHyEvh/nOGB4mXAR0r+d6fqptANPfVa0oj4WET894jYJqqROU6letj0Lqr+9ntHxDsiYquI\neDvVQwlXjLKqy4D3R8TsUh+jPqEcEduWi6bG8TGf6hhYxqYLoeOB75XPy4CF5WnhQ6geZl3DABqn\nbJthy84AAA2BSURBVDpprHpouxF92d9M5/cdeuz8bIcWnoPXAPMjYsdyzs8vab1kEOtzEOupbSJi\nZvm9BfA3VDENVOV1TEQ8JyL2oLpD/m/0wTETEUHVNfaOzPx0bVJnjo3sgacmJ/qhesjuI1RPU/6K\nqvI/RNWi+zhVC2zj6dHtge+X9FWl8BKYU6YPG1ljnLTjgP8LbFO+L6L64/pYSf9iSd+qvv6S9u9U\nt+x/TtVl4F+pDtadqPo6r6XqE/1wqdBdqUYA+VXJ872MGG0DOLQsM2NEPoOqD+57ctOTtPcx+mgb\n21F1+XiELo62kZuefG3U50fbfOy8pvb9DOBrI+b5m1rdrqcaQaM+osahwE2lTm6iut3bmDbEptE2\nGsPePUQ10seoo21QPbD589rx8dGS3jg+7qbqKz+jVseN42MFMLfb52Qb62vUsmnj9pZS3TF4qpwr\ni8eqhw5t++JSx78ofxt26VI9dOT87LXjbHPOwfI3d2X5eVe3923Q6nMy52i/11Mby+vUUv+/BM6l\nvF26zP/RUl53AYf3yzFD9X85y9/KW8rPEZ06Nnw9tyRJktSkfum2IUmSJHWdwbMkSZLUJINnSZIk\nqUkGz5IkSVKTtpp4lu7Zeeedc86cORu//+Y3v2Hbbbcde4FpplXlcdNNN63LzBdMPOfUjKzPbhqk\nY2nkvnSqPiVJmo56OnieM2cOy5cv3/h9aGiIefPmdS9DPaZV5RERHXnT4Mj67KZBOpZG7kun6lOS\npOnIbhuSJElSkwyeJUmSpCb1dLcNTd6cJVdOOM+qc1/fgZx0xkT7O0j7KkmSus+WZ0mSJKlJBs+S\nJElSkwyeJUmSpCbZ51lqI/tkS5I0WGx5liRJkppk8CxJkiQ1yW4b6pp+GFbPbheSJKnOlmdJkiSp\nSQbPkiRJUpMMniVJkqQmGTxLkiRJTTJ4liRJkppk8CxJkiQ1yeBZkiRJapLBsyRJktQkg2dtFBGr\nImJFRNwSEctL2oyIuDYi7i6/dyzpERGfjYiVEfGLiDigu7mXJElqP4NnjfTKzHxpZs4t35cA12Xm\nXsB15TvA4cBe5eck4PMdz6kkSVKHGTxrIkcCF5XPFwFvqqV/NSvXAztExC7dyKAkSVKnbNXtDKin\nJPDDiEjgnzPzfGBWZq4p0x8AZpXPuwL31Za9v6StqaURESdRtUwza9YshoaGNk47bb8NE2aoPv9o\nJlrHWMs/8cQTE657Kutv1fLNaHZfJEnS1E0peI6IVcDjwNPAhsycGxEzgG8Ac4BVwNGZ+XBEBPAP\nwBHAb4FFmXnzVLavljs0M1dHxEzg2oi4sz4xM7ME1k0rAfj5AHPnzs158+ZtnLZoyZUTLr/quHnj\nTp9oHWMtPzQ0RD0vrV5/q5ZvRrP7IkmSpq4V3TbsIzsgMnN1+b0WuBw4CHiw0R2j/F5bZl8N7FZb\nfHZJkyRJGljt6PNsH9k+FBHbRsT2jc/AfOBWYBlwfJnteOB75fMyYGEZdeMQ4NFa9w5JkqSBNNU+\nzx3tI2vfzuFGK48p9COeBVxe9a5hK+DrmXl1RNwIXBYRi4F7gaPL/D+g6oKzkqobzrs2Zx8kSZL6\nyVSD5472kbVv53Cjlcfm9iPOzHuA/UdJfwh49SjpCZzcbF4lSZIGwZSC53of2YgY1kc2M9fYR7b1\n5tSC49P229BUsCxJkqTW2OzgufSL3SIzH6/1kT2LTX1kz+XZfWRPiYhLgYPZjD6yK1Y/Om6wuOrc\n1096PyRJkqRmTaXl2T6ykiRJmlY2O3i2j6wkSZKmG1/PLUmSJDXJ4FmSJElqksGzJEmS1CSDZ0mS\nJKlJBs+SJElSkwyeJUmSpCZN9fXcktpoThNvkPzKgm07kBNJkgS2PEuSJElNM3iWJEmSmmTwLEmS\nJDXJ4FmSJElqksGzJEmS1CSDZwEQEbtFxI8i4vaIuC0iTi3pZ0TE6oi4pfwcUVvmwxGxMiLuiojX\ndS/3kiRJneFQdT2mmaHJ2mQDcFpm3hwR2wM3RcS1ZdpnMvNT9ZkjYl/gGOC/Ai8E/iUi9s7Mpzua\na0mSpA6y5VkAZOaazLy5fH4cuAPYdZxFjgQuzcwnM/PXwErgoPbnVJIkqXtsedazRMQc4GXADcAr\ngFMiYiGwnKp1+mGqwPr62mL3M0qwHREnAScBzJo1i6GhoY3TTttvw4R5qc8/monWMdbyTzzxxITr\nnsr6O7U8NL8vkiRp6gyeNUxEbAd8G/hAZj4WEZ8Hzgay/P474IRm15eZ5wPnA8ydOzfnzZu3cdqi\nJrqorDpu3rjTJ1rHWMsPDQ1Rz0ur19+p5aF6w2Az+yJJkqbObhvaKCK2pgqcL8nM7wBk5oOZ+XRm\nPgN8kU1dM1YDu9UWn13SJEmSBpbBswCIiAC+BNyRmZ+upe9Sm+3NwK3l8zLgmIh4TkTsAewF/Fun\n8itJktQNdttQwyuAdwIrIuKWkvYR4NiIeClVt41VwP8EyMzbIuIy4HaqkTpOdqQNSZI06AyeBUBm\n/gSIUSb9YJxlzgHOaVumJEmSeozB8yRNNA7zqnNf36GcSJIkqdMMnkfo4ktKJEmS1ON8YFCSJElq\n0kC1PNtqLEmSpHay5VmSJElqksGzJEmS1CSDZ0mSJKlJBs+SJElSkwbqgcF+4EONkiRJ/cuWZ0mS\nJKlJtjy3mC3LkiRJg8uWZ0mSJKlJBs+SJElSkwyeJUmSpCYZPEuSJElNMniWJEmSmtTx4DkiFkTE\nXRGxMiKWdHr7ai3rU5IkTScdDZ4jYkvgc8DhwL7AsRGxbyfzoNaxPiVJ0nTT6Zbng4CVmXlPZv4B\nuBQ4ssN5UOtYn5IkaVqJzOzcxiLeCizIzBPL93cCB2fmKbV5TgJOKl//M3BXbRU7A+s6lN1+0Kry\neFFmvmCyC7WgPrtpkI6lkfuyWfUpSZIm1nNvGMzM84HzR5sWEcszc26Hs9Sz+qE8xqvPbuqHsmvW\nIO2LJEm9rtPdNlYDu9W+zy5p6k/WpyRJmlY6HTzfCOwVEXtExDbAMcCyDudBrWN9SpKkaaWj3TYy\nc0NEnAJcA2wJXJiZt01iFT13+7/LuloeLajPbhqkY2mQ9kWSpJ7W0QcGJUmSpH7mGwYlSZKkJhk8\nS5IkSU3qevAcERdGxNqIuLWWtn9E/CwiVkTE9yPieSV9TkT8LiJuKT9fqC1zYJl/ZUR8NiKiG/sz\nFRGxW0T8KCJuj4jbIuLUkj4jIq6NiLvL7x1LepR9XRkRv4iIA2rrOr7Mf3dEHN+tfWqHVpVTRLyy\ndizdEhG/j4g3jbK9RRHxH7X5TuzivvyXcm48GRF/NWJdE74qPSKeExHfKPPcEBFzWrUvkiRNB10P\nnoGvAAtGpF0ALMnM/YDLgQ/Vpv0qM19aft5TS/888G5gr/Izcp39YANwWmbuCxwCnFxed70EuC4z\n9wKuK9+hei12Y39PoioDImIGcDpwMNVbAE9vBF8DoiXllJk/ahxLwKuA3wI/HGOb36gddxd0cV/W\nA+8HPlVfySRelb4YeDgzXwx8BjivhfsiSdLA63rwnJk/pgoI6vYGflw+XwscNd46ImIX4HmZeX1W\nT0B+FXhWC2Kvy8w1mXlz+fw4cAewK9Urry8qs13Epn07EvhqVq4Hdihl8Trg2sxcn5kPU5VhP15M\njKqF5VT3VuCqzPxt23egZrL7kplrM/NG4KkRq2r2Ven19X4LeHU/3qWRJKlbuh48j+E2Nv3jfxvD\nX8SxR0T8e0T8a0T8j5K2K3B/bZ77S1rfKrfTXwbcAMzKzDVl0gPArPJ5V+C+2mKN/R4rfeBMsZzq\njgGWjrOpo0qXj29FxG7jzLfZmtyXsTRb5xvny8wNwKPATpudaUmSppleDZ5PAN4bETcB2wN/KOlr\ngN0z82XAB4GvN/pDD5KI2A74NvCBzHysPq20rDu+IK0rp9IKvR/VeNWj+T4wJzP/G1Ur/kVjzLfZ\nrHNJkvpDTwbPmXlnZs7PzAOpWgN/VdKfzMyHyuebSvreVK+Enl1bRd++JjoitqYKoi7JzO+U5Acb\n3QzK77UlfazXYw/8a7NbVE4NRwOXZ+bIrhAAZOZDmflk+XoBcGBr9qIyyX0ZS7N1vnG+iNgKeD7w\n0ObnXpKk6aUng+eImFl+bwH8DfCF8v0F5cEoImJPqgfA7im3tx+LiENK/82FwPe6kvkpKHn/EnBH\nZn66NmkZ0Bgx43g27dsyYGEZTeIQ4NFSFtcA8yNix/Kg4HzGblXtOy0sp4ZjGafLxoj+0W+k6pfc\nEpuxL2Np9lXp9fW+Ffjf6ZuSJElqWtffMBgRS4F5wM7Ag1SjRGwHnFxm+Q7w4czMiDgKOIvqYaln\ngNMz8/tlPXOpRu74I+Aq4H39FhRExKHA/wFWUO0fwEeo+sBeBuwO3AscnZnrS+D1T1QPA/4WeFdm\nLi/rOqEsC3BOZn65YzvSZi0upznAT4HdMvOZ2jbOApZn5rKI+FuqoHkD1cOtf5GZd3ZpX/4YWA48\nr8z/BLBvZj4WEUcAf8+mV6WfM8q+PBe4mKpv9XrgmMy8pxX7IknSdND14FmSJEnqFz3ZbUOSJEnq\nRQbPkiRJUpMMniVJkqQmGTxLkiRJTTJ4liRJkppk8CxJkiQ1yeBZkiRJatL/B6dAqFklreijAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x720 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HAR4i0bIeE7",
        "colab_type": "text"
      },
      "source": [
        "## Manage categorial variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-OS-ihfIeE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c551eacc-f5fe-4bce-fb92-eb5e80337188"
      },
      "source": [
        "def oneHotEncode(df,colNames):\n",
        "    for col in colNames:\n",
        "        if( df[col].dtype == np.dtype('object')):\n",
        "            dummies = pd.get_dummies(df[col],prefix=col)\n",
        "            df = pd.concat([df,dummies],axis=1)\n",
        "\n",
        "            #drop the encoded column\n",
        "            df.drop([col],axis = 1 , inplace=True)\n",
        "    return df\n",
        "    \n",
        "\n",
        "print('There were {} columns before encoding categorical features'.format(combined.shape[1]))\n",
        "combined = oneHotEncode(combined, cat_cols)\n",
        "print('There are {} columns after encoding categorical features'.format(combined.shape[1]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There were 59 columns before encoding categorical features\n",
            "There are 214 columns after encoding categorical features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y70S3v7mIeFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Split back\n",
        "train = combined[:1460]\n",
        "test = combined[1460:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "794ox8-SIeFC",
        "colab_type": "text"
      },
      "source": [
        "### Normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXukeuMwIeFC",
        "colab_type": "text"
      },
      "source": [
        "## Regression Loss functions\n",
        "### The mean absolute percentage error (MAPE)\n",
        "MAPE, also known as mean absolute percentage deviation (MAPD), is a measure of prediction accuracy of a forecasting method in statistics, for example in trend estimation, also used as a Loss function for regression problems in Machine Learning. It usually expresses accuracy as a percentage, and is defined by the formula:\n",
        "\n",
        "$${\\displaystyle {\\mbox{M}}={\\frac {100\\%}{n}}\\sum _{t=1}^{n}\\left|{\\frac {A_{t}-F_{t}}{A_{t}}}\\right|,} {\\displaystyle {\\mbox{M}}={\\frac {100\\%}{n}}\\sum _{t=1}^{n}\\left|{\\frac {A_{t}-F_{t}}{A_{t}}}\\right|,}$$\n",
        "where $A_t$ is the actual value and $F_t$ is the forecast value. The difference between $A_t$  and $F_t$ is divided by the actual value $A_t$  again. The absolute value in this calculation is summed for every forecasted point in time and divided by the number of fitted points n. Multiplying by 100% makes it a percentage error.\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\n",
        "\n",
        "### mean_absolute_error\n",
        "### mean_squared_error\n",
        "### mean_squared_logarithmic_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxq_FRPwIeFD",
        "colab_type": "text"
      },
      "source": [
        "## Build Keras model - train and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHCtSrvdIeFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "f30aedb0-5586-431f-9596-e3ef457773c8"
      },
      "source": [
        "def get_model():\n",
        "    \n",
        "    NN_model = Sequential()\n",
        "\n",
        "    # The Input Layer :\n",
        "    NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
        "\n",
        "    # The Hidden Layers :\n",
        "    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "    # The Output Layer :\n",
        "    NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "    \n",
        "    return NN_model\n",
        "np.random.seed(1235)\n",
        "NN_model = get_model()\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', \n",
        "                 metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               27520     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 192,385\n",
            "Trainable params: 192,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYBY9rvzIeFH",
        "colab_type": "text"
      },
      "source": [
        "### Monitor Training\n",
        "* EarlyStopping\n",
        "* Save best models\n",
        "* ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AfsELTXrIeFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2fc4e2a-96d0-4e09-fd9e-3b3cb43652af"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "np.random.seed(1235)\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model_e200_b32_oAdam.h5', verbose=1, \n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True, mode='auto') \n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=5,\n",
        "                              verbose=1, mode='auto')\n",
        "\n",
        "history = NN_model.fit(train, target,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,callbacks=[checkpoint, early],\n",
        "                    validation_split=0.3)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 1021 samples, validate on 439 samples\n",
            "Epoch 1/200\n",
            "1021/1021 [==============================] - 5s 5ms/step - loss: 21.8687 - mean_absolute_error: 176554.8824 - val_loss: 5.0075 - val_mean_absolute_error: 159802.5926\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 5.00747, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 2/200\n",
            "1021/1021 [==============================] - 0s 215us/step - loss: 1.5710 - mean_absolute_error: 112961.6586 - val_loss: 0.1248 - val_mean_absolute_error: 49583.2969\n",
            "\n",
            "Epoch 00002: val_loss improved from 5.00747 to 0.12480, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 3/200\n",
            "1021/1021 [==============================] - 0s 225us/step - loss: 0.1372 - mean_absolute_error: 57943.2173 - val_loss: 0.1151 - val_mean_absolute_error: 48071.1863\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.12480 to 0.11509, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 4/200\n",
            "1021/1021 [==============================] - 0s 202us/step - loss: 0.1214 - mean_absolute_error: 53051.4445 - val_loss: 0.1089 - val_mean_absolute_error: 46690.5225\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.11509 to 0.10890, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 5/200\n",
            "1021/1021 [==============================] - 0s 231us/step - loss: 0.1141 - mean_absolute_error: 51417.0665 - val_loss: 0.1010 - val_mean_absolute_error: 44787.1097\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.10890 to 0.10102, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 6/200\n",
            "1021/1021 [==============================] - 0s 216us/step - loss: 0.1051 - mean_absolute_error: 48759.1714 - val_loss: 0.0923 - val_mean_absolute_error: 42759.1973\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.10102 to 0.09228, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 7/200\n",
            "1021/1021 [==============================] - 0s 218us/step - loss: 0.0940 - mean_absolute_error: 45671.0684 - val_loss: 0.0822 - val_mean_absolute_error: 40368.2223\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.09228 to 0.08221, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 8/200\n",
            "1021/1021 [==============================] - 0s 218us/step - loss: 0.0834 - mean_absolute_error: 42567.9228 - val_loss: 0.0726 - val_mean_absolute_error: 37461.3118\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.08221 to 0.07257, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 9/200\n",
            "1021/1021 [==============================] - 0s 222us/step - loss: 0.0723 - mean_absolute_error: 39177.3036 - val_loss: 0.0640 - val_mean_absolute_error: 34650.3345\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.07257 to 0.06402, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 10/200\n",
            "1021/1021 [==============================] - 0s 207us/step - loss: 0.0633 - mean_absolute_error: 36365.8118 - val_loss: 0.0607 - val_mean_absolute_error: 35564.2770\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.06402 to 0.06068, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 11/200\n",
            "1021/1021 [==============================] - 0s 220us/step - loss: 0.0575 - mean_absolute_error: 34427.6910 - val_loss: 0.0548 - val_mean_absolute_error: 32087.0417\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.06068 to 0.05477, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 12/200\n",
            "1021/1021 [==============================] - 0s 200us/step - loss: 0.0531 - mean_absolute_error: 32719.9210 - val_loss: 0.0534 - val_mean_absolute_error: 31291.2003\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.05477 to 0.05337, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 13/200\n",
            "1021/1021 [==============================] - 0s 205us/step - loss: 0.0532 - mean_absolute_error: 32298.0781 - val_loss: 0.0533 - val_mean_absolute_error: 32044.9081\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.05337 to 0.05327, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 14/200\n",
            "1021/1021 [==============================] - 0s 210us/step - loss: 0.0511 - mean_absolute_error: 31868.1741 - val_loss: 0.0554 - val_mean_absolute_error: 31137.1469\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.05327\n",
            "Epoch 15/200\n",
            "1021/1021 [==============================] - 0s 206us/step - loss: 0.0503 - mean_absolute_error: 31252.9057 - val_loss: 0.0523 - val_mean_absolute_error: 30941.8234\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.05327 to 0.05229, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 16/200\n",
            "1021/1021 [==============================] - 0s 211us/step - loss: 0.0490 - mean_absolute_error: 30940.2324 - val_loss: 0.0522 - val_mean_absolute_error: 31246.6980\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.05229 to 0.05218, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 17/200\n",
            "1021/1021 [==============================] - 0s 224us/step - loss: 0.0495 - mean_absolute_error: 31239.4488 - val_loss: 0.0517 - val_mean_absolute_error: 30922.4049\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.05218 to 0.05169, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 18/200\n",
            "1021/1021 [==============================] - 0s 208us/step - loss: 0.0478 - mean_absolute_error: 30502.2138 - val_loss: 0.0547 - val_mean_absolute_error: 30911.4847\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.05169\n",
            "Epoch 19/200\n",
            "1021/1021 [==============================] - 0s 218us/step - loss: 0.0484 - mean_absolute_error: 30752.3699 - val_loss: 0.0517 - val_mean_absolute_error: 30663.2155\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.05169\n",
            "Epoch 20/200\n",
            "1021/1021 [==============================] - 0s 209us/step - loss: 0.0491 - mean_absolute_error: 30477.8219 - val_loss: 0.0519 - val_mean_absolute_error: 31643.3379\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.05169\n",
            "Epoch 21/200\n",
            "1021/1021 [==============================] - 0s 224us/step - loss: 0.0466 - mean_absolute_error: 29966.6435 - val_loss: 0.0514 - val_mean_absolute_error: 30413.5408\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.05169 to 0.05142, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 22/200\n",
            "1021/1021 [==============================] - 0s 207us/step - loss: 0.0460 - mean_absolute_error: 29737.2702 - val_loss: 0.0507 - val_mean_absolute_error: 30557.5916\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.05142 to 0.05074, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 23/200\n",
            "1021/1021 [==============================] - 0s 210us/step - loss: 0.0467 - mean_absolute_error: 29875.2146 - val_loss: 0.0506 - val_mean_absolute_error: 30863.4750\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.05074 to 0.05064, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 24/200\n",
            "1021/1021 [==============================] - 0s 206us/step - loss: 0.0455 - mean_absolute_error: 29549.0764 - val_loss: 0.0507 - val_mean_absolute_error: 30848.2777\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.05064\n",
            "Epoch 25/200\n",
            "1021/1021 [==============================] - 0s 227us/step - loss: 0.0451 - mean_absolute_error: 29093.3789 - val_loss: 0.0503 - val_mean_absolute_error: 30528.6215\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.05064 to 0.05034, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 26/200\n",
            "1021/1021 [==============================] - 0s 215us/step - loss: 0.0455 - mean_absolute_error: 29215.2093 - val_loss: 0.0503 - val_mean_absolute_error: 30730.8786\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.05034 to 0.05033, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 27/200\n",
            "1021/1021 [==============================] - 0s 215us/step - loss: 0.0444 - mean_absolute_error: 29022.6920 - val_loss: 0.0497 - val_mean_absolute_error: 30195.7625\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.05033 to 0.04970, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 28/200\n",
            "1021/1021 [==============================] - 0s 212us/step - loss: 0.0442 - mean_absolute_error: 28807.1994 - val_loss: 0.0498 - val_mean_absolute_error: 30262.0801\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.04970\n",
            "Epoch 29/200\n",
            "1021/1021 [==============================] - 0s 232us/step - loss: 0.0442 - mean_absolute_error: 28925.3479 - val_loss: 0.0500 - val_mean_absolute_error: 30090.0755\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.04970\n",
            "Epoch 30/200\n",
            "1021/1021 [==============================] - 0s 231us/step - loss: 0.0464 - mean_absolute_error: 29700.6238 - val_loss: 0.0538 - val_mean_absolute_error: 33033.1970\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.04970\n",
            "Epoch 31/200\n",
            "1021/1021 [==============================] - 0s 219us/step - loss: 0.0438 - mean_absolute_error: 28582.8346 - val_loss: 0.0495 - val_mean_absolute_error: 30433.8566\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.04970 to 0.04946, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 32/200\n",
            "1021/1021 [==============================] - 0s 211us/step - loss: 0.0433 - mean_absolute_error: 28391.9933 - val_loss: 0.0499 - val_mean_absolute_error: 29709.6715\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.04946\n",
            "Epoch 33/200\n",
            "1021/1021 [==============================] - 0s 228us/step - loss: 0.0426 - mean_absolute_error: 28080.7247 - val_loss: 0.0531 - val_mean_absolute_error: 30304.3133\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.04946\n",
            "Epoch 34/200\n",
            "1021/1021 [==============================] - 0s 212us/step - loss: 0.0430 - mean_absolute_error: 28144.3950 - val_loss: 0.0490 - val_mean_absolute_error: 29814.5248\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.04946 to 0.04903, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 35/200\n",
            "1021/1021 [==============================] - 0s 209us/step - loss: 0.0429 - mean_absolute_error: 28133.8395 - val_loss: 0.0498 - val_mean_absolute_error: 29498.2024\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.04903\n",
            "Epoch 36/200\n",
            "1021/1021 [==============================] - 0s 207us/step - loss: 0.0421 - mean_absolute_error: 27989.7780 - val_loss: 0.0492 - val_mean_absolute_error: 29684.6461\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.04903\n",
            "Epoch 37/200\n",
            "1021/1021 [==============================] - 0s 218us/step - loss: 0.0420 - mean_absolute_error: 27735.3558 - val_loss: 0.0488 - val_mean_absolute_error: 29677.6167\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.04903 to 0.04881, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 38/200\n",
            "1021/1021 [==============================] - 0s 217us/step - loss: 0.0422 - mean_absolute_error: 28022.7517 - val_loss: 0.0488 - val_mean_absolute_error: 29952.1118\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.04881 to 0.04878, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 39/200\n",
            "1021/1021 [==============================] - 0s 219us/step - loss: 0.0417 - mean_absolute_error: 27710.0162 - val_loss: 0.0487 - val_mean_absolute_error: 29492.5281\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.04878 to 0.04874, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 40/200\n",
            "1021/1021 [==============================] - 0s 206us/step - loss: 0.0421 - mean_absolute_error: 27795.7251 - val_loss: 0.0487 - val_mean_absolute_error: 29702.5783\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.04874 to 0.04867, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 41/200\n",
            "1021/1021 [==============================] - 0s 226us/step - loss: 0.0430 - mean_absolute_error: 28380.3513 - val_loss: 0.0492 - val_mean_absolute_error: 29325.3154\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.04867\n",
            "Epoch 42/200\n",
            "1021/1021 [==============================] - 0s 206us/step - loss: 0.0424 - mean_absolute_error: 27676.1899 - val_loss: 0.0488 - val_mean_absolute_error: 29333.4952\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.04867\n",
            "Epoch 43/200\n",
            "1021/1021 [==============================] - 0s 210us/step - loss: 0.0419 - mean_absolute_error: 27570.3229 - val_loss: 0.0486 - val_mean_absolute_error: 29430.1946\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.04867 to 0.04863, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 44/200\n",
            "1021/1021 [==============================] - 0s 214us/step - loss: 0.0416 - mean_absolute_error: 27427.1933 - val_loss: 0.0489 - val_mean_absolute_error: 30302.7176\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.04863\n",
            "Epoch 45/200\n",
            "1021/1021 [==============================] - 0s 220us/step - loss: 0.0419 - mean_absolute_error: 27483.3761 - val_loss: 0.0496 - val_mean_absolute_error: 30600.3293\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.04863\n",
            "Epoch 46/200\n",
            "1021/1021 [==============================] - 0s 217us/step - loss: 0.0413 - mean_absolute_error: 27377.7059 - val_loss: 0.0487 - val_mean_absolute_error: 30091.8187\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.04863\n",
            "Epoch 47/200\n",
            "1021/1021 [==============================] - 0s 213us/step - loss: 0.0407 - mean_absolute_error: 27220.4875 - val_loss: 0.0488 - val_mean_absolute_error: 29158.7610\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.04863\n",
            "Epoch 48/200\n",
            "1021/1021 [==============================] - 0s 226us/step - loss: 0.0409 - mean_absolute_error: 27202.9544 - val_loss: 0.0481 - val_mean_absolute_error: 29186.8951\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.04863 to 0.04815, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 49/200\n",
            "1021/1021 [==============================] - 0s 223us/step - loss: 0.0417 - mean_absolute_error: 27537.5267 - val_loss: 0.0505 - val_mean_absolute_error: 29334.4519\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.04815\n",
            "Epoch 50/200\n",
            "1021/1021 [==============================] - 0s 223us/step - loss: 0.0412 - mean_absolute_error: 27093.7283 - val_loss: 0.0482 - val_mean_absolute_error: 29642.4907\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.04815\n",
            "Epoch 51/200\n",
            "1021/1021 [==============================] - 0s 222us/step - loss: 0.0414 - mean_absolute_error: 27248.9883 - val_loss: 0.0480 - val_mean_absolute_error: 29661.1545\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.04815 to 0.04804, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 52/200\n",
            "1021/1021 [==============================] - 0s 214us/step - loss: 0.0414 - mean_absolute_error: 27559.2659 - val_loss: 0.0499 - val_mean_absolute_error: 31012.3632\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.04804\n",
            "Epoch 53/200\n",
            "1021/1021 [==============================] - 0s 215us/step - loss: 0.0416 - mean_absolute_error: 27634.7468 - val_loss: 0.0480 - val_mean_absolute_error: 29090.5052\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.04804 to 0.04800, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 54/200\n",
            "1021/1021 [==============================] - 0s 214us/step - loss: 0.0404 - mean_absolute_error: 26809.8891 - val_loss: 0.0475 - val_mean_absolute_error: 29238.9291\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.04800 to 0.04750, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 55/200\n",
            "1021/1021 [==============================] - 0s 213us/step - loss: 0.0409 - mean_absolute_error: 27099.3272 - val_loss: 0.0477 - val_mean_absolute_error: 29620.6492\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.04750\n",
            "Epoch 56/200\n",
            "1021/1021 [==============================] - 0s 200us/step - loss: 0.0400 - mean_absolute_error: 26730.1684 - val_loss: 0.0474 - val_mean_absolute_error: 29079.2079\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.04750 to 0.04744, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 57/200\n",
            "1021/1021 [==============================] - 0s 243us/step - loss: 0.0397 - mean_absolute_error: 26646.4517 - val_loss: 0.0488 - val_mean_absolute_error: 28792.5993\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.04744\n",
            "Epoch 58/200\n",
            "1021/1021 [==============================] - 0s 212us/step - loss: 0.0390 - mean_absolute_error: 26335.1159 - val_loss: 0.0508 - val_mean_absolute_error: 29374.6488\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.04744\n",
            "Epoch 59/200\n",
            "1021/1021 [==============================] - 0s 219us/step - loss: 0.0397 - mean_absolute_error: 26679.0732 - val_loss: 0.0486 - val_mean_absolute_error: 28790.8217\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.04744\n",
            "Epoch 60/200\n",
            "1021/1021 [==============================] - 0s 210us/step - loss: 0.0398 - mean_absolute_error: 26636.6071 - val_loss: 0.0526 - val_mean_absolute_error: 29921.3500\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.04744\n",
            "Epoch 61/200\n",
            "1021/1021 [==============================] - 0s 203us/step - loss: 0.0391 - mean_absolute_error: 26574.7733 - val_loss: 0.0468 - val_mean_absolute_error: 29024.3697\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.04744 to 0.04684, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 62/200\n",
            "1021/1021 [==============================] - 0s 224us/step - loss: 0.0388 - mean_absolute_error: 26392.3412 - val_loss: 0.0490 - val_mean_absolute_error: 28857.3922\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.04684\n",
            "Epoch 63/200\n",
            "1021/1021 [==============================] - 0s 207us/step - loss: 0.0389 - mean_absolute_error: 26513.8167 - val_loss: 0.0464 - val_mean_absolute_error: 28310.2545\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.04684 to 0.04636, saving model to best_model_e200_b32_oAdam.h5\n",
            "Epoch 64/200\n",
            "1021/1021 [==============================] - 0s 207us/step - loss: 0.0385 - mean_absolute_error: 26099.5270 - val_loss: 0.0464 - val_mean_absolute_error: 28549.4180\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.04636\n",
            "Epoch 65/200\n",
            "1021/1021 [==============================] - 0s 215us/step - loss: 0.0383 - mean_absolute_error: 26070.4077 - val_loss: 0.0477 - val_mean_absolute_error: 28286.2501\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.04636\n",
            "Epoch 66/200\n",
            "1021/1021 [==============================] - 0s 220us/step - loss: 0.0390 - mean_absolute_error: 26488.8300 - val_loss: 0.0528 - val_mean_absolute_error: 30002.1785\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.04636\n",
            "Epoch 67/200\n",
            "1021/1021 [==============================] - 0s 201us/step - loss: 0.0390 - mean_absolute_error: 26431.2278 - val_loss: 0.0504 - val_mean_absolute_error: 29244.2859\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.04636\n",
            "Epoch 68/200\n",
            "1021/1021 [==============================] - 0s 206us/step - loss: 0.0395 - mean_absolute_error: 26466.0242 - val_loss: 0.0484 - val_mean_absolute_error: 28629.9227\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.04636\n",
            "Epoch 00068: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGI2fUROIeFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1b1370cf-7517-4b45-d902-4996c2e9f4d0"
      },
      "source": [
        "drow_history(history, 'loss', 2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0mShlFKqW5oslFJKdUuThVJKqW79f+nZwO5/UieyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q8smTovIeFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Load the best model\n",
        "NN_model.load_weights('best_model_e200_b32_oAdam.h5')\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', \n",
        "                 metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD5UV4J2IeFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b3e405dc-3801-459f-a184-58164cb7785c"
      },
      "source": [
        "score=NN_model.evaluate(train, target)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460/1460 [==============================] - 0s 116us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EqVr3PfIeFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7a97cf11-a225-47eb-8401-71ceccca395e"
      },
      "source": [
        "score"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04054630268109988, 26634.26052547089]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwtDzvfJIeFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7c87e03f-9ae3-4895-ea1f-be70b593ee35"
      },
      "source": [
        "def make_submission(prediction, sub_name):\n",
        "    my_submission = pd.DataFrame({'Id':pd.read_csv('test.csv').Id,'SalePrice':prediction})\n",
        "    my_submission.to_csv('{}.csv'.format(sub_name),index=False)\n",
        "    print('A submission file has been made')\n",
        "\n",
        "predictions = NN_model.predict(test)\n",
        "make_submission(predictions[:,0],'submission_oAdam')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A submission file has been made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI7jGTClKx3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "55f5bfcd-8751-4674-fe82-aa5e74ab728e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_model_e200_b32_oAdam.h5  sample_submission.csv\ttrain.csv\n",
            "data_description.txt\t      submission_oAdam.csv.csv\n",
            "sample_data\t\t      test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpsSSVrIIeFY",
        "colab_type": "text"
      },
      "source": [
        "kaggle result: 0.22215\n",
        "************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn7yDIX2Kkac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission_oAdam.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D45jObSgIeFZ",
        "colab_type": "text"
      },
      "source": [
        "## Improvments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw2se5_RIeFa",
        "colab_type": "text"
      },
      "source": [
        "Split the data, for better model comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ4qmLRGIeFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5ecea61c-3631-49a3-d29a-befc36cb08d5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=.3, \n",
        "                                                    random_state=42)\n",
        "X_train.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>MSZoning_C (all)</th>\n",
              "      <th>MSZoning_FV</th>\n",
              "      <th>MSZoning_RH</th>\n",
              "      <th>MSZoning_RL</th>\n",
              "      <th>MSZoning_RM</th>\n",
              "      <th>Street_Grvl</th>\n",
              "      <th>Street_Pave</th>\n",
              "      <th>LotShape_IR1</th>\n",
              "      <th>...</th>\n",
              "      <th>Heating_GasW</th>\n",
              "      <th>Heating_Grav</th>\n",
              "      <th>Heating_OthW</th>\n",
              "      <th>Heating_Wall</th>\n",
              "      <th>HeatingQC_Ex</th>\n",
              "      <th>HeatingQC_Fa</th>\n",
              "      <th>HeatingQC_Gd</th>\n",
              "      <th>HeatingQC_Po</th>\n",
              "      <th>HeatingQC_TA</th>\n",
              "      <th>CentralAir_N</th>\n",
              "      <th>CentralAir_Y</th>\n",
              "      <th>KitchenQual_Ex</th>\n",
              "      <th>KitchenQual_Fa</th>\n",
              "      <th>KitchenQual_Gd</th>\n",
              "      <th>KitchenQual_TA</th>\n",
              "      <th>Functional_Maj1</th>\n",
              "      <th>Functional_Maj2</th>\n",
              "      <th>Functional_Min1</th>\n",
              "      <th>Functional_Min2</th>\n",
              "      <th>Functional_Mod</th>\n",
              "      <th>Functional_Sev</th>\n",
              "      <th>Functional_Typ</th>\n",
              "      <th>PavedDrive_N</th>\n",
              "      <th>PavedDrive_P</th>\n",
              "      <th>PavedDrive_Y</th>\n",
              "      <th>SaleType_COD</th>\n",
              "      <th>SaleType_CWD</th>\n",
              "      <th>SaleType_Con</th>\n",
              "      <th>SaleType_ConLD</th>\n",
              "      <th>SaleType_ConLI</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_Abnorml</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>20</td>\n",
              "      <td>10400</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1970</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1304.0</td>\n",
              "      <td>1304.0</td>\n",
              "      <td>1682</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1682</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>180</td>\n",
              "      <td>3675</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>547.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>547.0</td>\n",
              "      <td>1072</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1072</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2006</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>60</td>\n",
              "      <td>8640</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>732.0</td>\n",
              "      <td>756.0</td>\n",
              "      <td>764</td>\n",
              "      <td>783</td>\n",
              "      <td>0</td>\n",
              "      <td>1547</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>169</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>20</td>\n",
              "      <td>11670</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2006</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1905.0</td>\n",
              "      <td>1905.0</td>\n",
              "      <td>1905</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>191</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2007</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>60</td>\n",
              "      <td>10667</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>385.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>799.0</td>\n",
              "      <td>827</td>\n",
              "      <td>834</td>\n",
              "      <td>0</td>\n",
              "      <td>1661</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>158</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 214 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MSSubClass  LotArea  ...  SaleCondition_Normal  SaleCondition_Partial\n",
              "135           20    10400  ...                     1                      0\n",
              "1452         180     3675  ...                     1                      0\n",
              "762           60     8640  ...                     1                      0\n",
              "932           20    11670  ...                     1                      0\n",
              "435           60    10667  ...                     1                      0\n",
              "\n",
              "[5 rows x 214 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQdryYw1IeFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1235)\n",
        "NN_model = get_model()\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', \n",
        "                 metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IIsFcjdXIeFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b46f9b88-cbee-4bcd-ee71-2e2dbdbbb85d"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "np.random.seed(1235)\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model_e200_b32_oadam_lr.h5', verbose=1, \n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True, mode='auto') \n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=10,\n",
        "                              verbose=1, mode='auto')\n",
        "\n",
        "history = NN_model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,callbacks=[checkpoint, early, reduce_lr],\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 610us/step - loss: 20.9905 - mean_absolute_error: 175308.8878 - val_loss: 4.2798 - val_mean_absolute_error: 157228.3307\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.27982, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 214us/step - loss: 1.2802 - mean_absolute_error: 106848.6608 - val_loss: 0.1355 - val_mean_absolute_error: 52806.7389\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.27982 to 0.13548, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 206us/step - loss: 0.1354 - mean_absolute_error: 57076.3923 - val_loss: 0.1305 - val_mean_absolute_error: 52515.2989\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.13548 to 0.13050, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 221us/step - loss: 0.1220 - mean_absolute_error: 52895.4726 - val_loss: 0.1256 - val_mean_absolute_error: 51011.8003\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.13050 to 0.12558, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 218us/step - loss: 0.1175 - mean_absolute_error: 51769.0013 - val_loss: 0.1200 - val_mean_absolute_error: 49889.2175\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.12558 to 0.12002, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 227us/step - loss: 0.1122 - mean_absolute_error: 50403.4423 - val_loss: 0.1139 - val_mean_absolute_error: 48544.6792\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.12002 to 0.11392, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 223us/step - loss: 0.1068 - mean_absolute_error: 48919.0568 - val_loss: 0.1069 - val_mean_absolute_error: 46790.9672\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.11392 to 0.10685, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0999 - mean_absolute_error: 47100.5762 - val_loss: 0.1011 - val_mean_absolute_error: 45173.2437\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.10685 to 0.10112, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 212us/step - loss: 0.0924 - mean_absolute_error: 45012.1116 - val_loss: 0.0888 - val_mean_absolute_error: 41902.3744\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.10112 to 0.08878, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 205us/step - loss: 0.0843 - mean_absolute_error: 42473.9488 - val_loss: 0.0816 - val_mean_absolute_error: 39632.6791\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.08878 to 0.08161, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 218us/step - loss: 0.0774 - mean_absolute_error: 40269.4484 - val_loss: 0.0700 - val_mean_absolute_error: 36976.3088\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.08161 to 0.07002, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 199us/step - loss: 0.0691 - mean_absolute_error: 37845.9964 - val_loss: 0.0628 - val_mean_absolute_error: 34796.9490\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.07002 to 0.06282, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 224us/step - loss: 0.0637 - mean_absolute_error: 36089.0498 - val_loss: 0.0598 - val_mean_absolute_error: 35420.7170\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.06282 to 0.05982, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 207us/step - loss: 0.0599 - mean_absolute_error: 34956.3438 - val_loss: 0.0528 - val_mean_absolute_error: 32115.5225\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.05982 to 0.05281, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0564 - mean_absolute_error: 33498.2963 - val_loss: 0.0498 - val_mean_absolute_error: 30997.1212\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.05281 to 0.04984, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 212us/step - loss: 0.0540 - mean_absolute_error: 32547.9119 - val_loss: 0.0481 - val_mean_absolute_error: 30561.2845\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.04984 to 0.04807, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 216us/step - loss: 0.0530 - mean_absolute_error: 32302.8418 - val_loss: 0.0467 - val_mean_absolute_error: 29992.5304\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.04807 to 0.04666, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 207us/step - loss: 0.0517 - mean_absolute_error: 31486.6455 - val_loss: 0.0467 - val_mean_absolute_error: 29156.5803\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.04666\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 221us/step - loss: 0.0518 - mean_absolute_error: 31531.6710 - val_loss: 0.0453 - val_mean_absolute_error: 29373.0506\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.04666 to 0.04534, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 226us/step - loss: 0.0507 - mean_absolute_error: 30993.2078 - val_loss: 0.0474 - val_mean_absolute_error: 31179.8571\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.04534\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0506 - mean_absolute_error: 31022.1337 - val_loss: 0.0489 - val_mean_absolute_error: 31727.7657\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.04534\n",
            "Epoch 22/200\n",
            "1022/1022 [==============================] - 0s 208us/step - loss: 0.0503 - mean_absolute_error: 31072.6515 - val_loss: 0.0447 - val_mean_absolute_error: 29519.5161\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.04534 to 0.04468, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 23/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0492 - mean_absolute_error: 30532.4380 - val_loss: 0.0449 - val_mean_absolute_error: 29560.0469\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.04468\n",
            "Epoch 24/200\n",
            "1022/1022 [==============================] - 0s 202us/step - loss: 0.0485 - mean_absolute_error: 30226.9010 - val_loss: 0.0445 - val_mean_absolute_error: 28779.6679\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.04468 to 0.04455, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 25/200\n",
            "1022/1022 [==============================] - 0s 218us/step - loss: 0.0485 - mean_absolute_error: 30058.3202 - val_loss: 0.0451 - val_mean_absolute_error: 29726.1371\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.04455\n",
            "Epoch 26/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0489 - mean_absolute_error: 30228.7690 - val_loss: 0.0445 - val_mean_absolute_error: 28487.8704\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.04455 to 0.04452, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 27/200\n",
            "1022/1022 [==============================] - 0s 203us/step - loss: 0.0499 - mean_absolute_error: 31037.9655 - val_loss: 0.0448 - val_mean_absolute_error: 29647.1619\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.04452\n",
            "Epoch 28/200\n",
            "1022/1022 [==============================] - 0s 213us/step - loss: 0.0480 - mean_absolute_error: 29934.0985 - val_loss: 0.0444 - val_mean_absolute_error: 28987.0579\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.04452 to 0.04439, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 29/200\n",
            "1022/1022 [==============================] - 0s 219us/step - loss: 0.0479 - mean_absolute_error: 29798.2000 - val_loss: 0.0452 - val_mean_absolute_error: 29537.3346\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.04439\n",
            "Epoch 30/200\n",
            "1022/1022 [==============================] - 0s 251us/step - loss: 0.0476 - mean_absolute_error: 29841.6041 - val_loss: 0.0444 - val_mean_absolute_error: 28382.2592\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.04439\n",
            "Epoch 31/200\n",
            "1022/1022 [==============================] - 0s 205us/step - loss: 0.0484 - mean_absolute_error: 30030.5932 - val_loss: 0.0442 - val_mean_absolute_error: 28679.2773\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.04439 to 0.04422, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 32/200\n",
            "1022/1022 [==============================] - 0s 212us/step - loss: 0.0476 - mean_absolute_error: 29747.1813 - val_loss: 0.0442 - val_mean_absolute_error: 29052.1879\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.04422 to 0.04417, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 33/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0474 - mean_absolute_error: 29671.2917 - val_loss: 0.0443 - val_mean_absolute_error: 28417.2942\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.04417\n",
            "Epoch 34/200\n",
            "1022/1022 [==============================] - 0s 222us/step - loss: 0.0474 - mean_absolute_error: 29665.2338 - val_loss: 0.0449 - val_mean_absolute_error: 29881.0710\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.04417\n",
            "Epoch 35/200\n",
            "1022/1022 [==============================] - 0s 223us/step - loss: 0.0475 - mean_absolute_error: 29665.2088 - val_loss: 0.0442 - val_mean_absolute_error: 29081.8599\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.04417\n",
            "Epoch 36/200\n",
            "1022/1022 [==============================] - 0s 226us/step - loss: 0.0469 - mean_absolute_error: 29621.7289 - val_loss: 0.0442 - val_mean_absolute_error: 28029.0987\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.04417\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 37/200\n",
            "1022/1022 [==============================] - 0s 213us/step - loss: 0.0466 - mean_absolute_error: 29217.6411 - val_loss: 0.0441 - val_mean_absolute_error: 29164.5192\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.04417 to 0.04405, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 38/200\n",
            "1022/1022 [==============================] - 0s 229us/step - loss: 0.0464 - mean_absolute_error: 29297.1526 - val_loss: 0.0437 - val_mean_absolute_error: 28799.3636\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.04405 to 0.04368, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 39/200\n",
            "1022/1022 [==============================] - 0s 227us/step - loss: 0.0465 - mean_absolute_error: 29329.5292 - val_loss: 0.0436 - val_mean_absolute_error: 28691.5392\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.04368 to 0.04359, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 40/200\n",
            "1022/1022 [==============================] - 0s 207us/step - loss: 0.0462 - mean_absolute_error: 29237.7469 - val_loss: 0.0435 - val_mean_absolute_error: 28616.5092\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.04359 to 0.04349, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 41/200\n",
            "1022/1022 [==============================] - 0s 224us/step - loss: 0.0465 - mean_absolute_error: 29266.8526 - val_loss: 0.0438 - val_mean_absolute_error: 28942.5312\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.04349\n",
            "Epoch 42/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0462 - mean_absolute_error: 29289.0532 - val_loss: 0.0434 - val_mean_absolute_error: 28469.5389\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.04349 to 0.04338, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 43/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0463 - mean_absolute_error: 29258.8962 - val_loss: 0.0434 - val_mean_absolute_error: 28619.4287\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.04338\n",
            "Epoch 44/200\n",
            "1022/1022 [==============================] - 0s 208us/step - loss: 0.0461 - mean_absolute_error: 29084.8770 - val_loss: 0.0434 - val_mean_absolute_error: 28526.6877\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.04338 to 0.04337, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 45/200\n",
            "1022/1022 [==============================] - 0s 219us/step - loss: 0.0461 - mean_absolute_error: 29289.7672 - val_loss: 0.0433 - val_mean_absolute_error: 28428.8702\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.04337 to 0.04327, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 46/200\n",
            "1022/1022 [==============================] - 0s 217us/step - loss: 0.0461 - mean_absolute_error: 28999.9695 - val_loss: 0.0436 - val_mean_absolute_error: 28907.5553\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.04327\n",
            "Epoch 47/200\n",
            "1022/1022 [==============================] - 0s 225us/step - loss: 0.0462 - mean_absolute_error: 29304.5288 - val_loss: 0.0434 - val_mean_absolute_error: 28687.0061\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.04327\n",
            "Epoch 48/200\n",
            "1022/1022 [==============================] - 0s 214us/step - loss: 0.0461 - mean_absolute_error: 29145.3971 - val_loss: 0.0433 - val_mean_absolute_error: 28500.6827\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.04327\n",
            "Epoch 49/200\n",
            "1022/1022 [==============================] - 0s 229us/step - loss: 0.0461 - mean_absolute_error: 29140.7164 - val_loss: 0.0435 - val_mean_absolute_error: 28784.4297\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.04327\n",
            "Epoch 50/200\n",
            "1022/1022 [==============================] - 0s 226us/step - loss: 0.0460 - mean_absolute_error: 29270.3107 - val_loss: 0.0432 - val_mean_absolute_error: 28076.6137\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.04327 to 0.04316, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 51/200\n",
            "1022/1022 [==============================] - 0s 213us/step - loss: 0.0467 - mean_absolute_error: 29300.4914 - val_loss: 0.0433 - val_mean_absolute_error: 28676.7639\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.04316\n",
            "Epoch 52/200\n",
            "1022/1022 [==============================] - 0s 205us/step - loss: 0.0462 - mean_absolute_error: 29082.4488 - val_loss: 0.0431 - val_mean_absolute_error: 28146.3845\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.04316 to 0.04309, saving model to best_model_e200_b32_oadam_lr.h5\n",
            "Epoch 53/200\n",
            "1022/1022 [==============================] - 0s 199us/step - loss: 0.0460 - mean_absolute_error: 28991.8304 - val_loss: 0.0431 - val_mean_absolute_error: 28269.5627\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.04309\n",
            "Epoch 54/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0459 - mean_absolute_error: 29117.2981 - val_loss: 0.0432 - val_mean_absolute_error: 28573.3669\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.04309\n",
            "Epoch 55/200\n",
            "1022/1022 [==============================] - 0s 218us/step - loss: 0.0460 - mean_absolute_error: 29020.4479 - val_loss: 0.0433 - val_mean_absolute_error: 28652.8851\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.04309\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 56/200\n",
            "1022/1022 [==============================] - 0s 227us/step - loss: 0.0458 - mean_absolute_error: 29078.8642 - val_loss: 0.0432 - val_mean_absolute_error: 28575.2046\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.04309\n",
            "Epoch 57/200\n",
            "1022/1022 [==============================] - 0s 220us/step - loss: 0.0458 - mean_absolute_error: 29026.1194 - val_loss: 0.0432 - val_mean_absolute_error: 28507.2217\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.04309\n",
            "Epoch 58/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0457 - mean_absolute_error: 29008.7312 - val_loss: 0.0431 - val_mean_absolute_error: 28465.2450\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.04309\n",
            "Epoch 59/200\n",
            "1022/1022 [==============================] - 0s 222us/step - loss: 0.0457 - mean_absolute_error: 28944.7700 - val_loss: 0.0431 - val_mean_absolute_error: 28480.6475\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.04309\n",
            "Epoch 60/200\n",
            "1022/1022 [==============================] - 0s 216us/step - loss: 0.0457 - mean_absolute_error: 28982.8645 - val_loss: 0.0431 - val_mean_absolute_error: 28463.6476\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.04309\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 61/200\n",
            "1022/1022 [==============================] - 0s 217us/step - loss: 0.0457 - mean_absolute_error: 28951.7593 - val_loss: 0.0431 - val_mean_absolute_error: 28478.1551\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.04309\n",
            "Epoch 62/200\n",
            "1022/1022 [==============================] - 0s 204us/step - loss: 0.0457 - mean_absolute_error: 28971.7020 - val_loss: 0.0431 - val_mean_absolute_error: 28460.5520\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.04309\n",
            "Epoch 00062: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbQpx8taIeFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "823837b5-f9c5-4276-85e6-f81327512361"
      },
      "source": [
        "drow_history(history, 'loss', 2)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqusPgIUIeFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Load the best model\n",
        "NN_model.load_weights('best_model_e200_b32_oadam_lr.h5')\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', \n",
        "                 metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-W46GZ7IeFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5f3552d3-1795-471b-cd8d-3bc1d931e759"
      },
      "source": [
        "score=NN_model.evaluate(X_test, y_test)\n",
        "score"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "438/438 [==============================] - 0s 430us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04309418520222516, 28146.384453481736]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRkOgAi7IeFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "93cca0b4-58d8-4351-95ba-f75d7e58cd5c"
      },
      "source": [
        "score=NN_model.evaluate(train, target)\n",
        "score"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460/1460 [==============================] - 0s 63us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0451003445542022, 28629.494124571916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FsMblAoIeF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "33530b2e-ded8-43a8-b668-d3a389bcbc4d"
      },
      "source": [
        "predictions = NN_model.predict(test)\n",
        "make_submission(predictions[:,0],'submission_oadam_lr')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A submission file has been made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbbIMbwHIeF3",
        "colab_type": "text"
      },
      "source": [
        "* kaggle result  0.22401\n",
        "**********************************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_pPCZfCIeF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "5a16b6ea-801c-4b00-8110-957b002eb577"
      },
      "source": [
        "np.random.seed(1235)\n",
        "    \n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',\n",
        "                       input_dim = train.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "    \n",
        "\n",
        "# mean_squared_logarithmic_error\n",
        "# mean_absolute_error\n",
        "# mean_squared_error\n",
        "\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop', \n",
        "                 metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 128)               27520     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 619,393\n",
            "Trainable params: 619,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlsTp5t-IeF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71941ec8-f78c-4a43-9484-836325afaf54"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "np.random.seed(1235)\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model_e200_b32_rmsprop_net_128_512_512_512.h5', verbose=1, \n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True, mode='auto') \n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=10,\n",
        "                              verbose=1, mode='auto')\n",
        "\n",
        "history = NN_model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,callbacks=[checkpoint, early, reduce_lr],\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 600us/step - loss: 7.6481 - mean_absolute_error: 108479.0418 - val_loss: 0.1612 - val_mean_absolute_error: 58208.4387\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.16115, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 241us/step - loss: 0.1384 - mean_absolute_error: 56959.5367 - val_loss: 0.1256 - val_mean_absolute_error: 50884.3818\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.16115 to 0.12563, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 214us/step - loss: 0.0997 - mean_absolute_error: 46995.0202 - val_loss: 0.0783 - val_mean_absolute_error: 38769.1937\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.12563 to 0.07830, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0875 - mean_absolute_error: 42715.5111 - val_loss: 0.1100 - val_mean_absolute_error: 49615.9417\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.07830\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 200us/step - loss: 0.0772 - mean_absolute_error: 40227.8744 - val_loss: 0.0597 - val_mean_absolute_error: 35643.7964\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.07830 to 0.05968, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0738 - mean_absolute_error: 39256.4642 - val_loss: 0.0532 - val_mean_absolute_error: 30859.3813\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.05968 to 0.05318, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 216us/step - loss: 0.0715 - mean_absolute_error: 38158.8862 - val_loss: 0.0513 - val_mean_absolute_error: 32512.9488\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.05318 to 0.05134, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 216us/step - loss: 0.0678 - mean_absolute_error: 35743.7850 - val_loss: 0.0724 - val_mean_absolute_error: 36308.8576\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.05134\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0629 - mean_absolute_error: 35729.8018 - val_loss: 0.0461 - val_mean_absolute_error: 29178.2482\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.05134 to 0.04615, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 224us/step - loss: 0.0639 - mean_absolute_error: 35776.5410 - val_loss: 0.0451 - val_mean_absolute_error: 29371.0909\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.04615 to 0.04507, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 206us/step - loss: 0.0599 - mean_absolute_error: 33986.5043 - val_loss: 0.0654 - val_mean_absolute_error: 38449.8640\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.04507\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 225us/step - loss: 0.0623 - mean_absolute_error: 34767.4375 - val_loss: 0.0701 - val_mean_absolute_error: 35883.4557\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.04507\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 208us/step - loss: 0.0619 - mean_absolute_error: 34746.8656 - val_loss: 0.0456 - val_mean_absolute_error: 28911.5900\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.04507\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 217us/step - loss: 0.0606 - mean_absolute_error: 34026.3986 - val_loss: 0.0538 - val_mean_absolute_error: 30777.4356\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.04507\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0533 - mean_absolute_error: 31924.9880 - val_loss: 0.0586 - val_mean_absolute_error: 36401.3403\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.04507\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 224us/step - loss: 0.0509 - mean_absolute_error: 30991.7825 - val_loss: 0.0548 - val_mean_absolute_error: 34508.4406\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.04507\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 201us/step - loss: 0.0503 - mean_absolute_error: 30763.1147 - val_loss: 0.0430 - val_mean_absolute_error: 29186.3479\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.04507 to 0.04296, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0503 - mean_absolute_error: 30860.3610 - val_loss: 0.0434 - val_mean_absolute_error: 29549.2006\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.04296\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0493 - mean_absolute_error: 30662.4622 - val_loss: 0.0530 - val_mean_absolute_error: 30232.7811\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.04296\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 212us/step - loss: 0.0503 - mean_absolute_error: 30771.1142 - val_loss: 0.0438 - val_mean_absolute_error: 27787.4078\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.04296\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 206us/step - loss: 0.0504 - mean_absolute_error: 30755.4883 - val_loss: 0.0439 - val_mean_absolute_error: 27830.3987\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.04296\n",
            "Epoch 22/200\n",
            "1022/1022 [==============================] - 0s 221us/step - loss: 0.0487 - mean_absolute_error: 30035.2185 - val_loss: 0.0563 - val_mean_absolute_error: 35201.0700\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.04296\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 23/200\n",
            "1022/1022 [==============================] - 0s 207us/step - loss: 0.0474 - mean_absolute_error: 29524.5616 - val_loss: 0.0424 - val_mean_absolute_error: 27284.9005\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.04296 to 0.04242, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 24/200\n",
            "1022/1022 [==============================] - 0s 204us/step - loss: 0.0459 - mean_absolute_error: 28911.5269 - val_loss: 0.0411 - val_mean_absolute_error: 27157.2512\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.04242 to 0.04108, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 25/200\n",
            "1022/1022 [==============================] - 0s 204us/step - loss: 0.0460 - mean_absolute_error: 29091.6620 - val_loss: 0.0407 - val_mean_absolute_error: 27082.9461\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.04108 to 0.04074, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 26/200\n",
            "1022/1022 [==============================] - 0s 224us/step - loss: 0.0455 - mean_absolute_error: 28713.6187 - val_loss: 0.0431 - val_mean_absolute_error: 29875.4664\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.04074\n",
            "Epoch 27/200\n",
            "1022/1022 [==============================] - 0s 205us/step - loss: 0.0459 - mean_absolute_error: 28993.1097 - val_loss: 0.0400 - val_mean_absolute_error: 27299.5786\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.04074 to 0.04001, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 28/200\n",
            "1022/1022 [==============================] - 0s 225us/step - loss: 0.0454 - mean_absolute_error: 28939.8418 - val_loss: 0.0414 - val_mean_absolute_error: 26866.9912\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.04001\n",
            "Epoch 29/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0449 - mean_absolute_error: 28433.9427 - val_loss: 0.0431 - val_mean_absolute_error: 29923.2549\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.04001\n",
            "Epoch 30/200\n",
            "1022/1022 [==============================] - 0s 224us/step - loss: 0.0455 - mean_absolute_error: 28937.5423 - val_loss: 0.0396 - val_mean_absolute_error: 27210.1801\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.04001 to 0.03956, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 31/200\n",
            "1022/1022 [==============================] - 0s 200us/step - loss: 0.0450 - mean_absolute_error: 28410.7433 - val_loss: 0.0408 - val_mean_absolute_error: 28455.6299\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.03956\n",
            "Epoch 32/200\n",
            "1022/1022 [==============================] - 0s 204us/step - loss: 0.0454 - mean_absolute_error: 28770.1248 - val_loss: 0.0393 - val_mean_absolute_error: 26832.1516\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.03956 to 0.03933, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 33/200\n",
            "1022/1022 [==============================] - 0s 212us/step - loss: 0.0442 - mean_absolute_error: 28307.6590 - val_loss: 0.0443 - val_mean_absolute_error: 30175.5954\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.03933\n",
            "Epoch 34/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0447 - mean_absolute_error: 28534.5336 - val_loss: 0.0446 - val_mean_absolute_error: 30534.4681\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.03933\n",
            "Epoch 35/200\n",
            "1022/1022 [==============================] - 0s 205us/step - loss: 0.0439 - mean_absolute_error: 28357.2695 - val_loss: 0.0444 - val_mean_absolute_error: 30526.8956\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.03933\n",
            "Epoch 36/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0440 - mean_absolute_error: 28293.2698 - val_loss: 0.0405 - val_mean_absolute_error: 28005.3671\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.03933\n",
            "Epoch 37/200\n",
            "1022/1022 [==============================] - 0s 204us/step - loss: 0.0439 - mean_absolute_error: 28111.4425 - val_loss: 0.0388 - val_mean_absolute_error: 26380.5374\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.03933 to 0.03884, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 38/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0442 - mean_absolute_error: 28176.3689 - val_loss: 0.0391 - val_mean_absolute_error: 26087.9515\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.03884\n",
            "Epoch 39/200\n",
            "1022/1022 [==============================] - 0s 212us/step - loss: 0.0440 - mean_absolute_error: 28158.9939 - val_loss: 0.0388 - val_mean_absolute_error: 26957.7754\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.03884 to 0.03878, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 40/200\n",
            "1022/1022 [==============================] - 0s 202us/step - loss: 0.0432 - mean_absolute_error: 27665.8526 - val_loss: 0.0395 - val_mean_absolute_error: 27424.6091\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.03878\n",
            "Epoch 41/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0428 - mean_absolute_error: 27664.3292 - val_loss: 0.0384 - val_mean_absolute_error: 26142.2409\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.03878 to 0.03845, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 42/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0433 - mean_absolute_error: 27819.1188 - val_loss: 0.0432 - val_mean_absolute_error: 26667.5589\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.03845\n",
            "Epoch 43/200\n",
            "1022/1022 [==============================] - 0s 228us/step - loss: 0.0426 - mean_absolute_error: 27837.1123 - val_loss: 0.0393 - val_mean_absolute_error: 25757.0168\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.03845\n",
            "Epoch 44/200\n",
            "1022/1022 [==============================] - 0s 258us/step - loss: 0.0434 - mean_absolute_error: 27931.4741 - val_loss: 0.0400 - val_mean_absolute_error: 27980.5429\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.03845\n",
            "Epoch 45/200\n",
            "1022/1022 [==============================] - 0s 199us/step - loss: 0.0430 - mean_absolute_error: 27703.6731 - val_loss: 0.0391 - val_mean_absolute_error: 25678.3247\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.03845\n",
            "Epoch 46/200\n",
            "1022/1022 [==============================] - 0s 218us/step - loss: 0.0420 - mean_absolute_error: 27317.3812 - val_loss: 0.0390 - val_mean_absolute_error: 27009.5345\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.03845\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 47/200\n",
            "1022/1022 [==============================] - 0s 219us/step - loss: 0.0413 - mean_absolute_error: 27134.0710 - val_loss: 0.0382 - val_mean_absolute_error: 26311.1487\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.03845 to 0.03821, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 48/200\n",
            "1022/1022 [==============================] - 0s 227us/step - loss: 0.0409 - mean_absolute_error: 26910.3651 - val_loss: 0.0385 - val_mean_absolute_error: 26546.7170\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.03821\n",
            "Epoch 49/200\n",
            "1022/1022 [==============================] - 0s 208us/step - loss: 0.0412 - mean_absolute_error: 27096.5733 - val_loss: 0.0380 - val_mean_absolute_error: 26136.6329\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.03821 to 0.03803, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 50/200\n",
            "1022/1022 [==============================] - 0s 218us/step - loss: 0.0405 - mean_absolute_error: 26884.9021 - val_loss: 0.0387 - val_mean_absolute_error: 25372.5620\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.03803\n",
            "Epoch 51/200\n",
            "1022/1022 [==============================] - 0s 222us/step - loss: 0.0409 - mean_absolute_error: 26810.0501 - val_loss: 0.0378 - val_mean_absolute_error: 25773.9210\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.03803 to 0.03782, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 52/200\n",
            "1022/1022 [==============================] - 0s 213us/step - loss: 0.0402 - mean_absolute_error: 26612.5579 - val_loss: 0.0379 - val_mean_absolute_error: 25486.9752\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.03782\n",
            "Epoch 53/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0410 - mean_absolute_error: 26867.6268 - val_loss: 0.0386 - val_mean_absolute_error: 27032.5442\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.03782\n",
            "Epoch 54/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0407 - mean_absolute_error: 26759.4961 - val_loss: 0.0377 - val_mean_absolute_error: 25436.0196\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.03782 to 0.03769, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 55/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0405 - mean_absolute_error: 26734.7804 - val_loss: 0.0390 - val_mean_absolute_error: 27182.9303\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.03769\n",
            "Epoch 56/200\n",
            "1022/1022 [==============================] - 0s 199us/step - loss: 0.0400 - mean_absolute_error: 26581.0744 - val_loss: 0.0376 - val_mean_absolute_error: 25980.7783\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.03769 to 0.03763, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 57/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0400 - mean_absolute_error: 26687.7594 - val_loss: 0.0378 - val_mean_absolute_error: 26144.6770\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.03763\n",
            "Epoch 58/200\n",
            "1022/1022 [==============================] - 0s 199us/step - loss: 0.0402 - mean_absolute_error: 26670.7562 - val_loss: 0.0381 - val_mean_absolute_error: 26562.4239\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.03763\n",
            "Epoch 59/200\n",
            "1022/1022 [==============================] - 0s 207us/step - loss: 0.0402 - mean_absolute_error: 26754.7172 - val_loss: 0.0377 - val_mean_absolute_error: 25845.0696\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.03763\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 60/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0395 - mean_absolute_error: 26344.5369 - val_loss: 0.0375 - val_mean_absolute_error: 25954.4563\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.03763 to 0.03755, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 61/200\n",
            "1022/1022 [==============================] - 0s 222us/step - loss: 0.0392 - mean_absolute_error: 26306.7604 - val_loss: 0.0372 - val_mean_absolute_error: 25411.4443\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.03755 to 0.03725, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 62/200\n",
            "1022/1022 [==============================] - 0s 196us/step - loss: 0.0394 - mean_absolute_error: 26373.0303 - val_loss: 0.0381 - val_mean_absolute_error: 26600.5299\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.03725\n",
            "Epoch 63/200\n",
            "1022/1022 [==============================] - 0s 214us/step - loss: 0.0393 - mean_absolute_error: 26281.5876 - val_loss: 0.0377 - val_mean_absolute_error: 26290.2124\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.03725\n",
            "Epoch 64/200\n",
            "1022/1022 [==============================] - 0s 219us/step - loss: 0.0389 - mean_absolute_error: 26149.7263 - val_loss: 0.0380 - val_mean_absolute_error: 26431.2652\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.03725\n",
            "Epoch 65/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0393 - mean_absolute_error: 26376.9115 - val_loss: 0.0373 - val_mean_absolute_error: 25569.3909\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.03725\n",
            "Epoch 66/200\n",
            "1022/1022 [==============================] - 0s 203us/step - loss: 0.0392 - mean_absolute_error: 26253.1516 - val_loss: 0.0378 - val_mean_absolute_error: 26350.3286\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.03725\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 67/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0388 - mean_absolute_error: 26221.8039 - val_loss: 0.0372 - val_mean_absolute_error: 25759.9507\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.03725 to 0.03721, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 68/200\n",
            "1022/1022 [==============================] - 0s 203us/step - loss: 0.0388 - mean_absolute_error: 26075.2019 - val_loss: 0.0374 - val_mean_absolute_error: 26094.3565\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.03721\n",
            "Epoch 69/200\n",
            "1022/1022 [==============================] - 0s 226us/step - loss: 0.0388 - mean_absolute_error: 26143.0398 - val_loss: 0.0373 - val_mean_absolute_error: 25893.6420\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.03721\n",
            "Epoch 70/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0387 - mean_absolute_error: 26021.2858 - val_loss: 0.0381 - val_mean_absolute_error: 26666.6378\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.03721\n",
            "Epoch 71/200\n",
            "1022/1022 [==============================] - 0s 204us/step - loss: 0.0387 - mean_absolute_error: 26152.6528 - val_loss: 0.0372 - val_mean_absolute_error: 25839.0523\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.03721 to 0.03719, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 72/200\n",
            "1022/1022 [==============================] - 0s 212us/step - loss: 0.0386 - mean_absolute_error: 26033.7784 - val_loss: 0.0372 - val_mean_absolute_error: 25779.2299\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.03719 to 0.03715, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 73/200\n",
            "1022/1022 [==============================] - 0s 214us/step - loss: 0.0386 - mean_absolute_error: 26009.5600 - val_loss: 0.0372 - val_mean_absolute_error: 25878.1557\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.03715\n",
            "Epoch 74/200\n",
            "1022/1022 [==============================] - 0s 217us/step - loss: 0.0385 - mean_absolute_error: 26047.3711 - val_loss: 0.0372 - val_mean_absolute_error: 25811.1980\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.03715\n",
            "Epoch 75/200\n",
            "1022/1022 [==============================] - 0s 210us/step - loss: 0.0385 - mean_absolute_error: 25853.7422 - val_loss: 0.0375 - val_mean_absolute_error: 26135.3508\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.03715\n",
            "Epoch 76/200\n",
            "1022/1022 [==============================] - 0s 211us/step - loss: 0.0384 - mean_absolute_error: 26060.2867 - val_loss: 0.0371 - val_mean_absolute_error: 25570.8299\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.03715 to 0.03706, saving model to best_model_e200_b32_rmsprop_net_128_512_512_512.h5\n",
            "Epoch 77/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0384 - mean_absolute_error: 26005.4376 - val_loss: 0.0372 - val_mean_absolute_error: 25820.9292\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.03706\n",
            "Epoch 78/200\n",
            "1022/1022 [==============================] - 0s 209us/step - loss: 0.0385 - mean_absolute_error: 25961.8805 - val_loss: 0.0374 - val_mean_absolute_error: 26059.3910\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.03706\n",
            "Epoch 79/200\n",
            "1022/1022 [==============================] - 0s 216us/step - loss: 0.0385 - mean_absolute_error: 26029.3411 - val_loss: 0.0373 - val_mean_absolute_error: 25987.4560\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.03706\n",
            "Epoch 80/200\n",
            "1022/1022 [==============================] - 0s 202us/step - loss: 0.0384 - mean_absolute_error: 25966.9384 - val_loss: 0.0373 - val_mean_absolute_error: 25957.4162\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.03706\n",
            "Epoch 81/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0384 - mean_absolute_error: 25941.3878 - val_loss: 0.0373 - val_mean_absolute_error: 25912.2404\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.03706\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 82/200\n",
            "1022/1022 [==============================] - 0s 217us/step - loss: 0.0384 - mean_absolute_error: 25947.6714 - val_loss: 0.0372 - val_mean_absolute_error: 25884.1682\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.03706\n",
            "Epoch 83/200\n",
            "1022/1022 [==============================] - 0s 208us/step - loss: 0.0384 - mean_absolute_error: 25905.1405 - val_loss: 0.0373 - val_mean_absolute_error: 25974.6872\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.03706\n",
            "Epoch 84/200\n",
            "1022/1022 [==============================] - 0s 215us/step - loss: 0.0384 - mean_absolute_error: 25974.0234 - val_loss: 0.0373 - val_mean_absolute_error: 25957.6310\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.03706\n",
            "Epoch 85/200\n",
            "1022/1022 [==============================] - 0s 198us/step - loss: 0.0383 - mean_absolute_error: 25940.4140 - val_loss: 0.0372 - val_mean_absolute_error: 25782.6681\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.03706\n",
            "Epoch 86/200\n",
            "1022/1022 [==============================] - 0s 207us/step - loss: 0.0384 - mean_absolute_error: 25926.9649 - val_loss: 0.0372 - val_mean_absolute_error: 25807.2821\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.03706\n",
            "Epoch 00086: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "spztihOcIeF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bf88fc98-3b27-4d3b-a431-fb678b2abd4a"
      },
      "source": [
        "drow_history(history, 'loss', 1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi9y9lXvIeGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Load the best model\n",
        "NN_model.load_weights('best_model_e200_b32_rmsprop_net_128_512_512_512.h5')\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', \n",
        "                 metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3WHsqw8IeGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "308e2dcf-b25f-4d5a-9da3-bc60f0444618"
      },
      "source": [
        "score=NN_model.evaluate(X_test, y_test)\n",
        "score"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "438/438 [==============================] - 0s 490us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03705601324433606, 25570.829890839042]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6wmLkA4IeGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "95c6885d-5d04-458d-b77a-d0b6e76c7b17"
      },
      "source": [
        "score=NN_model.evaluate(train, target)\n",
        "score"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460/1460 [==============================] - 0s 62us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03801739062756708, 25731.854163099317]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwzX7U4DIeGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2adc208e-c2fa-4378-ef76-e8f11f0150ad"
      },
      "source": [
        "predictions = NN_model.predict(test)\n",
        "make_submission(predictions[:,0],'submission_rmsprop_net_128_512_512_512')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A submission file has been made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOe3ReypIeGN",
        "colab_type": "text"
      },
      "source": [
        "* Result 0.20622\n",
        "\n",
        "******************************************************************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7KmzaByIeGO",
        "colab_type": "text"
      },
      "source": [
        "* Enlarge the first Layer\n",
        "* Drop the last Layer\n",
        "* reduce batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr1HOqCtIeGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "4998a1d8-e4e4-46b1-eea2-3985328c1aa9"
      },
      "source": [
        "np.random.seed(1235)\n",
        "    \n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(264, kernel_initializer='normal',\n",
        "                       input_dim = train.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "\n",
        "# mean_squared_logarithmic_error\n",
        "# mean_absolute_error\n",
        "# mean_squared_error\n",
        "\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='rmsprop', \n",
        "                 metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 264)               56760     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 512)               135680    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 455,609\n",
            "Trainable params: 455,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzSTbUq8IeGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da25253c-c443-4fad-f257-516a1ba98e7c"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "np.random.seed(1235)\n",
        "epochs = 200\n",
        "batch_size = 16\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model_e200_b16_rmsprop_net_264_512_512.h5', verbose=1, \n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True, mode='auto') \n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=10,\n",
        "                              verbose=1, mode='auto')\n",
        "\n",
        "history = NN_model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,callbacks=[checkpoint, early, reduce_lr],\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1022 samples, validate on 438 samples\n",
            "Epoch 1/200\n",
            "1022/1022 [==============================] - 1s 794us/step - loss: 2.6487 - mean_absolute_error: 95551.9504 - val_loss: 0.1179 - val_mean_absolute_error: 49873.1885\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.11787, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 2/200\n",
            "1022/1022 [==============================] - 0s 375us/step - loss: 0.0946 - mean_absolute_error: 45389.0175 - val_loss: 0.0824 - val_mean_absolute_error: 41404.7687\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.11787 to 0.08241, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 3/200\n",
            "1022/1022 [==============================] - 0s 389us/step - loss: 0.0753 - mean_absolute_error: 39306.8447 - val_loss: 0.0593 - val_mean_absolute_error: 33000.6553\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.08241 to 0.05925, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 4/200\n",
            "1022/1022 [==============================] - 0s 386us/step - loss: 0.0623 - mean_absolute_error: 34916.3884 - val_loss: 0.1379 - val_mean_absolute_error: 54664.3152\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.05925\n",
            "Epoch 5/200\n",
            "1022/1022 [==============================] - 0s 372us/step - loss: 0.0588 - mean_absolute_error: 33455.5125 - val_loss: 0.0532 - val_mean_absolute_error: 33540.6608\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.05925 to 0.05323, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 6/200\n",
            "1022/1022 [==============================] - 0s 383us/step - loss: 0.0574 - mean_absolute_error: 33046.0198 - val_loss: 0.0457 - val_mean_absolute_error: 29996.2143\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.05323 to 0.04573, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 7/200\n",
            "1022/1022 [==============================] - 0s 385us/step - loss: 0.0554 - mean_absolute_error: 32621.3383 - val_loss: 0.0486 - val_mean_absolute_error: 29166.9662\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.04573\n",
            "Epoch 8/200\n",
            "1022/1022 [==============================] - 0s 388us/step - loss: 0.0542 - mean_absolute_error: 32119.8917 - val_loss: 0.0440 - val_mean_absolute_error: 28439.7309\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.04573 to 0.04397, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 9/200\n",
            "1022/1022 [==============================] - 0s 389us/step - loss: 0.0538 - mean_absolute_error: 32262.5865 - val_loss: 0.0559 - val_mean_absolute_error: 34810.4561\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.04397\n",
            "Epoch 10/200\n",
            "1022/1022 [==============================] - 0s 386us/step - loss: 0.0547 - mean_absolute_error: 32568.2109 - val_loss: 0.0416 - val_mean_absolute_error: 27946.7873\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.04397 to 0.04159, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 11/200\n",
            "1022/1022 [==============================] - 0s 373us/step - loss: 0.0533 - mean_absolute_error: 31463.5643 - val_loss: 0.0511 - val_mean_absolute_error: 33305.2822\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.04159\n",
            "Epoch 12/200\n",
            "1022/1022 [==============================] - 0s 374us/step - loss: 0.0524 - mean_absolute_error: 31064.8287 - val_loss: 0.0410 - val_mean_absolute_error: 27839.1583\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.04159 to 0.04103, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 13/200\n",
            "1022/1022 [==============================] - 0s 395us/step - loss: 0.0523 - mean_absolute_error: 30829.1277 - val_loss: 0.0424 - val_mean_absolute_error: 27386.8961\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.04103\n",
            "Epoch 14/200\n",
            "1022/1022 [==============================] - 0s 387us/step - loss: 0.0514 - mean_absolute_error: 30576.7241 - val_loss: 0.0455 - val_mean_absolute_error: 30914.5203\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.04103\n",
            "Epoch 15/200\n",
            "1022/1022 [==============================] - 0s 384us/step - loss: 0.0508 - mean_absolute_error: 30924.1695 - val_loss: 0.0431 - val_mean_absolute_error: 29656.1838\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.04103\n",
            "Epoch 16/200\n",
            "1022/1022 [==============================] - 0s 391us/step - loss: 0.0502 - mean_absolute_error: 30414.3383 - val_loss: 0.0423 - val_mean_absolute_error: 28302.8889\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.04103\n",
            "Epoch 17/200\n",
            "1022/1022 [==============================] - 0s 400us/step - loss: 0.0519 - mean_absolute_error: 30746.6046 - val_loss: 0.0443 - val_mean_absolute_error: 29937.5174\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.04103\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 18/200\n",
            "1022/1022 [==============================] - 0s 373us/step - loss: 0.0455 - mean_absolute_error: 29027.5666 - val_loss: 0.0415 - val_mean_absolute_error: 28193.4447\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.04103\n",
            "Epoch 19/200\n",
            "1022/1022 [==============================] - 0s 392us/step - loss: 0.0450 - mean_absolute_error: 28685.8907 - val_loss: 0.0399 - val_mean_absolute_error: 26405.3577\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.04103 to 0.03989, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 20/200\n",
            "1022/1022 [==============================] - 0s 400us/step - loss: 0.0441 - mean_absolute_error: 28269.6373 - val_loss: 0.0398 - val_mean_absolute_error: 25859.1679\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.03989 to 0.03983, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 21/200\n",
            "1022/1022 [==============================] - 0s 374us/step - loss: 0.0440 - mean_absolute_error: 28488.9737 - val_loss: 0.0399 - val_mean_absolute_error: 26054.5932\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.03983\n",
            "Epoch 22/200\n",
            "1022/1022 [==============================] - 0s 373us/step - loss: 0.0449 - mean_absolute_error: 28351.0494 - val_loss: 0.0545 - val_mean_absolute_error: 34202.5183\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.03983\n",
            "Epoch 23/200\n",
            "1022/1022 [==============================] - 0s 359us/step - loss: 0.0447 - mean_absolute_error: 28128.2208 - val_loss: 0.0396 - val_mean_absolute_error: 25589.9896\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.03983 to 0.03964, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 24/200\n",
            "1022/1022 [==============================] - 0s 362us/step - loss: 0.0434 - mean_absolute_error: 27833.2698 - val_loss: 0.0409 - val_mean_absolute_error: 25756.5621\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.03964\n",
            "Epoch 25/200\n",
            "1022/1022 [==============================] - 0s 391us/step - loss: 0.0425 - mean_absolute_error: 27547.9473 - val_loss: 0.0395 - val_mean_absolute_error: 25248.3109\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.03964 to 0.03946, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 26/200\n",
            "1022/1022 [==============================] - 0s 372us/step - loss: 0.0432 - mean_absolute_error: 27509.2088 - val_loss: 0.0418 - val_mean_absolute_error: 28785.5175\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.03946\n",
            "Epoch 27/200\n",
            "1022/1022 [==============================] - 0s 397us/step - loss: 0.0429 - mean_absolute_error: 27750.3923 - val_loss: 0.0385 - val_mean_absolute_error: 26252.3324\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.03946 to 0.03854, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 28/200\n",
            "1022/1022 [==============================] - 0s 383us/step - loss: 0.0424 - mean_absolute_error: 27365.3694 - val_loss: 0.0393 - val_mean_absolute_error: 25132.0658\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.03854\n",
            "Epoch 29/200\n",
            "1022/1022 [==============================] - 0s 380us/step - loss: 0.0425 - mean_absolute_error: 27343.2272 - val_loss: 0.0451 - val_mean_absolute_error: 30462.1362\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.03854\n",
            "Epoch 30/200\n",
            "1022/1022 [==============================] - 0s 361us/step - loss: 0.0423 - mean_absolute_error: 27521.8161 - val_loss: 0.0379 - val_mean_absolute_error: 24681.0194\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.03854 to 0.03794, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 31/200\n",
            "1022/1022 [==============================] - 0s 391us/step - loss: 0.0419 - mean_absolute_error: 27172.3812 - val_loss: 0.0408 - val_mean_absolute_error: 27798.2335\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.03794\n",
            "Epoch 32/200\n",
            "1022/1022 [==============================] - 0s 392us/step - loss: 0.0428 - mean_absolute_error: 27533.4430 - val_loss: 0.0391 - val_mean_absolute_error: 26698.2547\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.03794\n",
            "Epoch 33/200\n",
            "1022/1022 [==============================] - 0s 391us/step - loss: 0.0418 - mean_absolute_error: 27316.0581 - val_loss: 0.0398 - val_mean_absolute_error: 25709.0399\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.03794\n",
            "Epoch 34/200\n",
            "1022/1022 [==============================] - 0s 406us/step - loss: 0.0414 - mean_absolute_error: 27018.4328 - val_loss: 0.0400 - val_mean_absolute_error: 27541.0747\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.03794\n",
            "Epoch 35/200\n",
            "1022/1022 [==============================] - 0s 372us/step - loss: 0.0411 - mean_absolute_error: 27260.0784 - val_loss: 0.0458 - val_mean_absolute_error: 30778.7593\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.03794\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 36/200\n",
            "1022/1022 [==============================] - 0s 391us/step - loss: 0.0392 - mean_absolute_error: 26263.4650 - val_loss: 0.0363 - val_mean_absolute_error: 24671.9855\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.03794 to 0.03627, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 37/200\n",
            "1022/1022 [==============================] - 0s 391us/step - loss: 0.0384 - mean_absolute_error: 25925.1580 - val_loss: 0.0369 - val_mean_absolute_error: 25942.7181\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.03627\n",
            "Epoch 38/200\n",
            "1022/1022 [==============================] - 0s 367us/step - loss: 0.0387 - mean_absolute_error: 25992.0732 - val_loss: 0.0357 - val_mean_absolute_error: 24438.2556\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.03627 to 0.03574, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 39/200\n",
            "1022/1022 [==============================] - 0s 398us/step - loss: 0.0387 - mean_absolute_error: 26028.7097 - val_loss: 0.0364 - val_mean_absolute_error: 25388.6631\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.03574\n",
            "Epoch 40/200\n",
            "1022/1022 [==============================] - 0s 361us/step - loss: 0.0385 - mean_absolute_error: 25947.4510 - val_loss: 0.0367 - val_mean_absolute_error: 25189.7937\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.03574\n",
            "Epoch 41/200\n",
            "1022/1022 [==============================] - 0s 388us/step - loss: 0.0374 - mean_absolute_error: 25474.8882 - val_loss: 0.0359 - val_mean_absolute_error: 24727.2463\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.03574\n",
            "Epoch 42/200\n",
            "1022/1022 [==============================] - 0s 376us/step - loss: 0.0381 - mean_absolute_error: 25618.1094 - val_loss: 0.0364 - val_mean_absolute_error: 23947.6729\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.03574\n",
            "Epoch 43/200\n",
            "1022/1022 [==============================] - 0s 361us/step - loss: 0.0381 - mean_absolute_error: 25640.0384 - val_loss: 0.0350 - val_mean_absolute_error: 24346.6168\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.03574 to 0.03503, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 44/200\n",
            "1022/1022 [==============================] - 0s 390us/step - loss: 0.0375 - mean_absolute_error: 25644.0383 - val_loss: 0.0363 - val_mean_absolute_error: 25453.9898\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.03503\n",
            "Epoch 45/200\n",
            "1022/1022 [==============================] - 0s 368us/step - loss: 0.0374 - mean_absolute_error: 25755.3592 - val_loss: 0.0368 - val_mean_absolute_error: 24048.2630\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.03503\n",
            "Epoch 46/200\n",
            "1022/1022 [==============================] - 0s 352us/step - loss: 0.0374 - mean_absolute_error: 25549.4076 - val_loss: 0.0360 - val_mean_absolute_error: 24877.4762\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.03503\n",
            "Epoch 47/200\n",
            "1022/1022 [==============================] - 0s 373us/step - loss: 0.0371 - mean_absolute_error: 25456.5933 - val_loss: 0.0376 - val_mean_absolute_error: 25943.5140\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.03503\n",
            "Epoch 48/200\n",
            "1022/1022 [==============================] - 0s 368us/step - loss: 0.0364 - mean_absolute_error: 25056.7518 - val_loss: 0.0362 - val_mean_absolute_error: 25087.3044\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.03503\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 49/200\n",
            "1022/1022 [==============================] - 0s 388us/step - loss: 0.0358 - mean_absolute_error: 24946.4506 - val_loss: 0.0354 - val_mean_absolute_error: 24565.7654\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.03503\n",
            "Epoch 50/200\n",
            "1022/1022 [==============================] - 0s 386us/step - loss: 0.0357 - mean_absolute_error: 24911.7633 - val_loss: 0.0354 - val_mean_absolute_error: 23705.1475\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.03503\n",
            "Epoch 51/200\n",
            "1022/1022 [==============================] - 0s 386us/step - loss: 0.0356 - mean_absolute_error: 24613.6108 - val_loss: 0.0352 - val_mean_absolute_error: 24275.9854\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.03503\n",
            "Epoch 52/200\n",
            "1022/1022 [==============================] - 0s 394us/step - loss: 0.0353 - mean_absolute_error: 24653.2621 - val_loss: 0.0348 - val_mean_absolute_error: 23838.3644\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.03503 to 0.03480, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 53/200\n",
            "1022/1022 [==============================] - 0s 358us/step - loss: 0.0355 - mean_absolute_error: 24692.7330 - val_loss: 0.0349 - val_mean_absolute_error: 24576.0290\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.03480\n",
            "Epoch 54/200\n",
            "1022/1022 [==============================] - 0s 373us/step - loss: 0.0354 - mean_absolute_error: 24741.2072 - val_loss: 0.0346 - val_mean_absolute_error: 23980.1584\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.03480 to 0.03458, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 55/200\n",
            "1022/1022 [==============================] - 0s 379us/step - loss: 0.0353 - mean_absolute_error: 24696.1771 - val_loss: 0.0356 - val_mean_absolute_error: 24960.3352\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.03458\n",
            "Epoch 56/200\n",
            "1022/1022 [==============================] - 0s 364us/step - loss: 0.0350 - mean_absolute_error: 24531.0259 - val_loss: 0.0351 - val_mean_absolute_error: 24698.5504\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.03458\n",
            "Epoch 57/200\n",
            "1022/1022 [==============================] - 0s 371us/step - loss: 0.0351 - mean_absolute_error: 24717.3262 - val_loss: 0.0346 - val_mean_absolute_error: 24132.3019\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.03458\n",
            "Epoch 58/200\n",
            "1022/1022 [==============================] - 0s 377us/step - loss: 0.0352 - mean_absolute_error: 24568.7698 - val_loss: 0.0353 - val_mean_absolute_error: 24841.2708\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.03458\n",
            "Epoch 59/200\n",
            "1022/1022 [==============================] - 0s 409us/step - loss: 0.0350 - mean_absolute_error: 24579.6715 - val_loss: 0.0348 - val_mean_absolute_error: 24191.1685\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.03458\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 60/200\n",
            "1022/1022 [==============================] - 0s 385us/step - loss: 0.0344 - mean_absolute_error: 24251.1924 - val_loss: 0.0345 - val_mean_absolute_error: 24156.1530\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.03458 to 0.03453, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 61/200\n",
            "1022/1022 [==============================] - 0s 387us/step - loss: 0.0342 - mean_absolute_error: 24373.9081 - val_loss: 0.0343 - val_mean_absolute_error: 23797.7820\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.03453 to 0.03432, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 62/200\n",
            "1022/1022 [==============================] - 0s 393us/step - loss: 0.0344 - mean_absolute_error: 24339.7368 - val_loss: 0.0349 - val_mean_absolute_error: 24668.3178\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.03432\n",
            "Epoch 63/200\n",
            "1022/1022 [==============================] - 0s 368us/step - loss: 0.0342 - mean_absolute_error: 24287.2060 - val_loss: 0.0348 - val_mean_absolute_error: 24572.7636\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.03432\n",
            "Epoch 64/200\n",
            "1022/1022 [==============================] - 0s 352us/step - loss: 0.0341 - mean_absolute_error: 24157.6274 - val_loss: 0.0351 - val_mean_absolute_error: 24690.9664\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.03432\n",
            "Epoch 65/200\n",
            "1022/1022 [==============================] - 0s 387us/step - loss: 0.0342 - mean_absolute_error: 24262.3217 - val_loss: 0.0344 - val_mean_absolute_error: 23846.3472\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.03432\n",
            "Epoch 66/200\n",
            "1022/1022 [==============================] - 0s 390us/step - loss: 0.0341 - mean_absolute_error: 24244.5556 - val_loss: 0.0347 - val_mean_absolute_error: 24381.4322\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.03432\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 67/200\n",
            "1022/1022 [==============================] - 0s 370us/step - loss: 0.0337 - mean_absolute_error: 24164.6211 - val_loss: 0.0343 - val_mean_absolute_error: 23977.8508\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.03432 to 0.03429, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 68/200\n",
            "1022/1022 [==============================] - 0s 363us/step - loss: 0.0338 - mean_absolute_error: 24060.6544 - val_loss: 0.0344 - val_mean_absolute_error: 24249.2168\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.03429\n",
            "Epoch 69/200\n",
            "1022/1022 [==============================] - 0s 384us/step - loss: 0.0337 - mean_absolute_error: 24127.1472 - val_loss: 0.0343 - val_mean_absolute_error: 24137.8073\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.03429\n",
            "Epoch 70/200\n",
            "1022/1022 [==============================] - 0s 381us/step - loss: 0.0337 - mean_absolute_error: 24049.3604 - val_loss: 0.0349 - val_mean_absolute_error: 24721.3828\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.03429\n",
            "Epoch 71/200\n",
            "1022/1022 [==============================] - 0s 374us/step - loss: 0.0337 - mean_absolute_error: 24113.7986 - val_loss: 0.0344 - val_mean_absolute_error: 24229.2244\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.03429\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 72/200\n",
            "1022/1022 [==============================] - 0s 376us/step - loss: 0.0335 - mean_absolute_error: 23993.4767 - val_loss: 0.0342 - val_mean_absolute_error: 23990.8541\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.03429 to 0.03417, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 73/200\n",
            "1022/1022 [==============================] - 0s 361us/step - loss: 0.0335 - mean_absolute_error: 23987.4314 - val_loss: 0.0343 - val_mean_absolute_error: 24194.2349\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.03417\n",
            "Epoch 74/200\n",
            "1022/1022 [==============================] - 0s 389us/step - loss: 0.0335 - mean_absolute_error: 24007.3425 - val_loss: 0.0342 - val_mean_absolute_error: 24113.4702\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.03417\n",
            "Epoch 75/200\n",
            "1022/1022 [==============================] - 0s 377us/step - loss: 0.0334 - mean_absolute_error: 23858.1369 - val_loss: 0.0346 - val_mean_absolute_error: 24409.7016\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.03417\n",
            "Epoch 76/200\n",
            "1022/1022 [==============================] - 0s 395us/step - loss: 0.0334 - mean_absolute_error: 24018.0270 - val_loss: 0.0341 - val_mean_absolute_error: 23875.6822\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.03417 to 0.03409, saving model to best_model_e200_b16_rmsprop_net_264_512_512.h5\n",
            "Epoch 77/200\n",
            "1022/1022 [==============================] - 0s 357us/step - loss: 0.0334 - mean_absolute_error: 23963.2801 - val_loss: 0.0343 - val_mean_absolute_error: 24111.6859\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.03409\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 78/200\n",
            "1022/1022 [==============================] - 0s 369us/step - loss: 0.0334 - mean_absolute_error: 23932.2525 - val_loss: 0.0344 - val_mean_absolute_error: 24238.7314\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.03409\n",
            "Epoch 79/200\n",
            "1022/1022 [==============================] - 0s 380us/step - loss: 0.0334 - mean_absolute_error: 23977.1925 - val_loss: 0.0343 - val_mean_absolute_error: 24226.2316\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.03409\n",
            "Epoch 80/200\n",
            "1022/1022 [==============================] - 0s 385us/step - loss: 0.0334 - mean_absolute_error: 23940.7070 - val_loss: 0.0343 - val_mean_absolute_error: 24200.5590\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.03409\n",
            "Epoch 81/200\n",
            "1022/1022 [==============================] - 0s 375us/step - loss: 0.0334 - mean_absolute_error: 23943.4907 - val_loss: 0.0342 - val_mean_absolute_error: 24118.3674\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.03409\n",
            "Epoch 82/200\n",
            "1022/1022 [==============================] - 0s 375us/step - loss: 0.0334 - mean_absolute_error: 23956.2445 - val_loss: 0.0342 - val_mean_absolute_error: 24122.6835\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.03409\n",
            "Epoch 83/200\n",
            "1022/1022 [==============================] - 0s 377us/step - loss: 0.0333 - mean_absolute_error: 23898.5561 - val_loss: 0.0343 - val_mean_absolute_error: 24268.9379\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.03409\n",
            "Epoch 84/200\n",
            "1022/1022 [==============================] - 0s 365us/step - loss: 0.0333 - mean_absolute_error: 23969.2142 - val_loss: 0.0342 - val_mean_absolute_error: 24106.2870\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.03409\n",
            "Epoch 85/200\n",
            "1022/1022 [==============================] - 0s 369us/step - loss: 0.0333 - mean_absolute_error: 23910.4555 - val_loss: 0.0342 - val_mean_absolute_error: 24084.8463\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.03409\n",
            "Epoch 86/200\n",
            "1022/1022 [==============================] - 0s 382us/step - loss: 0.0333 - mean_absolute_error: 23926.5126 - val_loss: 0.0342 - val_mean_absolute_error: 24092.3146\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.03409\n",
            "Epoch 00086: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "90YnajHzIeGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "479b45bf-35fc-4d36-c224-0b95abee4bce"
      },
      "source": [
        "drow_history(history, 'loss', 1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGO69f8BifUaYXqwuAwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLPKF_b4IeGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Load the best model\n",
        "NN_model.load_weights('best_model_e200_b16_rmsprop_net_264_512_512.h5')\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', \n",
        "                 metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGAVD3N7IeGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7e4e0aa3-5886-4b32-f8dc-b415d9c69f10"
      },
      "source": [
        "score=NN_model.evaluate(X_test, y_test)\n",
        "score"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "438/438 [==============================] - 0s 585us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03409179752547992, 23875.68234517694]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slENdqOvIeGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8639f82f-b6d5-4b45-9b9a-4c80309f0610"
      },
      "source": [
        "score=NN_model.evaluate(X_test, y_test)\n",
        "score"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "438/438 [==============================] - 0s 86us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03409179752547992, 23875.68234517694]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfHg1BJVIeGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "05f15446-2164-4786-b680-613572b23a87"
      },
      "source": [
        "score=NN_model.evaluate(train, target)\n",
        "score"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460/1460 [==============================] - 0s 52us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03359731672561332, 23837.644343964042]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CZNobAOIeGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e9c2acc0-1a6a-481a-8595-9fc108598be6"
      },
      "source": [
        "score=NN_model.evaluate(train, target)\n",
        "score"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460/1460 [==============================] - 0s 54us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03359731672561332, 23837.644343964042]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjdMpggfIeGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f235e450-c0ea-4988-bba7-159f25b64f39"
      },
      "source": [
        "y_test_pred = NN_model.predict(X_test)\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "mean_squared_log_error(y_test, y_test_pred)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.034091797705005006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx20PgqtIeGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "46db8eec-dddd-40f7-c28f-2eaccd39eb57"
      },
      "source": [
        "predictions = NN_model.predict(test)\n",
        "make_submission(predictions[:,0],'submission_rmsprop_net_264_512_512')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A submission file has been made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATbOTADiIeGm",
        "colab_type": "text"
      },
      "source": [
        "* result 0.19681"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGhySt77IeGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## NextLSTM and time series"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI1RnSi9O9Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://www.youtube.com/watch?v=ftMq5ps503w\n",
        "https://www.youtube.com/watch?v=9zhrxE5PQgY&t=44s\n",
        "https://github.com/llSourcell/How-to-Predict-Stock-Prices-Easily-Demo/blob/master/stockdemo.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY6s6yFKO5U9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}